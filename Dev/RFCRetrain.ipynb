{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d94d2bb",
   "metadata": {},
   "source": [
    "SAAPpred script that predicts protein pathogenicty from SAAPdap data, using SciKit-Learn random forests. \n",
    "Goal is to predict SNP or PD with MCC > 0.7.\n",
    "        \n",
    "Retrain CV models are directly used for final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports the required libraries and packages \"\"\"\n",
    "\n",
    "import pandas as pd                                                              # Data manipulation in dataframes\n",
    "import numpy as np                                                               # Array manipulation\n",
    "import pickle\n",
    "import hyperopt\n",
    "\n",
    "import random as rd                                                              # Random seed generation\n",
    "import time                                                                      # Time program run time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch                                             # CV visualise\n",
    "from matplotlib import colors \n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,                                                           # MCC for evaluation\n",
    "    confusion_matrix,                                                            # Confusion matrix for classification evalutation\n",
    "    classification_report                                                        # Return the F1, precision, and recall of a prediction\n",
    "    )\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    GroupKFold                                                                   # K-fold CV with as groups\n",
    "        )\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier                              # SK learn API for classificastion random forests\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK                                       # Functions for minimising cost functions\n",
    "from hyperopt.pyll.base import scope\n",
    "from functools import partial\n",
    "\n",
    "np.set_printoptions(precision = 3,threshold=np.inf, suppress=True)               # Full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(file_train, file_test):\n",
    "    \"\"\"      \n",
    "     Returns:    Training_Set     Scaled 80% training set split\n",
    "                 Testing_Set      Scaled 20% testing set split\n",
    "            \n",
    "    Opens the scaled training and testing data\n",
    "    \"\"\"\n",
    "    Training_Set = pd.read_csv(file_train, index_col = 0)\n",
    "    Testing_Set = pd.read_csv(file_test,index_col = 0)\n",
    "    \n",
    "    with open(\"seed.txt\", \"r\") as f:\n",
    "        seed = int(f.read().strip())\n",
    "    \n",
    "    return Training_Set, Testing_Set, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_data(Training_Set, Testing_Set):\n",
    "    \"\"\"      \n",
    "    Input:      Training_Set     Scaled 80% training set split\n",
    "                Testing_Set      20% testing set split\n",
    "\n",
    "    Returns:    TrainData        Training features \n",
    "                TrainLabels      Training labels\n",
    "                TestData         Testing features \n",
    "                TestLabels       Testing labels\n",
    "            \n",
    "    Separates training and testing data into features and labels\n",
    "    \"\"\"\n",
    "    TrainData     = Training_Set.drop(['AC Code','dataset'], axis =1)  \n",
    "    TrainLabels   = Training_Set['dataset']\n",
    "    \n",
    "    TestData     = Testing_Set.drop(['AC Code','dataset'], axis =1)  \n",
    "    TestLabels   = Testing_Set['dataset']        \n",
    "    \n",
    "    return (TrainData, TrainLabels, TestData, TestLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3a2df",
   "metadata": {},
   "source": [
    "## Group K-fold CV (outer loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ff775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(Training_Set):\n",
    "    \"\"\"      \n",
    "    Input:      Training_Set     80% training set split\n",
    "            \n",
    "    Returns:    IT_list         List of training features for each fold\n",
    "                LT_list         List of training class labels for each fold\n",
    "                IV_list         List of validation features for each fold\n",
    "                LV_list         List of validation class labels for each fold\n",
    "\n",
    "    K-fold CV with protein groups separated between training and validation sets for each fold. Creates 5 folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    features     = Training_Set.drop(['dataset'], axis =1)         #Features for training\n",
    "    labels       = Training_Set['dataset']                         #Class labels for training\n",
    "    groups       = Training_Set['AC Code'].to_list()               #List of proteins for grouping\n",
    "    \n",
    "    CV           = GroupKFold(n_splits = 5)                        #Creates 5 splits\n",
    "    \n",
    "    IT_list      = []\n",
    "    LT_list      = []\n",
    "    IV_list      = []\n",
    "    LV_list      = []\n",
    "    \n",
    "    for train_idx, val_idx in CV.split(features, labels, groups):       #Generates the indices to be used for a training and validation split. Indicies are unique to train/ val sets\n",
    "\n",
    "        Input_train                        = features.loc[train_idx]    #New dataframe from selected indices\n",
    "        Classes_train                      = labels.loc[train_idx]\n",
    "        Input_train.drop(['AC Code'], axis = 1, inplace = True)         #Group identifer not needed for training\n",
    "\n",
    "                \n",
    "        Input_val                          = features.loc[val_idx]\n",
    "        Classes_val                        = labels.loc[val_idx]\n",
    "        Input_val.drop(['AC Code'], axis   = 1, inplace = True)\n",
    "        \n",
    "        Input_train.reset_index(drop = True, inplace = True)            #Reset index of each set for compatability with balancing\n",
    "        Classes_train.reset_index(drop = True, inplace = True)\n",
    "        Input_val.reset_index(drop = True, inplace = True)\n",
    "        Classes_val.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        IT_list.append(Input_train)       \n",
    "        LT_list.append(Classes_train)\n",
    "        IV_list.append(Input_val)\n",
    "        LV_list.append(Classes_val)\n",
    "    \n",
    "    return(IT_list, LT_list, IV_list, LV_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "## Balancing (inner loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" \n",
    "    Input:        classData  Array of class labels\n",
    "\n",
    "    Returns:      minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "\n",
    "    Find information about class size imbalance\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize  = Minority_count\n",
    "    maxSize  = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize  = Majority_count\n",
    "        maxSize  = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:        inData          Dataframe of input data\n",
    "                  classData       Series of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "\n",
    "    Returns:      usedLines       array of indexes that are of interest for a balanced dataset\n",
    "\n",
    "    Perform the actual balancing for a fold between SNPs and PDs\n",
    "    \"\"\"\n",
    "    usedLines = [False] * len(inData)      #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData[i] == minClass:       #Balance directly with dataframe\n",
    "            usedLines[i] = True            #True lines are SNP\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedLines[i] = True\n",
    "            usedCount += 1                 #Set PD lines \"True\", until equal to number of SNP lines\n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    \"\"\"     \n",
    "    Input:      inData         Datframe of input training data\n",
    "                classData      Series of classes assigned to training data\n",
    "                usedLines      Array of line indexes to print\n",
    "\n",
    "    Returns:    input_balance  Dataframe of balanced training features\n",
    "                label_balance  Dataframe of balanced training labels\n",
    "                       \n",
    "    Create dataframe of the input training data and classes used. Index_list tracks the indicies between usedLines and inData, used to pull the required5 lines.\n",
    "    \"\"\"\n",
    "    input_balance = []\n",
    "    label_balance = []\n",
    "    index_list = []\n",
    "    \n",
    "    for i in range(len(usedLines)):\n",
    "        if usedLines[i] == True:\n",
    "            index_list.append(i)\n",
    "             \n",
    "    input_balance = inData.iloc[index_list].reset_index(inplace = False, drop = True)\n",
    "    label_balance = classData.iloc[index_list].reset_index(inplace = False, drop = True) \n",
    "    \n",
    "    return input_balance, label_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27419a33",
   "metadata": {},
   "source": [
    "### Balance for n folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_ratio(maxSize, minSize): \n",
    "    \"\"\" \n",
    "    Input:      maxSize     The number of items in the majority class\n",
    "                minSize     The number of items in the minority class\n",
    "\n",
    "    Returns:    BF          Number of balancing folds\n",
    "\n",
    "    Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "    majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "    \"\"\"\n",
    "    Divide = maxSize/minSize\n",
    "    BF = ((2 * round(Divide)) + 1)    # ratio to nearest odd integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Balance_Folds(BF, inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                inData            Datframe of input training data\n",
    "                classData         Series of classes assigned to training data\n",
    "                minClass          The label for the minority class\n",
    "                minSize           The number of items in the minority class\n",
    "                                  \n",
    "    Returns:    Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "\n",
    "    Runs balance_data() for the number of balancing folds. Return lists of balanced folds features and labels\n",
    "    where each item is the output of balance_data()\n",
    "    \"\"\"\n",
    "    Input_folds  = []\n",
    "    Output_folds = []\n",
    "\n",
    "    for i in range(BF):\n",
    "        usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "        input_balance, label_balance = balance_data(inData, classData, usedLines)\n",
    "        \n",
    "        Input_folds.append(input_balance)\n",
    "        Output_folds.append(label_balance)\n",
    "            \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd1aaa",
   "metadata": {},
   "source": [
    "### RFC hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840d9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hyperopt_space():\n",
    "    \"\"\" \n",
    "    Returns:   Space         Parameter space for hyperparameter searching\n",
    "\n",
    "    Define paramater space for Hyperopt to search throug\n",
    "   \"\"\"  \n",
    "    space = {\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators', 1250, 2000, 250)),\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 10, 15, 1)),\n",
    "        'min_samples_split': scope.int(hp.uniform('min_samples_split', 2, 6)),\n",
    "        }\n",
    "     \n",
    "    return space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, Input_folds, Output_folds, ValData, Vallabel, seed): \n",
    "    \"\"\" \n",
    "    Input:      params            Search paramaters parsed in fmin function()                     \n",
    "                Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "                \n",
    "    Returns:    loss, status      The MCC from evaluating hyperparameters during search\n",
    "\n",
    "    Define the model that Hyperopt will optimise hyperparameters for\n",
    "    \"\"\"     \n",
    "    max_depth = params['max_depth']\n",
    "    min_samples_split = params['min_samples_split']\n",
    "    n_estimators = params['n_estimators']\n",
    "    \n",
    "    RFC = RandomForestClassifier(n_estimators = n_estimators, \n",
    "                                 min_samples_split = min_samples_split, \n",
    "                                 max_depth = max_depth,\n",
    "                                 n_jobs = 4,\n",
    "                                 random_state=seed,\n",
    "                                 )                \n",
    "    #Generates and fits a RFC for each training balanced fold\n",
    "    model = RFC.fit(Input_folds, Output_folds)\n",
    "    \n",
    "    pred = model.predict(ValData)\n",
    "    MCC = matthews_corrcoef(Vallabel, pred.round())\n",
    "                                                                         \n",
    "    return {'loss': -MCC, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796af0e8",
   "metadata": {},
   "source": [
    "### Train RFC on the trainings folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_fitting(BF, Input_folds, Output_folds, fold, final_param, pickle_file, seed): \n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds                      \n",
    "                Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "\n",
    "    Returns:    BF_RFC            List of RFCs trained on each balancing fold\n",
    "\n",
    "    Create RFC model that returns probability predictions for each fold, using output of Balance_Folds() as training data\n",
    "    \"\"\"    \n",
    "    BF_RFC = []\n",
    "    \n",
    "    for i in range(BF):\n",
    "                    \n",
    "        input = Input_folds[i]\n",
    "        labels = Output_folds[i]\n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators = int(final_param[0]['n_estimators']), \n",
    "                                        min_samples_split = int(final_param[0]['min_samples_split']), \n",
    "                                        max_depth = int(final_param[0]['max_depth']),\n",
    "                                        n_jobs = -1,\n",
    "                                        random_state=seed,\n",
    "                                        ) \n",
    "        model = RandomForestClassifier(random_state=seed) \n",
    "        #Generates a RFC for each fold's training data\n",
    "        \n",
    "        model.fit(input, labels)     #Fits the RFC to each folds' training data\n",
    "        \n",
    "        filename = f\"RFC_CV_{fold + 1}_model_{i + 1}.pkl\"\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "            \n",
    "        pickle_file.append(filename)\n",
    "        BF_RFC.append(model)\n",
    "        \n",
    "    return BF_RFC, pickle_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd278c",
   "metadata": {},
   "source": [
    "#### Validate each RFC on validation set, for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_validate(BF_RFC, ValData):\n",
    "    \"\"\" \n",
    "    Input:      BF_RFC          List of RFCs trained on balancing folds\n",
    "                ValData         Unseen validation features from CV fold\n",
    "                \n",
    "    Returns:    Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "    Predicts the probabilty for every datapoint in the validation set.\n",
    "    \"\"\"\n",
    "    \n",
    "    Prob_matrix = []\n",
    "    \n",
    "    for i in range(len(BF_RFC)):\n",
    "        Prob = BF_RFC[i].predict_proba(ValData)     #Predicts the probability of an instance belonging to the major/ positive class (PD/ 1). Output has shape (n_predictions,)\n",
    "        Prob_matrix.append(Prob)   \n",
    "        \n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Vote(Prob_matrix):\n",
    "    \"\"\" \n",
    "    Input:      Prob_matrix     List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "\n",
    "    Returns:    Final_vote      Weighted vote classification\n",
    "\n",
    "    Calculate the final predictions with weighted vote using confidence scores. \n",
    "    Sc = (S0 -T)/(1-T) if S0> T\n",
    "    Sc = (T-S0)/T if S0 < T\n",
    "    \"\"\"\n",
    "    Sc_SNP = []\n",
    "    Sc_PD = []\n",
    "    \n",
    "    for i in range(len(Prob_matrix)):\n",
    "        Sc_SNP.append(Prob_matrix[i][:,0])\n",
    "        Sc_PD.append(Prob_matrix[i][:,1])\n",
    "\n",
    "    Sum_SNP   = np.sum(Sc_SNP, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD    = np.sum(Sc_PD, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "    \n",
    "    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)             #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()             #Flattens 2D array to 1D array\n",
    "\n",
    "    return(Final_vote)                          #Returns the CV votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CV_evaluation(Vallabel, Final_vote):\n",
    "    \"\"\" \n",
    "    Input:      d_val             Validation data as Dmatrix\n",
    "                Final_vote        Weighted vote classification\n",
    "                \n",
    "    Evaluates a CV fold's trained model with MCC\n",
    "    \"\"\"\n",
    "    Output_pred = Final_vote\n",
    "    TrueLabel   = Vallabel\n",
    "        \n",
    "    CV_MCC = matthews_corrcoef(TrueLabel, Output_pred)\n",
    "\n",
    "    return CV_MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_BF_predict(pickle_file, TestData):\n",
    "    \"\"\" \n",
    "    Input:      BF_RFC            List of RFCs trained on balancing folds\n",
    "                d_test            Testing data as Dmatrix\n",
    "\n",
    "                \n",
    "    Returns:    Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "    Predicts the probabilty for every datapoint in the testing set.\n",
    "    \"\"\"\n",
    "    all_prob_matrix = []\n",
    "    prefix = f\"RFC_\"\n",
    "        \n",
    "    for file in pickle_file:\n",
    "        if file.startswith(prefix):\n",
    "            with open(file, \"rb\") as f:\n",
    "                    model = pickle.load(f)\n",
    "                    Prob = model.predict_proba(TestData)     #Predicts the probability of an instance belonging to the major/ positive class (PD/ 1). Output has shape (n_predictions,)\n",
    "                    all_prob_matrix.append(Prob)  \n",
    "        \n",
    "            \n",
    "\n",
    "    return all_prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6444e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation(Prob_matrix, TestLabels):\n",
    "    \"\"\" \n",
    "    Input:      all_prob_matrix    List of all predicted probabilites from all optimised models\n",
    "                TestLabels         True labels from unseen 20% testing data\n",
    "\n",
    "    Returns:    MCC_final          Final MCC evaluation\n",
    "\n",
    "    Calculate the final predictions with weighted vote using confidence scores. \n",
    "    Evaluate votes agains true labels to give the final MCC\n",
    "    \"\"\"\n",
    "        \n",
    "    Sc_SNP = []\n",
    "    Sc_PD = []\n",
    "    \n",
    "    for i in range(len(Prob_matrix)):\n",
    "        Sc_SNP.append(Prob_matrix[i][:,0])\n",
    "        Sc_PD.append(Prob_matrix[i][:,1])\n",
    "            \n",
    "    Sum_SNP = np.sum(Sc_SNP, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(Sc_PD, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "                                                    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                    #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                    #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)                 #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()                 #Flattens 2D array to 1D array\n",
    "    \n",
    "    MCC_final = matthews_corrcoef(TestLabels, Final_vote)\n",
    "        \n",
    "    return(MCC_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632360c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model_train(BF, Input_folds, Output_folds, final_params, final_files, seed): \n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds                      \n",
    "                Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "\n",
    "    Returns:    BF_RFC            List of RFCs trained on each balancing fold  \n",
    "    \n",
    "    Retrains a final model using the best params from the best performance CV on the entire training data\n",
    "    \"\"\"\n",
    "    final_BF_RFC = []\n",
    "    for i in range(BF):\n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators = int(final_params['n_estimators']), \n",
    "                                        min_samples_split = int(final_params['min_samples_split']), \n",
    "                                        max_depth = int(final_params['max_depth']),\n",
    "                                        n_jobs = 4,\n",
    "                                        random_state=seed,\n",
    "                                        ) \n",
    "        \n",
    "        model.fit(Input_folds[i], Output_folds[i])    \n",
    "            \n",
    "        final_BF_RFC.append(model)\n",
    "        #Generates a RFC for each fold's training data\n",
    "    \n",
    "        \n",
    "        filename = f\"final_model_{i + 1}.pkll\"\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "            \n",
    "        final_files.append(filename)\n",
    "        \n",
    "    return final_BF_RFC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e232",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a9897",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# file_train                = input(\"Enter file for training: \")\n",
    "# file_test                 = input(\"Enter file for testing: \")\n",
    "file_train                  = \"STraining_Set.csv\"\n",
    "file_test                   = \"STesting_Set.csv\"\n",
    "Training_Set, Testing_Set, seed   = open_data(file_train, file_test)\n",
    "rd.seed(seed)\n",
    "\n",
    "Score_list = []\n",
    "\n",
    "# for i in range(0,15):\n",
    "pickle_file = []\n",
    "final_files = []\n",
    "CV_score = []\n",
    "final_param = []\n",
    "\n",
    "print(\"Opening dataset...\")\n",
    "TrainData, TrainLabels, TestData, TestLabels = learning_data(Training_Set, Testing_Set)   \n",
    "\n",
    "print(\"Performing Group fold cross validation...\")           \n",
    "IT_list, LT_list, IV_list, LV_list = CV(Training_Set)     \n",
    "\n",
    "for fold in range(len(IT_list)):          \n",
    "    inData                      = IT_list[fold]\n",
    "    classData                   = LT_list[fold]\n",
    "    ValData                     = IV_list[fold]\n",
    "    Vallabel                    = LV_list[fold]\n",
    "\n",
    "    print(f\"[Fold {fold + 1}] Balancing...\")\n",
    "    minClass, minSize, maxSize  = find_minority_class(classData)   \n",
    "    BF                          = Balance_ratio(maxSize, minSize)                        \n",
    "    Input_folds, Output_folds   = Balance_Folds(BF, inData, classData, minClass, minSize)\n",
    "    \n",
    "    print(f\"[Fold {fold + 1}] CV Training...\")\n",
    "\n",
    "    space                   = hyperopt_space()\n",
    "    trials                  = Trials()\n",
    "    \n",
    "    rd_fold                 = rd.randrange(BF)\n",
    "    fmin_objective          = partial(objective,\n",
    "                                        Input_folds    = Input_folds[rd_fold],\n",
    "                                        Output_folds   = Output_folds[rd_fold],\n",
    "                                        ValData        = ValData,\n",
    "                                        Vallabel       = Vallabel,\n",
    "                                        seed           = seed,\n",
    "                                    )     \n",
    "                  \n",
    "    best                    = fmin(fn = fmin_objective,\n",
    "                                    space             = space,\n",
    "                                    algo              = tpe.suggest,\n",
    "                                    max_evals         = 30,\n",
    "                                    trials            = trials,\n",
    "                                    )\n",
    "    \n",
    "    final_param.append(trials.argmin)\n",
    "    \n",
    "    BF_RFC, pickle_file                      = BF_fitting(BF, Input_folds, Output_folds, fold, final_param, pickle_file, seed)\n",
    "    Prob_matrix                              = BF_validate(BF_RFC, ValData)\n",
    "\n",
    "    Final_vote                               = Weighted_Vote(Prob_matrix)\n",
    "    CV_MCC                                   = CV_evaluation(Vallabel, Final_vote)  \n",
    "    CV_score.append(CV_MCC)\n",
    "              \n",
    "    print(f\"Fold {fold + 1} MCC:\\n{CV_MCC}\\n\")\n",
    "\n",
    "best_fold = (CV_score.index(max(CV_score)) + 1)\n",
    "final_params = final_param[(best_fold - 1)]\n",
    "\n",
    "#Testing\n",
    "print(\"Testing...\") \n",
    "Prob_matrix = final_BF_predict(pickle_file, TestData)\n",
    "MCC_final = final_evaluation(Prob_matrix, TestLabels) \n",
    "print(MCC_final) \n",
    "\n",
    "print(f\"Re-training final model...\\n\")\n",
    "inData = TrainData\n",
    "classData = TrainLabels\n",
    "ValData = TestData\n",
    "Vallabel = TestLabels\n",
    "minClass, minSize, maxSize  = find_minority_class(classData)   \n",
    "BF                          = Balance_ratio(maxSize, minSize)                        \n",
    "Input_folds, Output_folds   = Balance_Folds(BF, inData, classData, minClass, minSize)\n",
    "\n",
    "final_BF_RFC                = final_model_train(BF, Input_folds, Output_folds, final_params, final_files, seed)\n",
    "\n",
    "print(\"Testing...\") \n",
    "final_prob_matrix                 = BF_validate(final_BF_RFC, TestData)\n",
    "final_final_vote                  = Weighted_Vote(final_prob_matrix)\n",
    "final_MCC                         = CV_evaluation(TestLabels, final_final_vote)\n",
    "\n",
    "Score_list.append(final_MCC)\n",
    "#loop     \n",
    "end = time.time()\n",
    "print(f\"Final evaluation:{np.mean(Score_list)} \\u00B1 {np.std(Score_list)}\\n\\nLowest score:{min(Score_list)}\\nHighest score:{max(Score_list)}\\n\\nRun time: {end-start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e5cd67c8584618c148c6f2b57de13817422ccd98975b320089863a41752ead79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
