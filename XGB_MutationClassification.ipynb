{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d94d2bb",
   "metadata": {},
   "source": [
    "Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "    Goal is to predict if mutation is SNP or PD\n",
    "    XG Boost\n",
    "        \n",
    "    Total samples: 3368\n",
    "    2254 PD samples\n",
    "    1111 SNP samples\n",
    "    3 NA samples\n",
    "\n",
    "CV branch (best performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports the required libraries and packages \"\"\"\n",
    "\n",
    "import pandas as pd                                                              # Data manipulation in dataframes\n",
    "import numpy as np                                                               # Array manipulation\n",
    "import xgboost as xgb                                                            # Gradient boosting package\n",
    "\n",
    "import random as rd                                                              # Random seed generation\n",
    "import time                                                                      # Time program run time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,                                                           # MCC for evaluation\n",
    "    # balanced_accuracy_score, #hyperparameter evaluation\n",
    "    # f1_score,  #hyperparameter evaluation\n",
    "    confusion_matrix,                                                            # Confusion matrix for classification evalutation\n",
    "    classification_report                                                        # Return the F1, precision, and recall of a prediction\n",
    "    )\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,                                                            # Splits data frame into the training set and testing set\n",
    "    # GridSearchCV,  # Searches all hyperparameters\n",
    "    # RandomizedSearchCV, # Searches random range of hyperparameters\n",
    "    GroupKFold                                                                   # K-fold CV with as groups\n",
    "        )\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# from sklearn.ensemble import RandomForestClassifier                              # SK learn API for classificastion random forests\n",
    "\n",
    "np.set_printoptions(precision = 3,threshold=np.inf, suppress=True)               # Full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfacd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test_Split(file):\n",
    "    \"\"\"      \n",
    "    Input:      file             Pre-processed dataset done by PDB2AC script\n",
    "\n",
    "    Returns:    Training_Set     80% training set split\n",
    "                Testing_Set      20% testing set split\n",
    "                \n",
    "    80% training and 20% testing split. Splits are shuffled randomly and index reset\n",
    "    \"\"\"\n",
    "    AC_dataset                  = pd.read_csv(file, index_col=0)  \n",
    "    Training_Set                =AC_dataset\n",
    "        \n",
    "    Training_Set.reset_index(drop=True, inplace = True) #Drop index to avoid training on index values\n",
    "    \n",
    "    Training_Set                = Training_Set.sample(frac = 1) #Shuffle data after splitting\n",
    "    \n",
    "    # Training_Set, Testing_Set   = train_test_split(AC_dataset,train_size = 0.8)\n",
    "        \n",
    "    # Training_Set.reset_index(drop=True, inplace = True) #Drop index to avoid training on index values\n",
    "    # Testing_Set.reset_index(drop=True, inplace = True)  #Reset index after splitting for compatability with group fold CV\n",
    "    \n",
    "    # Training_Set                = Training_Set.sample(frac = 1) #Shuffle data after splitting\n",
    "    # Testing_Set                 = Testing_Set.sample(frac = 1)\n",
    "    \n",
    "    \n",
    "    return Training_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89126467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data(Training_Set, Testing_Set):\n",
    "#     \"\"\"      \n",
    "#     Input:      Training_Set     80% training set split\n",
    "#                 Testing_Set      20% testing set split\n",
    "\n",
    "#     Returns:    train_features   Features for training\n",
    "#                 train labels     Class lables for training\n",
    "#                 test_features    Features for testing\n",
    "#                 test_labels      Class labels for testing\n",
    "                \n",
    "#     Creates the datasets needed for GBC model training and predictions\n",
    "#     \"\"\"\n",
    "    \n",
    "#     train_features     = Training_Set.drop(['AC Code','dataset'], axis =1)      \n",
    "#     train_labels       = Training_Set['dataset']                                  \n",
    "        \n",
    "#     test_features     = Testing_Set.drop(['AC Code','dataset'], axis =1)         \n",
    "#     test_labels       = Testing_Set['dataset']                                  \n",
    "        \n",
    "#     return(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(inData, classData, ValData, Vallabel):\n",
    "#     \"\"\" \n",
    "#     Input:      inData          Features for training\n",
    "#                 classData       Class lables for training\n",
    "#                 valData         Features for testing\n",
    "#                 Vallabel        Class labels for testing\n",
    "\n",
    "#     Evaluate training data before CV and balancing. Gradient boosting for prediction on the test data. \n",
    "#     True values are testing data class labels\n",
    "#     \"\"\"    \n",
    "#     d_train = xgb.DMatrix(inData, classData)\n",
    "#     d_test = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "#     params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:hinge', \n",
    "#     }\n",
    "#     XGB_initial = xgb.train(params, d_train)\n",
    "    \n",
    "#     Output_pred = XGB_initial.predict(d_test)\n",
    "#     print(f\"              **Initial Evaluation**\")\n",
    "#     print(f\"Confusion Matrix:\\n {confusion_matrix(Vallabel, Output_pred)}\")\n",
    "#     print(f\"MCC              {matthews_corrcoef(Vallabel, Output_pred)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3a2df",
   "metadata": {},
   "source": [
    "## Group K-fold CV (outer loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975ff775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(Training_Set):\n",
    "    \"\"\"      \n",
    "    Input:      Training_Set     80% training set split\n",
    "            \n",
    "    Returns:    IT_list         List of training features for each fold\n",
    "                LT_list         List of training class labels for each fold\n",
    "                IV_list         List of validation features for each fold\n",
    "                LV_list         List of validation class labels for each fold\n",
    "\n",
    "    K-fold CV with protein groups separated between training and validation sets for each fold. Creates 5 folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    features     = Training_Set.drop(['dataset'], axis =1)         #Features for training\n",
    "    labels       = Training_Set['dataset']                         #Class labels for training\n",
    "    groups       = Training_Set['AC Code'].to_list()               #List of proteins for grouping\n",
    "    \n",
    "    IT_list = []\n",
    "    LT_list = []\n",
    "    IV_list = []\n",
    "    LV_list = []\n",
    "    \n",
    "    CV             = GroupKFold(n_splits = 5)                           #Creates 5 splits\n",
    "\n",
    "    for train_idx, val_idx in CV.split(features, labels, groups):       #Generates the indices to be used for a training and validation split. Indicies are unique to train/ val sets\n",
    "\n",
    "        Rd = np.random.randint(time.time())                                  #Random number from 1 to time since epoch\n",
    "\n",
    "        Input_train                        = features.loc[train_idx]   #New dataframe from selected indices\n",
    "        Classes_train                      = labels.loc[train_idx]\n",
    "        Input_train.drop(['AC Code'], axis = 1, inplace = True)              #Group identifer not needed for training\n",
    "\n",
    "                \n",
    "        Input_val                          = features.loc[val_idx]\n",
    "        Classes_val                        = labels.loc[val_idx]\n",
    "        Input_val.drop(['AC Code'], axis   = 1, inplace = True)\n",
    "        \n",
    "        Input_train.reset_index(drop = True, inplace = True)\n",
    "        Classes_train.reset_index(drop = True, inplace = True)\n",
    "        Input_val.reset_index(drop = True, inplace = True)\n",
    "        Classes_val.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        IT_list.append(Input_train.sample(frac=1, random_state=Rd))          #Shuffles lists, random state to ensure features and labels match for each fold\n",
    "        LT_list.append(Classes_train.sample(frac=1, random_state=Rd))\n",
    "        IV_list.append(Input_val.sample(frac=1, random_state=(Rd-1)))\n",
    "        LV_list.append(Classes_val.sample(frac=1, random_state=(Rd-1)))\n",
    "    \n",
    "    return(IT_list, LT_list, IV_list, LV_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "## Balancing (inner loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" \n",
    "    Input:        classData  Array of class labels\n",
    "\n",
    "    Returns:      minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "\n",
    "    Find information about class size imbalance\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize  = Minority_count\n",
    "    maxSize  = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize  = Majority_count\n",
    "        maxSize  = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:        inData          array of input data\n",
    "                  classData       array of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "\n",
    "    Returns:      usedLines       array of indexes that are of interest for a balanced dataset\n",
    "\n",
    "    Perform the actual balancing for a fold between SNPs and PDs\n",
    "    \"\"\"\n",
    "    usedLines = [False] * len(inData) #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData[i] == minClass:        #Balance directly with dataframe\n",
    "            usedLines[i] = True            #True lines are SNP\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedLines[i] = True\n",
    "            usedCount += 1          #Set PD lines \"True\", until equal to number of SNP lines\n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    \"\"\"     \n",
    "    Input:      inData      array of input training data\n",
    "                classData   array of classes assigned to training data\n",
    "                usedLines   array of line indexes to print\n",
    "\n",
    "    Returns:    input_balance  Dataframe of balanced training features\n",
    "                label_balance  Dataframe of balanced training labels\n",
    "                       \n",
    "    Create dataframe of the input training data and classes used. Index_list preserves the indicies between usedLines and inData, used to pull the needed lines.\n",
    "    \"\"\"\n",
    "    input_balance = []\n",
    "    label_balance = []\n",
    "    \n",
    "    # for i in range(len(inData)):\n",
    "    #     if usedLines[i] == True:\n",
    "    #         input_i = inData.iloc[i]\n",
    "    #         input_balance.append(input_i)\n",
    "            \n",
    "    #         label_i = classData.iloc[i]\n",
    "    #         label_balance.append(label_i)\n",
    "            \n",
    "    Rd = np.random.randint(time.time())\n",
    "    index_list = []\n",
    "    \n",
    "    for i in range(len(usedLines)):\n",
    "        if usedLines[i] == True:\n",
    "            index_list.append(i)\n",
    "             \n",
    "    input_balance = inData.iloc[index_list] \n",
    "    label_balance = classData.iloc[index_list]   \n",
    "    \n",
    "    input_balance = input_balance.sample(frac=1, random_state=Rd).reset_index(inplace = False, drop = True)\n",
    "    label_balance = label_balance.sample(frac=1, random_state=Rd).reset_index(inplace = False, drop = True)\n",
    "    \n",
    "    return input_balance, label_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_ratio(maxSize, minSize): \n",
    "    \"\"\" \n",
    "    Input:      maxSize     The number of items in the majority class\n",
    "                minSize     The number of items in the minority class\n",
    "\n",
    "    Returns:    BF          Number of balancing folds\n",
    "\n",
    "    Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "    majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "    \"\"\"\n",
    "    Divide = maxSize/minSize\n",
    "    BF = (2 * round(Divide)) + 1 #Double ratio to nearest integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Balance_Folds(BF, inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                inData            Features for training\n",
    "                classData         Class labels for training\n",
    "                minClass          The label for the minority class\n",
    "                minSize           The number of items in the minority class\n",
    "                                  \n",
    "    Returns:    Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "\n",
    "    Perform the balance_data() function n number of balancing fold times. Return lists for feature data and labels\n",
    "    where each item is the output of balance_data()\n",
    "    \"\"\"\n",
    "    Input_folds  = []\n",
    "    Output_folds = []\n",
    "\n",
    "    for i in range(BF):\n",
    "        usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "        input_balance, label_balance = balance_data(inData, classData, usedLines)\n",
    "        \n",
    "        Input_folds.append(input_balance)\n",
    "        Output_folds.append(label_balance)\n",
    "            \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21cd1aaa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ede39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_data(BF, Input_folds, Output_folds, ValData, Vallabel):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "                ValData           Unseen validation features from CV fold\n",
    "                ValLabel          Unseen valiadation labels from CV fold\n",
    "                                  \n",
    "    Returns:    d_train_list      List of balanced training feature folds as DMatrix\n",
    "                d_val             Validation data as Dmatrix\n",
    "\n",
    "    Converts the balanced and validation data into Dmatrix for model training and evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    d_train_list =[]\n",
    "    for i in range(BF):\n",
    "            d_train = xgb.DMatrix(Input_folds[i], Output_folds[i])      #Create DMatrix for each training balanced fold\n",
    "            d_train_list.append(d_train)\n",
    "    d_val = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "    return (d_train_list, d_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cb2003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CM(pred, d_val):\n",
    "    \"\"\" \n",
    "    Input:      pred              Prediction from a boosted tree during training\n",
    "                d_test            Validation data as Dmatrix\n",
    "\n",
    "    MCC as a custom evaluation metric for evaluating the model during training. This is different from the final weighted evaluation\n",
    "    \"\"\"\n",
    "    true_label = d_val.get_label()   \n",
    "    pred_label = np.round(pred) \n",
    "    \n",
    "    # CM = confusion_matrix(true_label, pred_label)\n",
    "    # error = (CM[0, 1] + CM[1,0])/(CM[0, 1] + CM[1,0] + CM[1, 1] + CM[0,0])\n",
    "\n",
    "    \n",
    "    return 'mcc', matthews_corrcoef(pred_label, true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0840d9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def hyperparameter(BF, d_train_list, d_val):\n",
    "#   \"\"\" Input:      BF                Number of balancing folds needed\n",
    "#                   d_train_list      List of balanced training feature folds as DMatrix\n",
    "#                   d_val             Validation data as Dmatrix\n",
    "\n",
    "#       Returns:    BF_GBC_HP         List of optimized hyperparameters for each GBC\n",
    "\n",
    "#       Use XGB in-built cross validaiton for hyperparameter turning\n",
    "#   \"\"\"  \n",
    "#   params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:logistic', \n",
    "#     # 'learning_rate': 0.3,\n",
    "#     # 'max_depth': 5,\n",
    "#     }\n",
    "#   for i in range(BF):        \n",
    "#     BF_GBC_HP = xgb.cv(\n",
    "#         params,\n",
    "#         d_train_list[i],\n",
    "#         nfold = 5,\n",
    "#         num_boost_round= 500,\n",
    "#         early_stopping_rounds= 20,\n",
    "#         custom_metric = CM, \n",
    "#         as_pandas=True,\n",
    "#     )\n",
    "  \n",
    "#   return(BF_GBC_HP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_fitting(BF, d_train_list, d_val): \n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds                      \n",
    "                d_train_list      List of balanced training feature folds in DMatrix\n",
    "                d_test            Validation data as Dmatrix\n",
    "                \n",
    "    Returns:    BF_GBC            List of gradient boosted trees trained on each balancing fold\n",
    "\n",
    "    Create GBC model that returns probability predictions for each fold, using output of Balance_Folds() as training data (as a Dmatrix)\n",
    "    \"\"\"     \n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic', \n",
    "    # 'disable_default_eval_metric': 1,\n",
    "    'verbosity': 0,\n",
    "    'eval_metric':['error'],\n",
    "    } \n",
    "    \n",
    "    BF_GBC = []\n",
    "    for fold_i in range(BF):\n",
    "        d_train = d_train_list[fold_i]                          #Dmatrix for each balanced fold\n",
    "        BF_GBC.append(xgb.train(params, \n",
    "                                d_train, \n",
    "                                num_boost_round = 250,\n",
    "                                evals  = [(d_val,'Model')],\n",
    "                                verbose_eval = False,               #Print evaluation metrics every 50 trees\n",
    "                                early_stopping_rounds = 10,\n",
    "                                # custom_metric = CM, \n",
    "                                )\n",
    "                      )                                         #Generates and fits a GBC for each training balanced fold\n",
    "        \n",
    "        \n",
    "    return BF_GBC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0dd278c",
   "metadata": {},
   "source": [
    "#### Validate each GBC on validation set, for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_validate(BF_GBC, d_val):\n",
    "    \"\"\" \n",
    "    Input:      BF_RFC            List of RFCs trained on balancing folds\n",
    "                d_test            Validation data as Dmatrix\n",
    "\n",
    "                \n",
    "    Returns:    Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "    Test the trained RFCs on the test set, then for every instance, outputs the predicted probability for each class\n",
    "    \"\"\"\n",
    "    \n",
    "    Prob_matrix = []\n",
    "    for i in range(len(BF_GBC)):\n",
    "        Prob = BF_GBC[i].predict(d_val) #Predicts the probability of an instance belonging to the major/ positive class (PD/ 1). Output has shape (n_predictions,)\n",
    "        Prob_matrix.append(Prob)   \n",
    "        \n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Vote(Prob_matrix):\n",
    "    \"\"\" \n",
    "    Input:      Prob_matrix     List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "\n",
    "    Returns:    Final_vote      Weighted vote classification\n",
    "\n",
    "    Calculate the final weighted vote using confidence scores (Sc) from Prob_matrix. Binary classification formula for:\n",
    "    Predictor states its prediction/ confidence scores are between 0.0 and 1.0 for each class\n",
    "    \"\"\"\n",
    "    PD_prob_matrix = Prob_matrix \n",
    "    \n",
    "    SNP_prob_matrix = []\n",
    "    for i in range(len(Prob_matrix)):               #SNP probabilites are 1 - (PD probabilites)\n",
    "        sub = 1 - Prob_matrix[i]\n",
    "        SNP_prob_matrix.append(sub)\n",
    "            \n",
    "    Sum_SNP = np.sum(SNP_prob_matrix, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(PD_prob_matrix, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "                                                    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)             #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()             #Flattens 2D array to 1D array\n",
    "\n",
    "    return(Final_vote, Sum_PD, Sum_SNP)         #Returns the final confidence scores\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd9d48f0",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evalutation(Vallabel, Final_vote):\n",
    "    \"\"\" \n",
    "    Input:      Vallabel           Unseen validation class labels from CV fold\n",
    "                Final_vote         Weighted vote classification\n",
    "\n",
    "    Evaluate each fold with confusion matrix and MCC\n",
    "    \"\"\"\n",
    "    Output_pred = Final_vote\n",
    "        \n",
    "    print(f\"-----------------------------------------------------\\n              ***Fold {i + 1} Evaluation***\\n\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(Vallabel, Output_pred)}\")\n",
    "    print(f\"{classification_report(Vallabel, Output_pred)}\\nMCC                  {matthews_corrcoef(Vallabel, Output_pred)})\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7de56398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_MCC(Vallabel, Final_vote):\n",
    "    \"\"\" \n",
    "    Input:      Vallabel           Unseen validation class labels from CV fold\n",
    "                Final_vote         Weighted vote classification\n",
    "\n",
    "    Return fold MCC value\n",
    "    \"\"\"\n",
    "    Output_pred = Final_vote\n",
    "    MCC = matthews_corrcoef(Vallabel, Output_pred)\n",
    "    \n",
    "    return MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53993642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(Score_list):\n",
    "     \"\"\" \n",
    "     Input:      Score_list        List of MCC scores\n",
    "\n",
    "     Plots the MCCs of n runs, and calculates the average MCC\n",
    "     \"\"\"\n",
    "     fig, ax = plt.subplots(figsize=(16,10), dpi= 65)\n",
    "     x_axis = range(len(Score_list))\n",
    "     y_axis = Score_list\n",
    "\n",
    "     plt.scatter(x_axis, y_axis, color = 'teal')\n",
    "     plt.axhline(y=np.nanmean(Score_list), color = 'red', linestyle = 'dotted', linewidth = '1', label ='Avg')\n",
    "     plt.title('MCC of 15 XG Boost runs with group 5-fold CV, default parameters')\n",
    "     plt.xlabel('Run Number')\n",
    "     plt.ylabel('MCC')\n",
    "     plt.legend()\n",
    "     plt.show()\n",
    "     print(f\"Average: {np.nanmean(Score_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e232",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a74965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[144  75]\n",
      " [ 37 417]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.66      0.72       219\n",
      "           1       0.85      0.92      0.88       454\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6086646922465697)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157  74]\n",
      " [ 26 416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.68      0.76       231\n",
      "           1       0.85      0.94      0.89       442\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.81      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6624701887747229)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[150  67]\n",
      " [ 38 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74       217\n",
      "           1       0.86      0.92      0.89       456\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6332897068409014)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[155  62]\n",
      " [ 40 416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75       217\n",
      "           1       0.87      0.91      0.89       456\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.83      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6455771455180358)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[167  60]\n",
      " [ 28 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.74      0.79       227\n",
      "           1       0.87      0.94      0.90       446\n",
      "\n",
      "    accuracy                           0.87       673\n",
      "   macro avg       0.87      0.84      0.85       673\n",
      "weighted avg       0.87      0.87      0.87       673\n",
      "\n",
      "MCC                  0.7012958650897649)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[130  65]\n",
      " [ 38 440]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72       195\n",
      "           1       0.87      0.92      0.90       478\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.82      0.79      0.81       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6154515421330802)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[168  75]\n",
      " [ 33 397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76       243\n",
      "           1       0.84      0.92      0.88       430\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6450162724879834)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157  80]\n",
      " [ 21 415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.66      0.76       237\n",
      "           1       0.84      0.95      0.89       436\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.86      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6652313247153497)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[153  45]\n",
      " [ 32 443]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80       198\n",
      "           1       0.91      0.93      0.92       475\n",
      "\n",
      "    accuracy                           0.89       673\n",
      "   macro avg       0.87      0.85      0.86       673\n",
      "weighted avg       0.88      0.89      0.88       673\n",
      "\n",
      "MCC                  0.7199357591864592)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  89]\n",
      " [ 34 401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.63      0.71       238\n",
      "           1       0.82      0.92      0.87       435\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.82      0.77      0.79       673\n",
      "weighted avg       0.82      0.82      0.81       673\n",
      "\n",
      "MCC                  0.58871147375615)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[152  65]\n",
      " [ 37 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75       217\n",
      "           1       0.87      0.92      0.89       456\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.83      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6441309187294673)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[153  77]\n",
      " [ 41 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.67      0.72       230\n",
      "           1       0.84      0.91      0.87       443\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.81      0.79      0.80       673\n",
      "weighted avg       0.82      0.82      0.82       673\n",
      "\n",
      "MCC                  0.5996516245682136)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[155  84]\n",
      " [ 31 403]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.65      0.73       239\n",
      "           1       0.83      0.93      0.88       434\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6175600584880103)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[147  63]\n",
      " [ 31 432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       210\n",
      "           1       0.87      0.93      0.90       463\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6650011091732838)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[138  77]\n",
      " [ 31 427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72       215\n",
      "           1       0.85      0.93      0.89       458\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6173586441012863)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[168  67]\n",
      " [ 46 392]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75       235\n",
      "           1       0.85      0.89      0.87       438\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.80      0.81       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.624303237692772)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[152  60]\n",
      " [ 33 428]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77       212\n",
      "           1       0.88      0.93      0.90       461\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6715061215859207)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[135  77]\n",
      " [ 38 423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.70       212\n",
      "           1       0.85      0.92      0.88       461\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.81      0.78      0.79       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.5892567117990946)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  66]\n",
      " [ 30 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.71      0.77       224\n",
      "           1       0.86      0.93      0.90       449\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.85       673\n",
      "\n",
      "MCC                  0.6706359842699124)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  70]\n",
      " [ 28 417]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76       228\n",
      "           1       0.86      0.94      0.89       445\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6668208161647973)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[163  66]\n",
      " [ 33 411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77       229\n",
      "           1       0.86      0.93      0.89       444\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.66478172783911)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[148  73]\n",
      " [ 42 410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.67      0.72       221\n",
      "           1       0.85      0.91      0.88       452\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.81      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6017447476142033)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  59]\n",
      " [ 35 421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77       217\n",
      "           1       0.88      0.92      0.90       456\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.83      0.84       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6731805742393678)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157  71]\n",
      " [ 38 407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.69      0.74       228\n",
      "           1       0.85      0.91      0.88       445\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6293320294145852)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[152  64]\n",
      " [ 41 416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.74       216\n",
      "           1       0.87      0.91      0.89       457\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.81      0.82       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6337904693538932)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[142  73]\n",
      " [ 30 428]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.73       215\n",
      "           1       0.85      0.93      0.89       458\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.80      0.81       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6360024548020361)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[161  57]\n",
      " [ 36 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78       218\n",
      "           1       0.88      0.92      0.90       455\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.83      0.84       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6781936129409288)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[164  76]\n",
      " [ 26 407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.68      0.76       240\n",
      "           1       0.84      0.94      0.89       433\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.81      0.83       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6632654456665372)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  70]\n",
      " [ 31 423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.68      0.75       219\n",
      "           1       0.86      0.93      0.89       454\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6478893537340591)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[163  56]\n",
      " [ 43 411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77       219\n",
      "           1       0.88      0.91      0.89       454\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.82      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6603734884070593)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[162  50]\n",
      " [ 29 432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80       212\n",
      "           1       0.90      0.94      0.92       461\n",
      "\n",
      "    accuracy                           0.88       673\n",
      "   macro avg       0.87      0.85      0.86       673\n",
      "weighted avg       0.88      0.88      0.88       673\n",
      "\n",
      "MCC                  0.7225160256516827)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[143  65]\n",
      " [ 33 432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.69      0.74       208\n",
      "           1       0.87      0.93      0.90       465\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6483050733875588)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[164  62]\n",
      " [ 39 408]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.76       226\n",
      "           1       0.87      0.91      0.89       447\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.82      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6569228739642954)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[159  64]\n",
      " [ 49 401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.74       223\n",
      "           1       0.86      0.89      0.88       450\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.81      0.80      0.81       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6153477143556525)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[165  77]\n",
      " [ 23 408]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.77       242\n",
      "           1       0.84      0.95      0.89       431\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.86      0.81      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6721558125184061)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  68]\n",
      " [ 24 432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.76       217\n",
      "           1       0.86      0.95      0.90       456\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.86      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6781042760015823)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  62]\n",
      " [ 36 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.75       211\n",
      "           1       0.87      0.92      0.90       462\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6528168785052619)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[168  67]\n",
      " [ 39 399]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76       235\n",
      "           1       0.86      0.91      0.88       438\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.81      0.82       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6464945399747596)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[164  64]\n",
      " [ 31 414]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78       228\n",
      "           1       0.87      0.93      0.90       445\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.82      0.84       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6777754076367076)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[154  66]\n",
      " [ 41 412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.74       220\n",
      "           1       0.86      0.91      0.89       453\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6302275614557199)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[147  57]\n",
      " [ 46 423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74       204\n",
      "           1       0.88      0.90      0.89       469\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.82      0.81      0.82       673\n",
      "weighted avg       0.84      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6326253914459652)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[150  69]\n",
      " [ 26 428]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.68      0.76       219\n",
      "           1       0.86      0.94      0.90       454\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.86      0.81      0.83       673\n",
      "weighted avg       0.86      0.86      0.85       673\n",
      "\n",
      "MCC                  0.6691782774208161)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[159  80]\n",
      " [ 31 403]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.74       239\n",
      "           1       0.83      0.93      0.88       434\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6313430149160388)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[143  66]\n",
      " [ 49 415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71       209\n",
      "           1       0.86      0.89      0.88       464\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.80      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.5929153894100287)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[177  63]\n",
      " [ 25 408]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.80       240\n",
      "           1       0.87      0.94      0.90       433\n",
      "\n",
      "    accuracy                           0.87       673\n",
      "   macro avg       0.87      0.84      0.85       673\n",
      "weighted avg       0.87      0.87      0.87       673\n",
      "\n",
      "MCC                  0.7104297361094603)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[156  69]\n",
      " [ 36 412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.69      0.75       225\n",
      "           1       0.86      0.92      0.89       448\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.81      0.82       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.640399109407383)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157  70]\n",
      " [ 40 406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74       227\n",
      "           1       0.85      0.91      0.88       446\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.82      0.80      0.81       673\n",
      "weighted avg       0.83      0.84      0.83       673\n",
      "\n",
      "MCC                  0.625460309535872)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[166  74]\n",
      " [ 32 401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76       240\n",
      "           1       0.84      0.93      0.88       433\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6493704612980294)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  68]\n",
      " [ 29 427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.75       217\n",
      "           1       0.86      0.94      0.90       456\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.81      0.83       673\n",
      "weighted avg       0.85      0.86      0.85       673\n",
      "\n",
      "MCC                  0.6602603784906982)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[148  54]\n",
      " [ 30 441]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.78       202\n",
      "           1       0.89      0.94      0.91       471\n",
      "\n",
      "    accuracy                           0.88       673\n",
      "   macro avg       0.86      0.83      0.85       673\n",
      "weighted avg       0.87      0.88      0.87       673\n",
      "\n",
      "MCC                  0.6951619976147183)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[146  64]\n",
      " [ 30 433]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       210\n",
      "           1       0.87      0.94      0.90       463\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.664678503903067)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[159  65]\n",
      " [ 39 410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75       224\n",
      "           1       0.86      0.91      0.89       449\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.83      0.81      0.82       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6442125108212327)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[167  69]\n",
      " [ 38 399]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76       236\n",
      "           1       0.85      0.91      0.88       437\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.81      0.82       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6435140522180899)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[171  63]\n",
      " [ 39 400]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       234\n",
      "           1       0.86      0.91      0.89       439\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.82      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.659824396599281)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[127  80]\n",
      " [ 31 435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.61      0.70       207\n",
      "           1       0.84      0.93      0.89       466\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.82      0.77      0.79       673\n",
      "weighted avg       0.83      0.84      0.83       673\n",
      "\n",
      "MCC                  0.5955738946716467)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[137  65]\n",
      " [ 42 429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72       202\n",
      "           1       0.87      0.91      0.89       471\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6110056791467877)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[172  76]\n",
      " [ 25 400]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77       248\n",
      "           1       0.84      0.94      0.89       425\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.86      0.82      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.672928966192573)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[140  69]\n",
      " [ 42 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72       209\n",
      "           1       0.86      0.91      0.88       464\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.81      0.79      0.80       673\n",
      "weighted avg       0.83      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6035157689341162)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[155  69]\n",
      " [ 27 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76       224\n",
      "           1       0.86      0.94      0.90       449\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.86      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.85       673\n",
      "\n",
      "MCC                  0.6703034165033785)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[168  60]\n",
      " [ 34 411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78       228\n",
      "           1       0.87      0.92      0.90       445\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.83      0.84       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6820136838532939)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[156  71]\n",
      " [ 28 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76       227\n",
      "           1       0.85      0.94      0.89       446\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.81      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.662385462723756)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[174  60]\n",
      " [ 33 406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.79       234\n",
      "           1       0.87      0.92      0.90       439\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.86      0.83      0.84       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.689780288533047)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[151  59]\n",
      " [ 35 428]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76       210\n",
      "           1       0.88      0.92      0.90       463\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6666478304941393)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[146  62]\n",
      " [ 29 436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       208\n",
      "           1       0.88      0.94      0.91       465\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6737581546387976)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[160  72]\n",
      " [ 43 398]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74       232\n",
      "           1       0.85      0.90      0.87       441\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.80      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6131937345681785)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[159  60]\n",
      " [ 35 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77       219\n",
      "           1       0.87      0.92      0.90       454\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6712471956455981)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[168  71]\n",
      " [ 29 405]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77       239\n",
      "           1       0.85      0.93      0.89       434\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6690190568226361)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[155  68]\n",
      " [ 35 415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.75       223\n",
      "           1       0.86      0.92      0.89       450\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6455014215387759)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  62]\n",
      " [ 35 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77       220\n",
      "           1       0.87      0.92      0.90       453\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.84      0.82      0.83       673\n",
      "weighted avg       0.85      0.86      0.85       673\n",
      "\n",
      "MCC                  0.6647592655787841)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[144  66]\n",
      " [ 28 435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.75       210\n",
      "           1       0.87      0.94      0.90       463\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.81      0.83       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6641454508552245)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[156  69]\n",
      " [ 30 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76       225\n",
      "           1       0.86      0.93      0.89       448\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.81      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6607536974081091)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157  61]\n",
      " [ 36 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76       218\n",
      "           1       0.87      0.92      0.90       455\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.84      0.82      0.83       673\n",
      "weighted avg       0.85      0.86      0.85       673\n",
      "\n",
      "MCC                  0.6633383671089917)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[156  66]\n",
      " [ 41 410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.74       222\n",
      "           1       0.86      0.91      0.88       451\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.81      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6321688708752198)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[151  60]\n",
      " [ 37 425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76       211\n",
      "           1       0.88      0.92      0.90       462\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.84      0.82      0.83       673\n",
      "weighted avg       0.85      0.86      0.85       673\n",
      "\n",
      "MCC                  0.657149757473642)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[152  83]\n",
      " [ 30 408]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73       235\n",
      "           1       0.83      0.93      0.88       438\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6206678837922336)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1040x650 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.6500042752177972\n"
     ]
    }
   ],
   "source": [
    "Score_list = []\n",
    "for i in range(0,15):\n",
    "    file = \"AC_dataset.csv\"\n",
    "    Training_Set                     = Train_Test_Split(file)                                 #Create training and testing sets\n",
    "    # test(inData, classData, ValData, Vallabel)                                                          #Initial evaluation\n",
    "    IT_list, LT_list, IV_list, LV_list = CV(Training_Set)                #Cross-validate training set        \n",
    "\n",
    "    K_fold_score = []\n",
    "    for i in range(len(IT_list)):          \n",
    "        inData = IT_list[i]\n",
    "        classData = LT_list[i]\n",
    "        ValData = IV_list[i]\n",
    "        Vallabel = LV_list[i]\n",
    "\n",
    "        minClass, minSize, maxSize  = find_minority_class(classData)                            #Determines imbalance\n",
    "        BF                          = Balance_ratio(maxSize, minSize)                           #Determins number of balancing folds needed\n",
    "        Input_folds, Output_folds   = Balance_Folds(BF, inData, classData, minClass, minSize)   # balance() and balance_data() functions are called under this\n",
    "        d_train_list, d_val         = model_training_data(BF, Input_folds, Output_folds, ValData, Vallabel)\n",
    "        # BF_GBC_HP                   = hyperparameter(BF, d_train_list, d_val)\n",
    "        BF_GBC                      = BF_fitting(BF, d_train_list, d_val)\n",
    "        Prob_matrix                 = BF_validate(BF_GBC, d_val)\n",
    "\n",
    "        Final_vote, Sum_PD, Sum_SNP = Weighted_Vote(Prob_matrix)\n",
    "        \n",
    "        evalutation(Vallabel, Final_vote)\n",
    "        MCC = fold_MCC(Final_vote, Vallabel)\n",
    "\n",
    "        K_fold_score.append(MCC)\n",
    "\n",
    "    run_score = np.nanmean(K_fold_score)\n",
    "    Score_list.append(run_score)  \n",
    "\n",
    "plot(Score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9ddc247",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"(improved_param)Final_MCCs.txt\", Score_list, fmt = '%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b20dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e5cd67c8584618c148c6f2b57de13817422ccd98975b320089863a41752ead79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
