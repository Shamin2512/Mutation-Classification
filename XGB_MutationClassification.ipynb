{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d94d2bb",
   "metadata": {},
   "source": [
    "Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "    Goal is to predict if mutation is SNP or PD\n",
    "    XG Boost\n",
    "        \n",
    "    Total samples: 3368\n",
    "    2254 PD samples\n",
    "    1111 SNP samples\n",
    "    3 NA samples\n",
    "\n",
    "CV branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports the required libraries and packages \"\"\"\n",
    "\n",
    "import pandas as pd                                                              # Data manipulation in dataframes\n",
    "import numpy as np                                                               # Array manipulation\n",
    "import xgboost as xgb                                                            # Gradient boosting package\n",
    "\n",
    "import random as rd                                                              # Random seed generation\n",
    "import time                                                                      # Time program run time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,                                                           # MCC for evaluation\n",
    "    # balanced_accuracy_score, #hyperparameter evaluation\n",
    "    # f1_score,  #hyperparameter evaluation\n",
    "    confusion_matrix,                                                            # Confusion matrix for classification evalutation\n",
    "    classification_report                                                        # Return the F1, precision, and recall of a prediction\n",
    "    )\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,                                                            # Splits data frame into the training set and testing set\n",
    "    # GridSearchCV,  # Searches all hyperparameters\n",
    "    # RandomizedSearchCV, # Searches random range of hyperparameters\n",
    "    GroupKFold                                                                   # K-fold CV with as groups\n",
    "        )\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# from sklearn.ensemble import RandomForestClassifier                              # SK learn API for classificastion random forests\n",
    "\n",
    "np.set_printoptions(precision = 3,threshold=np.inf, suppress=True)               # Full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfacd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test_Split(file):\n",
    "    \"\"\"      \n",
    "    Input:      file             Pre-processed dataset done by PDB2AC script\n",
    "\n",
    "    Returns:    Training_Set     80% training set split\n",
    "                Testing_Set      20% testing set split\n",
    "                \n",
    "    80% training and 20% testing split. Splits are shuffled randomly and index reset\n",
    "    \"\"\"\n",
    "    AC_dataset                  = pd.read_csv(file, index_col=0)  \n",
    "    Training_Set, Testing_Set   = train_test_split(AC_dataset,train_size = 0.8)\n",
    "        \n",
    "    Training_Set.reset_index(drop=True, inplace = True) #Drop index to avoid training on index values\n",
    "    Testing_Set.reset_index(drop=True, inplace = True)  #Reset index after splitting for compatability with group fold CV\n",
    "    \n",
    "    Training_Set                = Training_Set.sample(frac = 1) #Shuffle data after splitting\n",
    "    Testing_Set                 = Testing_Set.sample(frac = 1)\n",
    "    \n",
    "    \n",
    "    return Training_Set, Testing_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89126467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data(Training_Set, Testing_Set):\n",
    "#     \"\"\"      \n",
    "#     Input:      Training_Set     80% training set split\n",
    "#                 Testing_Set      20% testing set split\n",
    "\n",
    "#     Returns:    train_features   Features for training\n",
    "#                 train labels     Class lables for training\n",
    "#                 test_features    Features for testing\n",
    "#                 test_labels      Class labels for testing\n",
    "                \n",
    "#     Creates the datasets needed for GBC model training and predictions\n",
    "#     \"\"\"\n",
    "    \n",
    "#     train_features     = Training_Set.drop(['AC Code','dataset'], axis =1)      \n",
    "#     train_labels       = Training_Set['dataset']                                  \n",
    "        \n",
    "#     test_features     = Testing_Set.drop(['AC Code','dataset'], axis =1)         \n",
    "#     test_labels       = Testing_Set['dataset']                                  \n",
    "        \n",
    "#     return(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(inData, classData, ValData, Vallabel):\n",
    "#     \"\"\" \n",
    "#     Input:      inData          Features for training\n",
    "#                 classData       Class lables for training\n",
    "#                 valData         Features for testing\n",
    "#                 Vallabel        Class labels for testing\n",
    "\n",
    "#     Evaluate training data before CV and balancing. Gradient boosting for prediction on the test data. \n",
    "#     True values are testing data class labels\n",
    "#     \"\"\"    \n",
    "#     d_train = xgb.DMatrix(inData, classData)\n",
    "#     d_test = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "#     params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:hinge', \n",
    "#     }\n",
    "#     XGB_initial = xgb.train(params, d_train)\n",
    "    \n",
    "#     Output_pred = XGB_initial.predict(d_test)\n",
    "#     print(f\"              **Initial Evaluation**\")\n",
    "#     print(f\"Confusion Matrix:\\n {confusion_matrix(Vallabel, Output_pred)}\")\n",
    "#     print(f\"MCC              {matthews_corrcoef(Vallabel, Output_pred)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3a2df",
   "metadata": {},
   "source": [
    "## Group K-fold CV (outer loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975ff775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(Training_Set):\n",
    "    \"\"\"      \n",
    "    Input:      Training_Set     80% training set split\n",
    "            \n",
    "    Returns:    IT_list         List of training features for each fold\n",
    "                LT_list         List of training class labels for each fold\n",
    "                IV_list         List of validation features for each fold\n",
    "                LV_list         List of validation class labels for each fold\n",
    "\n",
    "    K-fold CV with protein groups separated between training and validation sets for each fold. Creates 5 folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    features     = Training_Set.drop(['dataset'], axis =1)         #Features for training\n",
    "    labels       = Training_Set['dataset']                         #Class labels for training\n",
    "    groups       = Training_Set['AC Code'].to_list()               #List of proteins for grouping\n",
    "    \n",
    "    IT_list = []\n",
    "    LT_list = []\n",
    "    IV_list = []\n",
    "    LV_list = []\n",
    "    \n",
    "    CV             = GroupKFold(n_splits = 5)                           #Creates 5 splits\n",
    "\n",
    "    for train_idx, val_idx in CV.split(features, labels, groups):       #Generates the indices to be used for a training and validation split. Indicies are unique to train/ val sets\n",
    "\n",
    "        Rd = np.random.randint(time.time())                                  #Random number from 1 to time since epoch\n",
    "\n",
    "        Input_train                        = features.loc[train_idx]   #New dataframe from selected indices\n",
    "        Classes_train                      = labels.loc[train_idx]\n",
    "        Input_train.drop(['AC Code'], axis = 1, inplace = True)              #Group identifer not needed for training\n",
    "\n",
    "                \n",
    "        Input_val                          = features.loc[val_idx]\n",
    "        Classes_val                        = labels.loc[val_idx]\n",
    "        Input_val.drop(['AC Code'], axis   = 1, inplace = True)\n",
    "        \n",
    "        Input_train.reset_index(drop = True, inplace = True)\n",
    "        Classes_train.reset_index(drop = True, inplace = True)\n",
    "        Input_val.reset_index(drop = True, inplace = True)\n",
    "        Classes_val.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        IT_list.append(Input_train.sample(frac=1, random_state=Rd))          #Shuffles lists, random state to ensure features and labels match for each fold\n",
    "        LT_list.append(Classes_train.sample(frac=1, random_state=Rd))\n",
    "        IV_list.append(Input_val.sample(frac=1, random_state=(Rd-1)))\n",
    "        LV_list.append(Classes_val.sample(frac=1, random_state=(Rd-1)))\n",
    "    \n",
    "    return(IT_list, LT_list, IV_list, LV_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "## Balancing (inner loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" \n",
    "    Input:        classData  Array of class labels\n",
    "\n",
    "    Returns:      minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "\n",
    "    Find information about class size imbalance\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize  = Minority_count\n",
    "    maxSize  = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize  = Majority_count\n",
    "        maxSize  = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:        inData          array of input data\n",
    "                  classData       array of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "\n",
    "    Returns:      usedLines       array of indexes that are of interest for a balanced dataset\n",
    "\n",
    "    Perform the actual balancing for a fold between SNPs and PDs\n",
    "    \"\"\"\n",
    "    usedLines = [False] * len(inData) #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData[i] == minClass:        #Balance directly with dataframe\n",
    "            usedLines[i] = True            #True lines are SNP\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedLines[i] = True\n",
    "            usedCount += 1          #Set PD lines \"True\", until equal to number of SNP lines\n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    \"\"\"     \n",
    "    Input:      inData      array of input training data\n",
    "                classData   array of classes assigned to training data\n",
    "                usedLines   array of line indexes to print\n",
    "\n",
    "    Returns:    input_balance  Dataframe of balanced training features\n",
    "                label_balance  Dataframe of balanced training labels\n",
    "                       \n",
    "    Create dataframe of the input training data and classes used. Index_list preserves the indicies between usedLines and inData, used to pull the needed lines.\n",
    "    \"\"\"\n",
    "    Rd = np.random.randint(time.time())\n",
    "    index_list = []\n",
    "    \n",
    "    for i in range(len(usedLines)):\n",
    "        if usedLines[i] == True:\n",
    "            index_list.append(i)\n",
    "             \n",
    "    input_balance = inData.iloc[index_list] \n",
    "    label_balance = classData.iloc[index_list]   \n",
    "    \n",
    "    input_balance = input_balance.sample(frac=1, random_state=Rd).reset_index(inplace = False, drop = True)\n",
    "    label_balance = label_balance.sample(frac=1, random_state=Rd).reset_index(inplace = False, drop = True)\n",
    "    \n",
    "    return input_balance, label_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_ratio(maxSize, minSize): \n",
    "    \"\"\" \n",
    "    Input:      maxSize     The number of items in the majority class\n",
    "                minSize     The number of items in the minority class\n",
    "\n",
    "    Returns:    BF          Number of balancing folds\n",
    "\n",
    "    Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "    majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "    \"\"\"\n",
    "    Divide = maxSize/minSize\n",
    "    BF = (2 * round(Divide)) + 1 #Double ratio to nearest integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Balance_Folds(BF, inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                inData            Features for training\n",
    "                classData         Class labels for training\n",
    "                minClass          The label for the minority class\n",
    "                minSize           The number of items in the minority class\n",
    "                                  \n",
    "    Returns:    Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "\n",
    "    Perform the balance_data() function n number of balancing fold times. Return lists for feature data and labels\n",
    "    where each item is the output of balance_data()\n",
    "    \"\"\"\n",
    "    Input_folds  = []\n",
    "    Output_folds = []\n",
    "\n",
    "    for i in range(BF):\n",
    "        usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "        input_balance, label_balance = balance_data(inData, classData, usedLines)\n",
    "        \n",
    "        Input_folds.append(input_balance)\n",
    "        Output_folds.append(label_balance)\n",
    "            \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21cd1aaa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ede39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_data(BF, Input_folds, Output_folds, ValData, Vallabel):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "                ValData           Unseen validation features from CV fold\n",
    "                ValLabel          Unseen valiadation labels from CV fold\n",
    "                                  \n",
    "    Returns:    d_train_list      List of balanced training feature folds as DMatrix\n",
    "                d_val             Validation data as Dmatrix\n",
    "\n",
    "    Converts the balanced and validation data into Dmatrix for model training and evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    d_train_list =[]\n",
    "    for i in range(BF):\n",
    "            d_train = xgb.DMatrix(Input_folds[i], Output_folds[i])      #Create DMatrix for each training balanced fold\n",
    "            d_train_list.append(d_train)\n",
    "    d_val = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "    return (d_train_list, d_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb2003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CM(pred, d_val):\n",
    "    \"\"\" \n",
    "    Input:      pred              Prediction from a boosted tree during training\n",
    "                d_test            Validation data as Dmatrix\n",
    "\n",
    "    MCC as a custom evaluation metric for evaluating the model during training. This is different from the final weighted evaluation\n",
    "    \"\"\"\n",
    "    true_label = d_val.get_label()   \n",
    "    pred_label = np.round(pred) \n",
    "    \n",
    "    # CM = confusion_matrix(true_label, pred_label)\n",
    "    # error = (CM[0, 1] + CM[1,0])/(CM[0, 1] + CM[1,0] + CM[1, 1] + CM[0,0])\n",
    "\n",
    "    \n",
    "    return 'mcc', matthews_corrcoef(pred_label, true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0840d9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hyperparameter(BF, d_train_list, d_val):\n",
    "  \"\"\" Input:      BF                Number of balancing folds needed\n",
    "                  d_train_list      List of balanced training feature folds as DMatrix\n",
    "                  d_val             Validation data as Dmatrix\n",
    "\n",
    "      Returns:    BF_GBC_HP         List of optimized hyperparameters for each GBC\n",
    "\n",
    "      Use XGB in-built cross validaiton for hyperparameter turning\n",
    "  \"\"\"  \n",
    "  params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic', \n",
    "    'learning_rate': 0.3,\n",
    "    'max_depth': 5\n",
    "    }\n",
    "  for i in range(BF):        \n",
    "    BF_GBC_HP = xgb.cv(\n",
    "        params,\n",
    "        d_train_list[i],\n",
    "        nfold = 5,\n",
    "        num_boost_round= 500,\n",
    "        early_stopping_rounds= 20,\n",
    "        custom_metric = CM, \n",
    "        as_pandas=True,\n",
    "    )\n",
    "  \n",
    "  return(BF_GBC_HP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_fitting(BF, d_train_list, d_val): \n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds                      \n",
    "                d_train_list      List of balanced training feature folds in DMatrix\n",
    "                d_test            Validation data as Dmatrix\n",
    "                \n",
    "    Returns:    BF_GBC            List of gradient boosted trees trained on each balancing fold\n",
    "\n",
    "    Create GBC model that returns probability predictions for each fold, using output of Balance_Folds() as training data (as a Dmatrix)\n",
    "    \"\"\"     \n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic', \n",
    "    'disable_default_eval_metric': 1,\n",
    "    'verbosity': 1,\n",
    "    # 'eval_metric':['error'],\n",
    "    } \n",
    "    \n",
    "    BF_GBC = []\n",
    "    for fold_i in range(BF):\n",
    "        d_train = d_train_list[fold_i]                          #Dmatrix for each balanced fold\n",
    "        BF_GBC.append(xgb.train(params, \n",
    "                                d_train, \n",
    "                                num_boost_round = 500,\n",
    "                                evals  = [(d_val,'Model')],\n",
    "                                verbose_eval = 50,               #Print evaluation metrics every 50 trees\n",
    "                                early_stopping_rounds = 20,\n",
    "                                custom_metric = CM, \n",
    "                                )\n",
    "                      )                                         #Generates and fits a GBC for each training balanced fold\n",
    "        \n",
    "        \n",
    "    return BF_GBC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0dd278c",
   "metadata": {},
   "source": [
    "#### Validate each GBC on validation set, for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_validate(BF_GBC, d_val):\n",
    "    \"\"\" \n",
    "    Input:      BF_RFC            List of RFCs trained on balancing folds\n",
    "                d_test            Validation data as Dmatrix\n",
    "\n",
    "                \n",
    "    Returns:    Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "    Test the trained RFCs on the test set, then for every instance, outputs the predicted probability for each class\n",
    "    \"\"\"\n",
    "    \n",
    "    Prob_matrix = []\n",
    "    for i in range(len(BF_GBC)):\n",
    "        Prob = BF_GBC[i].predict(d_test) #Predicts the probability of an instance belonging to the major/ positive class (PD/ 1). Output has shape (n_predictions,)\n",
    "        Prob_matrix.append(Prob)   \n",
    "        \n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Vote(Prob_matrix):\n",
    "    \"\"\" \n",
    "    Input:      Prob_matrix     List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "\n",
    "    Returns:    Final_vote      Weighted vote classification\n",
    "\n",
    "    Calculate the final weighted vote using confidence scores (Sc) from Prob_matrix. Binary classification formula for:\n",
    "    Predictor states its prediction/ confidence scores are between 0.0 and 1.0 for each class\n",
    "    \"\"\"\n",
    "    PD_prob_matrix = Prob_matrix \n",
    "    \n",
    "    SNP_prob_matrix = []\n",
    "    for i in range(len(Prob_matrix)):               #SNP probabilites are 1 - (PD probabilites)\n",
    "        sub = 1 - Prob_matrix[i]\n",
    "        SNP_prob_matrix.append(sub)\n",
    "            \n",
    "    Sum_SNP = np.sum(SNP_prob_matrix, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(PD_prob_matrix, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "                                                    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)             #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()             #Flattens 2D array to 1D array\n",
    "\n",
    "    return(Final_vote, Sum_PD, Sum_SNP)         #Returns the final confidence scores\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd9d48f0",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evalutation(Final_vote, Vallabel):\n",
    "    \"\"\" \n",
    "    Input:      Final Vote      Weighted vote classification\n",
    "                ValLabel        Unseen 20% testing data labels\n",
    "\n",
    "    Evaluate each fold with confusion matrix and MCC\n",
    "    \"\"\"\n",
    "\n",
    "    Output_pred = Final_vote\n",
    "    MCC = matthews_corrcoef(Vallabel, Output_pred)\n",
    "    print(f\"-----------------------------------------------------\\n              ***Fold Evaluation***\\n\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(Vallabel, Output_pred)}\")\n",
    "    print(f\"{classification_report(Vallabel, Output_pred)}\\nMCC                           {MCC}\\n\")\n",
    "    \n",
    "    return MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53993642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(Score_list):\n",
    "     \"\"\" \n",
    "     Input:      Score_list        List of MCC scores\n",
    "\n",
    "     Plots the MCCs of n runs, and calculates the average MCC\n",
    "     \"\"\"\n",
    "     fig, ax = plt.subplots(figsize=(16,10), dpi= 65)\n",
    "     x_axis = range(len(Score_list))\n",
    "     y_axis = Score_list\n",
    "\n",
    "     plt.scatter(x_axis, y_axis, color = 'teal')\n",
    "     plt.axhline(y=np.nanmean(Score_list), color = 'red', linestyle = 'dotted', linewidth = '1', label ='Avg')\n",
    "     plt.title('MCC of 15 XG Boost runs, group CV')\n",
    "     plt.xlabel('Run Number')\n",
    "     plt.ylabel('MCC')\n",
    "     plt.legend()\n",
    "     plt.show()\n",
    "     print(f\"Average: {np.nanmean(Score_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e232",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a74965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tModel-mcc:0.30842\n",
      "[10]\tModel-mcc:0.45064\n",
      "[0]\tModel-mcc:0.28201\n",
      "[10]\tModel-mcc:0.44348\n",
      "[0]\tModel-mcc:0.28042\n",
      "[10]\tModel-mcc:0.52147\n",
      "[0]\tModel-mcc:0.35474\n",
      "[10]\tModel-mcc:0.49432\n",
      "[0]\tModel-mcc:0.39559\n",
      "[9]\tModel-mcc:0.49745\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[118  69]\n",
      " [ 37 315]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.63      0.69       187\n",
      "           1       0.82      0.89      0.86       352\n",
      "\n",
      "    accuracy                           0.80       539\n",
      "   macro avg       0.79      0.76      0.77       539\n",
      "weighted avg       0.80      0.80      0.80       539\n",
      "\n",
      "MCC                           0.5530518275660484\n",
      "\n",
      "[0]\tModel-mcc:0.29986\n",
      "[10]\tModel-mcc:0.49173\n",
      "[0]\tModel-mcc:0.34712\n",
      "[11]\tModel-mcc:0.46469\n",
      "[0]\tModel-mcc:0.32912\n",
      "[10]\tModel-mcc:0.51041\n",
      "[0]\tModel-mcc:0.32370\n",
      "[10]\tModel-mcc:0.53846\n",
      "[0]\tModel-mcc:0.26100\n",
      "[10]\tModel-mcc:0.50209\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[102  75]\n",
      " [ 26 336]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.58      0.67       177\n",
      "           1       0.82      0.93      0.87       362\n",
      "\n",
      "    accuracy                           0.81       539\n",
      "   macro avg       0.81      0.75      0.77       539\n",
      "weighted avg       0.81      0.81      0.80       539\n",
      "\n",
      "MCC                           0.5567130627254657\n",
      "\n",
      "[0]\tModel-mcc:0.31173\n",
      "[9]\tModel-mcc:0.51592\n",
      "[0]\tModel-mcc:0.38481\n",
      "[9]\tModel-mcc:0.45137\n",
      "[0]\tModel-mcc:0.33350\n",
      "[10]\tModel-mcc:0.53660\n",
      "[0]\tModel-mcc:0.35586\n",
      "[10]\tModel-mcc:0.54799\n",
      "[0]\tModel-mcc:0.33880\n",
      "[10]\tModel-mcc:0.51975\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[112  64]\n",
      " [ 41 321]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68       176\n",
      "           1       0.83      0.89      0.86       362\n",
      "\n",
      "    accuracy                           0.80       538\n",
      "   macro avg       0.78      0.76      0.77       538\n",
      "weighted avg       0.80      0.80      0.80       538\n",
      "\n",
      "MCC                           0.5440296294159189\n",
      "\n",
      "[0]\tModel-mcc:0.32213\n",
      "[9]\tModel-mcc:0.51587\n",
      "[0]\tModel-mcc:0.34255\n",
      "[9]\tModel-mcc:0.47334\n",
      "[0]\tModel-mcc:0.29596\n",
      "[9]\tModel-mcc:0.48236\n",
      "[0]\tModel-mcc:0.36564\n",
      "[9]\tModel-mcc:0.51232\n",
      "[0]\tModel-mcc:0.32095\n",
      "[9]\tModel-mcc:0.46366\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[114  68]\n",
      " [ 46 310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67       182\n",
      "           1       0.82      0.87      0.84       356\n",
      "\n",
      "    accuracy                           0.79       538\n",
      "   macro avg       0.77      0.75      0.76       538\n",
      "weighted avg       0.78      0.79      0.78       538\n",
      "\n",
      "MCC                           0.5145778714710155\n",
      "\n",
      "[0]\tModel-mcc:0.45758\n",
      "[9]\tModel-mcc:0.53539\n",
      "[0]\tModel-mcc:0.34332\n",
      "[10]\tModel-mcc:0.54695\n",
      "[0]\tModel-mcc:0.34945\n",
      "[9]\tModel-mcc:0.57167\n",
      "[0]\tModel-mcc:0.38717\n",
      "[10]\tModel-mcc:0.49445\n",
      "[0]\tModel-mcc:0.40024\n",
      "[9]\tModel-mcc:0.51753\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[113  75]\n",
      " [ 26 324]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.60      0.69       188\n",
      "           1       0.81      0.93      0.87       350\n",
      "\n",
      "    accuracy                           0.81       538\n",
      "   macro avg       0.81      0.76      0.78       538\n",
      "weighted avg       0.81      0.81      0.80       538\n",
      "\n",
      "MCC                           0.5737818720951249\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1040x650 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.5484308526547147\n"
     ]
    }
   ],
   "source": [
    "file = \"AC_dataset.csv\"\n",
    "Score_list = []\n",
    "Training_Set, Testing_Set          = Train_Test_Split(file)                                 #Create training and testing sets\n",
    "# test(inData, classData, ValData, Vallabel)                                                          #Initial evaluation\n",
    "IT_list, LT_list, IV_list, LV_list = CV(Training_Set)                #Cross-validate training set        \n",
    "\n",
    "for i in range(len(IT_list)):          \n",
    "    inData = IT_list[i]\n",
    "    classData = LT_list[i]\n",
    "    ValData = IV_list[i]\n",
    "    Vallabel = LV_list[i]\n",
    "\n",
    "    minClass, minSize, maxSize  = find_minority_class(classData)                            #Determines imbalance\n",
    "    BF                          = Balance_ratio(maxSize, minSize)                           #Determins number of balancing folds needed\n",
    "    Input_folds, Output_folds   = Balance_Folds(BF, inData, classData, minClass, minSize)   # balance() and balance_data() functions are called under this\n",
    "    d_train_list, d_test        = model_training_data(BF, Input_folds, Output_folds, ValData, Vallabel)\n",
    "    BF_GBC_HP                   = hyperparameter(BF, d_train_list, d_val)\n",
    "    BF_GBC                      = BF_fitting(BF, d_train_list, d_test)\n",
    "    Prob_matrix                 = BF_validate(BF_GBC, d_test)\n",
    "\n",
    "    Final_vote, Sum_PD, Sum_SNP = Weighted_Vote(Prob_matrix)\n",
    "\n",
    "    MCC = evalutation(Final_vote, Vallabel)\n",
    "    Score_list.append(MCC)  \n",
    "        \n",
    "plot(Score_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e5cd67c8584618c148c6f2b57de13817422ccd98975b320089863a41752ead79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
