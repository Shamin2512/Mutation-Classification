{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d94d2bb",
   "metadata": {},
   "source": [
    "Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "    Goal is to predict if mutation is SNP or PD\n",
    "    XG Boost\n",
    "        \n",
    "    Total samples: 3368\n",
    "    2254 PD samples\n",
    "    1111 SNP samples\n",
    "    3 NA samples\n",
    "\n",
    "CV branch (best performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports the required libraries and packages \"\"\"\n",
    "\n",
    "import pandas as pd                                                              # Data manipulation in dataframes\n",
    "import numpy as np                                                               # Array manipulation\n",
    "import xgboost as xgb                                                            # Gradient boosting package\n",
    "\n",
    "import random as rd                                                              # Random seed generation\n",
    "import time                                                                      # Time program run time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,                                                           # MCC for evaluation\n",
    "    # balanced_accuracy_score, #hyperparameter evaluation\n",
    "    # f1_score,  #hyperparameter evaluation\n",
    "    confusion_matrix,                                                            # Confusion matrix for classification evalutation\n",
    "    classification_report                                                        # Return the F1, precision, and recall of a prediction\n",
    "    )\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,                                                            # Splits data frame into the training set and testing set\n",
    "    # GridSearchCV,  # Searches all hyperparameters\n",
    "    # RandomizedSearchCV, # Searches random range of hyperparameters\n",
    "    GroupKFold                                                                   # K-fold CV with as groups\n",
    "        )\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# from sklearn.ensemble import RandomForestClassifier                              # SK learn API for classificastion random forests\n",
    "\n",
    "np.set_printoptions(precision = 3,threshold=np.inf, suppress=True)               # Full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfacd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test_Split(file):\n",
    "    \"\"\"      \n",
    "    Input:      file             Pre-processed dataset done by PDB2AC script\n",
    "\n",
    "    Returns:    Training_Set     80% training set split\n",
    "                Testing_Set      20% testing set split\n",
    "                \n",
    "    80% training and 20% testing split. Splits are shuffled randomly and index reset\n",
    "    \"\"\"\n",
    "    AC_dataset                  = pd.read_csv(file, index_col=0)  \n",
    "    Training_Set                = AC_dataset\n",
    "        \n",
    "    Training_Set, Testing_Set   = train_test_split(AC_dataset,train_size = 0.8)\n",
    "        \n",
    "    Training_Set.reset_index(drop=True, inplace = True) #Drop index to avoid training on index values\n",
    "    Testing_Set.reset_index(drop=True, inplace = True)  #Reset index after splitting for compatability with group fold CV\n",
    "    \n",
    "    Training_Set                = Training_Set.sample(frac = 1) #Shuffle data after splitting\n",
    "    Testing_Set                 = Testing_Set.sample(frac = 1)\n",
    "    \n",
    "    \n",
    "    return Training_Set, Testing_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466d455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_matrix(Testing_Set):\n",
    "    TestData     = Testing_Set.drop(['AC Code','dataset'], axis =1)         #Features for testing\n",
    "    TestLabels   = Testing_Set['dataset']     #Class labels for testing\n",
    "    \n",
    "    d_test = xgb.DMatrix(TestData, TestLabels)\n",
    "\n",
    "    return (d_test, TestData, TestLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89126467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data(Training_Set, Testing_Set):\n",
    "#     \"\"\"      \n",
    "#     Input:      Training_Set     80% training set split\n",
    "#                 Testing_Set      20% testing set split\n",
    "\n",
    "#     Returns:    train_features   Features for training\n",
    "#                 train labels     Class lables for training\n",
    "#                 test_features    Features for testing\n",
    "#                 test_labels      Class labels for testing\n",
    "                \n",
    "#     Creates the datasets needed for GBC model training and predictions\n",
    "#     \"\"\"\n",
    "    \n",
    "#     train_features     = Training_Set.drop(['AC Code','dataset'], axis =1)      \n",
    "#     train_labels       = Training_Set['dataset']                                  \n",
    "        \n",
    "#     test_features     = Testing_Set.drop(['AC Code','dataset'], axis =1)         \n",
    "#     test_labels       = Testing_Set['dataset']                                  \n",
    "        \n",
    "#     return(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(inData, classData, ValData, Vallabel):\n",
    "#     \"\"\" \n",
    "#     Input:      inData          Features for training\n",
    "#                 classData       Class lables for training\n",
    "#                 valData         Features for testing\n",
    "#                 Vallabel        Class labels for testing\n",
    "\n",
    "#     Evaluate training data before CV and balancing. Gradient boosting for prediction on the test data. \n",
    "#     True values are testing data class labels\n",
    "#     \"\"\"    \n",
    "#     d_train = xgb.DMatrix(inData, classData)\n",
    "#     d_test = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "#     params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:hinge', \n",
    "#     }\n",
    "#     XGB_initial = xgb.train(params, d_train)\n",
    "    \n",
    "#     Output_pred = XGB_initial.predict(d_test)\n",
    "#     print(f\"              **Initial Evaluation**\")\n",
    "#     print(f\"Confusion Matrix:\\n {confusion_matrix(Vallabel, Output_pred)}\")\n",
    "#     print(f\"MCC              {matthews_corrcoef(Vallabel, Output_pred)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3a2df",
   "metadata": {},
   "source": [
    "## Group K-fold CV (outer loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975ff775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(Training_Set):\n",
    "    \"\"\"      \n",
    "    Input:      Training_Set     80% training set split\n",
    "            \n",
    "    Returns:    IT_list         List of training features for each fold\n",
    "                LT_list         List of training class labels for each fold\n",
    "                IV_list         List of validation features for each fold\n",
    "                LV_list         List of validation class labels for each fold\n",
    "\n",
    "    K-fold CV with protein groups separated between training and validation sets for each fold. Creates 5 folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    features     = Training_Set.drop(['dataset'], axis =1)         #Features for training\n",
    "    labels       = Training_Set['dataset']                         #Class labels for training\n",
    "    groups       = Training_Set['AC Code'].to_list()               #List of proteins for grouping\n",
    "    \n",
    "    IT_list = []\n",
    "    LT_list = []\n",
    "    IV_list = []\n",
    "    LV_list = []\n",
    "    \n",
    "    CV             = GroupKFold(n_splits = 5)                           #Creates 5 splits\n",
    "\n",
    "    for train_idx, val_idx in CV.split(features, labels, groups):       #Generates the indices to be used for a training and validation split. Indicies are unique to train/ val sets\n",
    "\n",
    "        Rd = np.random.randint(time.time())                                  #Random number from 1 to time since epoch\n",
    "\n",
    "        Input_train                        = features.loc[train_idx]   #New dataframe from selected indices\n",
    "        Classes_train                      = labels.loc[train_idx]\n",
    "        Input_train.drop(['AC Code'], axis = 1, inplace = True)              #Group identifer not needed for training\n",
    "\n",
    "                \n",
    "        Input_val                          = features.loc[val_idx]\n",
    "        Classes_val                        = labels.loc[val_idx]\n",
    "        Input_val.drop(['AC Code'], axis   = 1, inplace = True)\n",
    "        \n",
    "        Input_train.reset_index(drop = True, inplace = True)\n",
    "        Classes_train.reset_index(drop = True, inplace = True)\n",
    "        Input_val.reset_index(drop = True, inplace = True)\n",
    "        Classes_val.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        IT_list.append(Input_train.sample(frac=1, random_state=Rd))          #Shuffles lists, random state to ensure features and labels match for each fold\n",
    "        LT_list.append(Classes_train.sample(frac=1, random_state=Rd))\n",
    "        IV_list.append(Input_val.sample(frac=1, random_state=(Rd-1)))\n",
    "        LV_list.append(Classes_val.sample(frac=1, random_state=(Rd-1)))\n",
    "    \n",
    "    return(IT_list, LT_list, IV_list, LV_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "## Balancing (inner loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" \n",
    "    Input:        classData  Array of class labels\n",
    "\n",
    "    Returns:      minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "\n",
    "    Find information about class size imbalance\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize  = Minority_count\n",
    "    maxSize  = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize  = Majority_count\n",
    "        maxSize  = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:        inData          array of input data\n",
    "                  classData       array of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "\n",
    "    Returns:      usedLines       array of indexes that are of interest for a balanced dataset\n",
    "\n",
    "    Perform the actual balancing for a fold between SNPs and PDs\n",
    "    \"\"\"\n",
    "    usedLines = [False] * len(inData) #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData[i] == minClass:        #Balance directly with dataframe\n",
    "            usedLines[i] = True            #True lines are SNP\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedLines[i] = True\n",
    "            usedCount += 1          #Set PD lines \"True\", until equal to number of SNP lines\n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    \"\"\"     \n",
    "    Input:      inData      array of input training data\n",
    "                classData   array of classes assigned to training data\n",
    "                usedLines   array of line indexes to print\n",
    "\n",
    "    Returns:    input_balance  Dataframe of balanced training features\n",
    "                label_balance  Dataframe of balanced training labels\n",
    "                       \n",
    "    Create dataframe of the input training data and classes used. Index_list preserves the indicies between usedLines and inData, used to pull the needed lines.\n",
    "    \"\"\"\n",
    "    input_balance = []\n",
    "    label_balance = []\n",
    "    \n",
    "    # for i in range(len(inData)):\n",
    "    #     if usedLines[i] == True:\n",
    "    #         input_i = inData.iloc[i]\n",
    "    #         input_balance.append(input_i)\n",
    "            \n",
    "    #         label_i = classData.iloc[i]\n",
    "    #         label_balance.append(label_i)\n",
    "            \n",
    "    Rd = np.random.randint(time.time())\n",
    "    index_list = []\n",
    "    \n",
    "    for i in range(len(usedLines)):\n",
    "        if usedLines[i] == True:\n",
    "            index_list.append(i)\n",
    "             \n",
    "    input_balance = inData.iloc[index_list] \n",
    "    label_balance = classData.iloc[index_list]   \n",
    "    \n",
    "    input_balance = input_balance.sample(frac=1, random_state=Rd).reset_index(inplace = False, drop = True)\n",
    "    label_balance = label_balance.sample(frac=1, random_state=Rd).reset_index(inplace = False, drop = True)\n",
    "    \n",
    "    return input_balance, label_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_ratio(maxSize, minSize): \n",
    "    \"\"\" \n",
    "    Input:      maxSize     The number of items in the majority class\n",
    "                minSize     The number of items in the minority class\n",
    "\n",
    "    Returns:    BF          Number of balancing folds\n",
    "\n",
    "    Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "    majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "    \"\"\"\n",
    "    Divide = maxSize/minSize\n",
    "    BF = (2 * round(Divide)) + 1 #Double ratio to nearest integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Balance_Folds(BF, inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                inData            Features for training\n",
    "                classData         Class labels for training\n",
    "                minClass          The label for the minority class\n",
    "                minSize           The number of items in the minority class\n",
    "                                  \n",
    "    Returns:    Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "\n",
    "    Perform the balance_data() function n number of balancing fold times. Return lists for feature data and labels\n",
    "    where each item is the output of balance_data()\n",
    "    \"\"\"\n",
    "    Input_folds  = []\n",
    "    Output_folds = []\n",
    "\n",
    "    for i in range(BF):\n",
    "        usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "        input_balance, label_balance = balance_data(inData, classData, usedLines)\n",
    "        \n",
    "        Input_folds.append(input_balance)\n",
    "        Output_folds.append(label_balance)\n",
    "            \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21cd1aaa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ede39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_data(BF, Input_folds, Output_folds, ValData, Vallabel):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "                ValData           Unseen validation features from CV fold\n",
    "                ValLabel          Unseen valiadation labels from CV fold\n",
    "                                  \n",
    "    Returns:    d_train_list      List of balanced training feature folds as DMatrix\n",
    "                d_val             Validation data as Dmatrix\n",
    "\n",
    "    Converts the balanced and validation data into Dmatrix for model training and evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    d_train_list =[]\n",
    "    for i in range(BF):\n",
    "            d_train = xgb.DMatrix(Input_folds[i], Output_folds[i])      #Create DMatrix for each training balanced fold\n",
    "            d_train_list.append(d_train)\n",
    "    d_val = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "    return (d_train_list, d_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb2003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CM(pred, d_val):\n",
    "    \"\"\" \n",
    "    Input:      pred              Prediction from a boosted tree during training\n",
    "                d_test            Validation data as Dmatrix\n",
    "\n",
    "    MCC as a custom evaluation metric for evaluating the model during training. This is different from the final weighted evaluation\n",
    "    \"\"\"\n",
    "    true_label = d_val.get_label()   \n",
    "    pred_label = np.round(pred) \n",
    "    \n",
    "    # CM = confusion_matrix(true_label, pred_label)\n",
    "    # error = (CM[0, 1] + CM[1,0])/(CM[0, 1] + CM[1,0] + CM[1, 1] + CM[0,0])\n",
    "\n",
    "    \n",
    "    return 'mcc', matthews_corrcoef(pred_label, true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0840d9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def hyperparameter(BF, d_train_list, d_val):\n",
    "#   \"\"\" Input:      BF                Number of balancing folds needed\n",
    "#                   d_train_list      List of balanced training feature folds as DMatrix\n",
    "#                   d_val             Validation data as Dmatrix\n",
    "\n",
    "#       Returns:    BF_GBC_HP         List of optimized hyperparameters for each GBC\n",
    "\n",
    "#       Use XGB in-built cross validaiton for hyperparameter turning\n",
    "#   \"\"\"  \n",
    "#   params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:logistic', \n",
    "#     # 'learning_rate': 0.3,\n",
    "#     # 'max_depth': 5,\n",
    "#     }\n",
    "#   for i in range(BF):        \n",
    "#     BF_GBC_HP = xgb.cv(\n",
    "#         params,\n",
    "#         d_train_list[i],\n",
    "#         nfold = 5,\n",
    "#         num_boost_round= 500,\n",
    "#         early_stopping_rounds= 20,\n",
    "#         custom_metric = CM, \n",
    "#         as_pandas=True,\n",
    "#     )\n",
    "  \n",
    "#   return(BF_GBC_HP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_fitting(BF, d_train_list, d_val): \n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds                      \n",
    "                d_train_list      List of balanced training feature folds in DMatrix\n",
    "                d_test            Validation data as Dmatrix\n",
    "                \n",
    "    Returns:    BF_GBC            List of gradient boosted trees trained on each balancing fold\n",
    "\n",
    "    Create GBC model that returns probability predictions for each fold, using output of Balance_Folds() as training data (as a Dmatrix)\n",
    "    \"\"\"     \n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic', \n",
    "    'disable_default_eval_metric': 1,\n",
    "    'verbosity': 0,\n",
    "    # 'eval_metric':['MCC'],\n",
    "    } \n",
    "    \n",
    "    BF_GBC = []\n",
    "    for fold_i in range(BF):\n",
    "        d_train = d_train_list[fold_i]                          #Dmatrix for each balanced fold\n",
    "        BF_GBC.append(xgb.train(params, \n",
    "                                d_train, \n",
    "                                num_boost_round = 250,\n",
    "                                evals  = [(d_val,'Model')],\n",
    "                                verbose_eval = False,               #Print evaluation metrics every 50 trees\n",
    "                                early_stopping_rounds = 50,\n",
    "                                custom_metric = CM, \n",
    "                                )\n",
    "                      )                                         #Generates and fits a GBC for each training balanced fold\n",
    "        \n",
    "        \n",
    "    return BF_GBC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0dd278c",
   "metadata": {},
   "source": [
    "#### Test each GBC on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_validate(BF_GBC, d_test):\n",
    "    \"\"\" \n",
    "    Input:      BF_RFC            List of RFCs trained on balancing folds\n",
    "                d_test            Testing data as Dmatrix\n",
    "\n",
    "                \n",
    "    Returns:    Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "    Test the trained RFCs on the test set, then for every instance, outputs the predicted probability for each class\n",
    "    \"\"\"\n",
    "    \n",
    "    Prob_matrix = []\n",
    "    for i in range(len(BF_GBC)):\n",
    "        Prob = BF_GBC[i].predict(d_test) #Predicts the probability of an instance belonging to the major/ positive class (PD/ 1). Output has shape (n_predictions,)\n",
    "        Prob_matrix.append(Prob)   \n",
    "        \n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Vote(Prob_matrix):\n",
    "    \"\"\" \n",
    "    Input:      Prob_matrix     List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "\n",
    "    Returns:    Final_vote      Weighted vote classification\n",
    "\n",
    "    Calculate the final weighted vote using confidence scores (Sc) from Prob_matrix. Binary classification formula for:\n",
    "    Predictor states its prediction/ confidence scores are between 0.0 and 1.0 for each class\n",
    "    \"\"\"\n",
    "    PD_prob_matrix = Prob_matrix \n",
    "    \n",
    "    SNP_prob_matrix = []\n",
    "    for i in range(len(Prob_matrix)):               #SNP probabilites are 1 - (PD probabilites)\n",
    "        sub = 1 - Prob_matrix[i]\n",
    "        SNP_prob_matrix.append(sub)\n",
    "            \n",
    "    Sum_SNP = np.sum(SNP_prob_matrix, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(PD_prob_matrix, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "                                                    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)             #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()             #Flattens 2D array to 1D array\n",
    "\n",
    "    return(Final_vote, Sum_PD, Sum_SNP)         #Returns the final confidence scores\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd9d48f0",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evalutation(TestLabels, Final_vote):\n",
    "    \"\"\" \n",
    "    Input:      Vallabel           Unseen validation class labels from CV fold\n",
    "                Final_vote         Weighted vote classification\n",
    "\n",
    "    Evaluate each fold with confusion matrix and MCC\n",
    "    \"\"\"\n",
    "    Output_pred = Final_vote\n",
    "        \n",
    "    print(f\"-----------------------------------------------------\\n              ***Fold {i + 1} Evaluation***\\n\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(TestLabels, Output_pred)}\")\n",
    "    print(f\"{classification_report(TestLabels, Output_pred)}\\nMCC                  {matthews_corrcoef(TestLabels, Output_pred)})\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7de56398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_MCC(TestLabels, Final_vote):\n",
    "    \"\"\" \n",
    "    Input:      Vallabel           Unseen validation class labels from CV fold\n",
    "                Final_vote         Weighted vote classification\n",
    "\n",
    "    Return fold MCC value\n",
    "    \"\"\"\n",
    "    Output_pred = Final_vote\n",
    "    MCC = matthews_corrcoef(TestLabels, Output_pred)\n",
    "    \n",
    "    return MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5ce9bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation(all_prob_matrix, TestLabels):\n",
    "    \n",
    "    flat_list = [matrix for proba in all_prob_matrix for matrix in proba]\n",
    "    \n",
    "    PD_prob_matrix = flat_list \n",
    "\n",
    "    SNP_prob_matrix = []\n",
    "    for i in range(len(flat_list)):               #SNP probabilites are 1 - (PD probabilites)\n",
    "        sub = 1 - flat_list[i]\n",
    "        SNP_prob_matrix.append(sub)\n",
    "            \n",
    "    Sum_SNP = np.sum(SNP_prob_matrix, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(PD_prob_matrix, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "                                                    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)             #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()             #Flattens 2D array to 1D array\n",
    "    \n",
    "    MCC_final = matthews_corrcoef(TestLabels, Final_vote)\n",
    "    # print(f\"\\n\\n\\nFinal MCC: {MCC_final}\")\n",
    "    \n",
    "    return(MCC_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53993642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(Score_list):\n",
    "     \"\"\" \n",
    "     Input:      Score_list        List of MCC scores\n",
    "\n",
    "     Plots the MCCs of n runs, and calculates the average MCC\n",
    "     \"\"\"\n",
    "     fig, ax = plt.subplots(figsize=(16,10), dpi= 65)\n",
    "     x_axis = range(len(Score_list))\n",
    "     y_axis = Score_list\n",
    "\n",
    "     plt.scatter(x_axis, y_axis, color = 'teal')\n",
    "     plt.axhline(y=np.nanmean(Score_list), color = 'red', linestyle = 'dotted', linewidth = '1', label ='Avg')\n",
    "     plt.title('MCC of 15 XG Boost runs with group 5-fold CV, default parameters')\n",
    "     plt.xlabel('Run Number')\n",
    "     plt.ylabel('MCC')\n",
    "     plt.legend()\n",
    "     plt.show()\n",
    "     print(f\"Average: {np.nanmean(Score_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e232",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a74965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[153  65]\n",
      " [ 33 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76       218\n",
      "           1       0.87      0.93      0.90       455\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.81      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6585303935934596)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[140  78]\n",
      " [ 38 417]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71       218\n",
      "           1       0.84      0.92      0.88       455\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.81      0.78      0.79       673\n",
      "weighted avg       0.82      0.83      0.82       673\n",
      "\n",
      "MCC                  0.5927732934216844)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[154  64]\n",
      " [ 43 412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74       218\n",
      "           1       0.87      0.91      0.89       455\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.82      0.81      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.629346087285193)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[151  67]\n",
      " [ 37 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74       218\n",
      "           1       0.86      0.92      0.89       455\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.83      0.81      0.82       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6376293386705776)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[145  73]\n",
      " [ 37 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.72       218\n",
      "           1       0.85      0.92      0.88       455\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6150857706614695)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[155  81]\n",
      " [ 27 410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.66      0.74       236\n",
      "           1       0.84      0.94      0.88       437\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6391950805222174)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  78]\n",
      " [ 32 405]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.67      0.74       236\n",
      "           1       0.84      0.93      0.88       437\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6320998069543965)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[166  70]\n",
      " [ 32 405]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.76       236\n",
      "           1       0.85      0.93      0.89       437\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6598882829565568)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[162  74]\n",
      " [ 30 407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76       236\n",
      "           1       0.85      0.93      0.89       437\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6528523905012317)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[151  85]\n",
      " [ 27 410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.64      0.73       236\n",
      "           1       0.83      0.94      0.88       437\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.84      0.79      0.80       673\n",
      "weighted avg       0.84      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6253832249379406)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[153  73]\n",
      " [ 36 411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74       226\n",
      "           1       0.85      0.92      0.88       447\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6268036643654334)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  77]\n",
      " [ 38 409]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.66      0.72       226\n",
      "           1       0.84      0.91      0.88       447\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.605471042927512)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[153  73]\n",
      " [ 40 407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73       226\n",
      "           1       0.85      0.91      0.88       447\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6135087857389613)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[146  80]\n",
      " [ 42 405]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71       226\n",
      "           1       0.84      0.91      0.87       447\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.81      0.78      0.79       673\n",
      "weighted avg       0.82      0.82      0.81       673\n",
      "\n",
      "MCC                  0.5810892877864006)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[156  70]\n",
      " [ 35 412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75       226\n",
      "           1       0.85      0.92      0.89       447\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6410543727094832)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[152  75]\n",
      " [ 38 408]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73       227\n",
      "           1       0.84      0.91      0.88       446\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6138206367323371)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  69]\n",
      " [ 37 409]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75       227\n",
      "           1       0.86      0.92      0.89       446\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.81      0.82       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6389445006349502)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[162  65]\n",
      " [ 47 399]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74       227\n",
      "           1       0.86      0.89      0.88       446\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.80      0.81       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6215103285413117)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[169  58]\n",
      " [ 39 407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.78       227\n",
      "           1       0.88      0.91      0.89       446\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.84      0.83      0.84       673\n",
      "weighted avg       0.85      0.86      0.85       673\n",
      "\n",
      "MCC                  0.6722336797863548)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[162  65]\n",
      " [ 44 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75       227\n",
      "           1       0.86      0.90      0.88       446\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.82      0.81      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6309059293930147)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[152  73]\n",
      " [ 44 404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.72       225\n",
      "           1       0.85      0.90      0.87       448\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.81      0.79      0.80       673\n",
      "weighted avg       0.82      0.83      0.82       673\n",
      "\n",
      "MCC                  0.5994813048724444)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[150  75]\n",
      " [ 29 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.74       225\n",
      "           1       0.85      0.94      0.89       448\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.80      0.82       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6426722220623431)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[156  69]\n",
      " [ 44 404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.69      0.73       225\n",
      "           1       0.85      0.90      0.88       448\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.80      0.81       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6143113629253071)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  76]\n",
      " [ 42 406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.72       225\n",
      "           1       0.84      0.91      0.87       448\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.81      0.78      0.79       673\n",
      "weighted avg       0.82      0.82      0.82       673\n",
      "\n",
      "MCC                  0.5948388310876066)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[145  80]\n",
      " [ 35 413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.64      0.72       225\n",
      "           1       0.84      0.92      0.88       448\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.78      0.80       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6035760897183415)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[138  89]\n",
      " [ 21 425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.61      0.72       227\n",
      "           1       0.83      0.95      0.89       446\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.85      0.78      0.80       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6242270111316354)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[137  90]\n",
      " [ 22 424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.60      0.71       227\n",
      "           1       0.82      0.95      0.88       446\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.84      0.78      0.80       673\n",
      "weighted avg       0.84      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6168283253301949)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[145  82]\n",
      " [ 30 416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72       227\n",
      "           1       0.84      0.93      0.88       446\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6159768288282277)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[147  80]\n",
      " [ 30 416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.65      0.73       227\n",
      "           1       0.84      0.93      0.88       446\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.79      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6231818925673865)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  78]\n",
      " [ 27 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.66      0.74       227\n",
      "           1       0.84      0.94      0.89       446\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6410360362615652)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[151  65]\n",
      " [ 39 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.74       216\n",
      "           1       0.87      0.91      0.89       457\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.83      0.81      0.82       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.636524953477547)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[140  76]\n",
      " [ 31 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.72       216\n",
      "           1       0.85      0.93      0.89       457\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.79      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6222980594346407)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[142  74]\n",
      " [ 30 427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.73       216\n",
      "           1       0.85      0.93      0.89       457\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.80      0.81       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6333574513610918)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[145  71]\n",
      " [ 31 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74       216\n",
      "           1       0.86      0.93      0.89       457\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.80      0.82       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6410631388617006)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  67]\n",
      " [ 31 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75       216\n",
      "           1       0.86      0.93      0.90       457\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6559979213289481)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[124  71]\n",
      " [ 31 447]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.64      0.71       195\n",
      "           1       0.86      0.94      0.90       478\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6152760440693384)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[120  75]\n",
      " [ 30 448]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.62      0.70       195\n",
      "           1       0.86      0.94      0.90       478\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.78      0.80       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6023706761515527)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[130  65]\n",
      " [ 29 449]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.73       195\n",
      "           1       0.87      0.94      0.91       478\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.80      0.82       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6471750373519558)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[125  70]\n",
      " [ 32 446]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.64      0.71       195\n",
      "           1       0.86      0.93      0.90       478\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6157848785112958)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[128  67]\n",
      " [ 41 437]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.66      0.70       195\n",
      "           1       0.87      0.91      0.89       478\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.81      0.79      0.80       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.5969417449544018)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[145  83]\n",
      " [ 34 411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.64      0.71       228\n",
      "           1       0.83      0.92      0.88       445\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.78      0.79       673\n",
      "weighted avg       0.82      0.83      0.82       673\n",
      "\n",
      "MCC                  0.5993830052164655)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[143  85]\n",
      " [ 33 412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.63      0.71       228\n",
      "           1       0.83      0.93      0.87       445\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.82      0.78      0.79       673\n",
      "weighted avg       0.82      0.82      0.82       673\n",
      "\n",
      "MCC                  0.595615582747183)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[148  80]\n",
      " [ 31 414]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.65      0.73       228\n",
      "           1       0.84      0.93      0.88       445\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.83      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6206986708943766)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[150  78]\n",
      " [ 27 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.66      0.74       228\n",
      "           1       0.84      0.94      0.89       445\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.85      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6420291136505065)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[137  91]\n",
      " [ 27 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.60      0.70       228\n",
      "           1       0.82      0.94      0.88       445\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.83      0.77      0.79       673\n",
      "weighted avg       0.83      0.82      0.82       673\n",
      "\n",
      "MCC                  0.595557412222964)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[138  77]\n",
      " [ 36 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71       215\n",
      "           1       0.85      0.92      0.88       458\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.78      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.5998384782155965)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[138  77]\n",
      " [ 31 427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72       215\n",
      "           1       0.85      0.93      0.89       458\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6173586441012863)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[136  79]\n",
      " [ 38 420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.63      0.70       215\n",
      "           1       0.84      0.92      0.88       458\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.81      0.77      0.79       673\n",
      "weighted avg       0.82      0.83      0.82       673\n",
      "\n",
      "MCC                  0.5852816018331107)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[150  65]\n",
      " [ 31 427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       215\n",
      "           1       0.87      0.93      0.90       458\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.81      0.83       673\n",
      "weighted avg       0.86      0.86      0.85       673\n",
      "\n",
      "MCC                  0.6624650619954542)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[129  86]\n",
      " [ 36 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.60      0.68       215\n",
      "           1       0.83      0.92      0.87       458\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.81      0.76      0.78       673\n",
      "weighted avg       0.82      0.82      0.81       673\n",
      "\n",
      "MCC                  0.5651282077450807)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[140  74]\n",
      " [ 39 420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71       214\n",
      "           1       0.85      0.92      0.88       459\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.78      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.5999531566631755)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[133  81]\n",
      " [ 38 421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.62      0.69       214\n",
      "           1       0.84      0.92      0.88       459\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.81      0.77      0.78       673\n",
      "weighted avg       0.82      0.82      0.82       673\n",
      "\n",
      "MCC                  0.5762562613133758)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[143  71]\n",
      " [ 35 424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73       214\n",
      "           1       0.86      0.92      0.89       459\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6250308921237097)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[136  78]\n",
      " [ 39 420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.70       214\n",
      "           1       0.84      0.92      0.88       459\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.81      0.78      0.79       673\n",
      "weighted avg       0.82      0.83      0.82       673\n",
      "\n",
      "MCC                  0.584485439023384)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[139  75]\n",
      " [ 37 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.71       214\n",
      "           1       0.85      0.92      0.88       459\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.78      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6028814965468248)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[151  75]\n",
      " [ 36 411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.67      0.73       226\n",
      "           1       0.85      0.92      0.88       447\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.79      0.81       673\n",
      "weighted avg       0.83      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6195185138191853)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[146  80]\n",
      " [ 41 406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.65      0.71       226\n",
      "           1       0.84      0.91      0.87       447\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.81      0.78      0.79       673\n",
      "weighted avg       0.82      0.82      0.82       673\n",
      "\n",
      "MCC                  0.5843998365900019)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157  69]\n",
      " [ 33 414]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75       226\n",
      "           1       0.86      0.93      0.89       447\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6514103085290933)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[152  74]\n",
      " [ 33 414]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74       226\n",
      "           1       0.85      0.93      0.89       447\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6333606954247798)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[152  74]\n",
      " [ 43 404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.67      0.72       226\n",
      "           1       0.85      0.90      0.87       447\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.81      0.79      0.80       673\n",
      "weighted avg       0.82      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6000365715066966)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[154  82]\n",
      " [ 37 400]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.65      0.72       236\n",
      "           1       0.83      0.92      0.87       437\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.82      0.78      0.80       673\n",
      "weighted avg       0.82      0.82      0.82       673\n",
      "\n",
      "MCC                  0.6010472859802868)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  87]\n",
      " [ 33 404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.63      0.71       236\n",
      "           1       0.82      0.92      0.87       437\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.82      0.78      0.79       673\n",
      "weighted avg       0.82      0.82      0.82       673\n",
      "\n",
      "MCC                  0.5971327671550627)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[153  83]\n",
      " [ 32 405]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.65      0.73       236\n",
      "           1       0.83      0.93      0.88       437\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6146503119164775)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[150  86]\n",
      " [ 31 406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72       236\n",
      "           1       0.83      0.93      0.87       437\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.78      0.80       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6076563817628381)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  78]\n",
      " [ 37 400]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.67      0.73       236\n",
      "           1       0.84      0.92      0.87       437\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6151629312816693)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[145  96]\n",
      " [ 33 399]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.60      0.69       241\n",
      "           1       0.81      0.92      0.86       432\n",
      "\n",
      "    accuracy                           0.81       673\n",
      "   macro avg       0.81      0.76      0.78       673\n",
      "weighted avg       0.81      0.81      0.80       673\n",
      "\n",
      "MCC                  0.5709802735637345)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[152  89]\n",
      " [ 23 409]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.63      0.73       241\n",
      "           1       0.82      0.95      0.88       432\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.84      0.79      0.81       673\n",
      "weighted avg       0.84      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6311638334260569)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[153  88]\n",
      " [ 24 408]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.63      0.73       241\n",
      "           1       0.82      0.94      0.88       432\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.84      0.79      0.81       673\n",
      "weighted avg       0.84      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6308496467134777)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[154  87]\n",
      " [ 31 401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72       241\n",
      "           1       0.82      0.93      0.87       432\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.83      0.78      0.80       673\n",
      "weighted avg       0.83      0.82      0.82       673\n",
      "\n",
      "MCC                  0.609151351129997)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[146  95]\n",
      " [ 23 409]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.61      0.71       241\n",
      "           1       0.81      0.95      0.87       432\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.84      0.78      0.79       673\n",
      "weighted avg       0.83      0.82      0.82       673\n",
      "\n",
      "MCC                  0.6109108096245852)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[151  89]\n",
      " [ 27 406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.63      0.72       240\n",
      "           1       0.82      0.94      0.88       433\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.78      0.80       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6155668797909443)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[155  85]\n",
      " [ 30 403]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73       240\n",
      "           1       0.83      0.93      0.88       433\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6185719457094554)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157  83]\n",
      " [ 31 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73       240\n",
      "           1       0.83      0.93      0.88       433\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6219424888883774)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[160  80]\n",
      " [ 29 404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.67      0.75       240\n",
      "           1       0.83      0.93      0.88       433\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6391816414899992)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[160  80]\n",
      " [ 34 399]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74       240\n",
      "           1       0.83      0.92      0.88       433\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.79      0.81       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6219638666897976)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAAIqCAYAAAA99zvrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAAn/AAAJ/wEHzD5GAABE6UlEQVR4nO3deVxWdf7//ydeKvJBTWhsMaE0KzcEzEsKZHG/mtJsMU0lmU/qMEY1S5ZWtlrqfGamNKfMr1MMajVmtieN4FJGJi5IWWaZBEoLKpIikuL798f5cSUKivmWC/Rxv9262XXe5zrX65zzvpYn55z38TPGGAEAAAAArGnk6wIAAAAA4ExD0AIAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBlBC0AtXLJJZeobdu2Onz4sHfa3Llz5efnp9TUVO+01atXq0+fPmrfvr3cbrf69++vNWvWSJKMMfr73/+uTp06qWvXroqMjNT48eO1f//+k6rlueeeU8eOHRUREaGff/65SltmZqbcbrf8/f01ceLEKm1JSUkKCQlRRESEIiIi9MQTT1S7/AULFigqKkoVFRWSpH379ql9+/b68MMPvevx1FNPqUuXLurcubMiIyM1ZMgQ5ebm1rjtOnXqpIiICHXq1EnJyck6dOjQSa1zbeTk5GjRokXWl3u6vPXWW959dHTteXl5uuCCC3xV2q+2YsUKBQYGevtYVFRUjfN+9dVXioyMVGRk5An3m5+fnw4cOHDM9AMHDsjPz6/G59X0fkxOTtbkyZOPmT8sLEzvv//+cWs52uzZs5WUlHTC+U5mfWuyYsUKXXXVVZKcPjJ37txftZz6pKG9bwHUHkELQK2dd955ysjI8D5OTU1V9+7dvY83btyoQYMGadKkSfrmm2+UnZ2tWbNm6YcffpAk3X///XrzzTe1cuVKffbZZ1q3bp169eqlvXv3nlQdM2fO1Msvv6ycnBw1bdq0Slu7du00Z84cTZgwodrnPvDAA8rJyVFOTo4eeOCBaucZOXKkzj//fP3973+XJE2YMEGDBg1SbGysdz3eeOMNZWZm6vPPP9eGDRuUkpKiL7/8ssaaX3/9deXk5Oizzz5Tbm6u3nzzzZNa59o4mR9spyPonazBgwdr2rRpkurmx2ZdrXNYWJi3j33yySc1zrd48WLFxcVpw4YNuvnmm63Xcbz34+9+9zulpaXpyDu8rF27VsXFxerfv7/1WiT761sXQasu+syv7fvGmCp/+AJQDxkAqIWLL77YzJgxw9x6663GGGO2bNliYmJizLBhw8yLL75ojDFmxIgRZuLEidU+f+/evcbf399s3ry5Vq/31VdfmT59+piwsDATGRlplixZYowx5pZbbjFNmjQxHTt2NElJSTU+/+GHHzb33XdflWmjR482zz33XK1ef8eOHeaCCy4wzz77rOnQoYMpLS2tsh5btmyp1XKMcbbdF198YYwxZt++fSYyMtJkZGR4l5eUlGS6dOliunTpYqZPn37CbVBaWmpuvvlm06lTJ9OtWzdz6623mp07d5qQkBDTqlUrEx4ebu65555j6hg9erQZM2aMiYmJMVFRUWb58uUmKirK275kyRITHx9vjDFm+fLlpnv37mbMmDEmLCzMdO/e3WzdutUYY8xHH31kIiMjTXh4uOncubP5z3/+c8xr3XzzzWbx4sXGGGMeeughc/7553vbLrzwQrN7927z4osvmmHDhlVb+7Zt28z5559v7rvvPhMREWE6depk1qxZU+323bRpk3G73aZLly4mMTHRREZGmuXLlxtjjImPjzd333236dmzp7nhhhuOu72P3E/GGHP++eebbdu2edsmTpxounfvbjp06GCeffbZams5epvWZP78+eb888835513ngkPDzf5+fk17m9jjJFkysrKjDHGvPbaa+aKK64w4eHh5qGHHjI1fZUf7/1ojDGdOnUymZmZ3scpKSlm0qRJJ6y9vLzcjB071lx22WXmqquuMmPHjjWjR482xhhz+PBhM2XKFNOjRw8TERFhhg4daoqLi6td3+nTp5sePXqY8PBwExsb631PnahfVrZ17tzZ/M///I8JDw83I0aMOKbOhx9+2AwbNswkJCSYK664wtx0003mp59+MsYY8/7775urrrrKREREmG7dupl33nnH+7yLL77Y3HfffaZHjx5m/PjxZsOGDSYmJsZERkaazp07mxdeeME7b3x8vLnnnntMTEyMadu2rXnmmWfM3LlzTVRUlGnXrp157733vPO+9dZb5qqrrjLdu3c3sbGx5tNPP63xfVvdvMYY8+KLL5r+/fubQYMGmc6dO5svv/zS/OEPfzBXXHGF6datm4mNjT3h/gNQdwhaAGrl4osvNps2bTIdOnQwJSUl5v777zfPP/98laDVqVMn8/rrr1f7/E8++cScc845tX69nj17mtTUVGOM80P6N7/5jfnxxx+9tRz5g7g6NQWt9u3bm7CwMHPDDTecMPQ988wzRlKVH6Mnux6V9Xbs2NGEh4eb5s2bmxtvvNHbdu+995rf/e535vDhw6akpMR06dLF++Ospm2wePFiM2DAAO8ydu/ebYwx3uBSk9GjR5uePXua/fv3G2NO/IO2SZMmZuPGjcYYYx588EEzbtw4Y4wxgwcPNi+99JIxxvlhXVxcfMxrPffccyYlJcUYY0yvXr1MVFSU+eyzz8ynn35qunfvfky9R9e+bds2I8kbNubOnVtlnY/UvXt38/LLLxtjnBDo5+dXJWgNGTLEHDp06ITb+0RBa+zYscYYY3744QfTtm1b74/fIy1fvty0aNHCREREmKioKDNv3rxqazbm2D56vD5fGbS+//57c+6555qvvvrKGGPMo48+WmPQOt770Rhjpk+fbhITE40xTng699xzzZdfflnj/JVmzpxpPB6POXjwoNm7d68JCwvzBq1///vfZvz48aaiosIYY8yUKVPMn/70p2rXt6ioyPv///nPf8ygQYOMMbUPWicKtQ8//LBp06aN+eGHH4wxxowZM8ZMmDDBGOO8Zyr7RF5enmnTpo05ePCgMcbZ13feead3OSUlJaa8vNz7vEsuucR8//33xhinf40aNcocPnzY5OXlmYCAAPPkk08aY5wwFxYWZoxx/mgSExNj9u3bZ4wxZtWqVSYyMtIYc2zfP9G8LVq08PbL9evXm44dO3q3d+VnAYD6gVMHAdRao0aNdNNNN+mVV17RokWLNGzYsNPyOnv37tWnn36q2267TZLUuXNnde/eXatXrz6l5T7xxBP66quvlJubqyFDhuiaa66pcurU0d5++21ddNFF2rhxY43zFBQUKCIiQldccYWSk5NrnK/y1MGioiIdOHBATz/9tCQpIyND48aNk5+fn1q2bKmRI0cqIyPjuNsgPDxcX3zxhe644w4tWrRI/v7+td4GQ4cOVUBAQK3m7dy5s7p16yZJuuqqq7R161ZJUu/evTVlyhRNmTJF2dnZatWq1THP7du3rzIzM7Vv3z7t27dPI0eOVGZmpjIzM9WnT59avf4555wjj8dzzOsf6aefftIXX3yh4cOHS5Kio6N1xRVXVJln5MiRcrlckmre3rVx++23S3JOob3uuuu0bNmyY+bp3r27CgoKtGHDBr388st65JFHtGLFihMuu7Z9/pNPPpHb7VaHDh0kSePGjatV7dVJTEzUm2++qX379untt9/WFVdcocsvv/yEz1u+fLmSkpLUuHFjNW/eXCNGjPC2vf3221qyZIm6d++uiIgILViwQNu2bat2OZ988ol69eqlrl276pFHHqnxGsdTMXjwYJ133nmSpDFjxnj39Q8//KAbbrhBXbp00fXXX6+ioiJt377d+7zK/SBJpaWlGj16tLp27arevXurqKhIX3zxhbf95ptvlp+fny6++GIFBgbqxhtvlCRdeeWV+uabbyRJ77//vrZs2aKYmBhFRETojjvu0A8//OC9DvRIJ5o3Li5Ol1xyiSSpffv2OnjwoG6//XbNnz//uNfrAah7BC0AJyUpKUn333+/unfvrnPOOadKW2RkpHfgi6N16tRJBw4c0JYtW37V69r4AXHRRRepUSPnY++2225TSUmJCgsLq5137ty5Ki8v18cff6y//vWv3h/5levx1VdfSZJCQkKUk5OjSZMmac+ePSesoVmzZrruuuu0dOnSatuPt56Vbe3bt9emTZvUv39/LV26VJGRkccMClKT5s2be/+/cePGVa7xOHqwhWbNmnn/3+Vyea9X+eMf/6i33npLrVu3VkpKih555JFjXueyyy7Tvn37tHDhQsXGxqpPnz5atmyZli1bVuugVdPrn6wj1/loR27vE22P4z23UsuWLb3vi3bt2un666/XRx99JEmKiopSRESEBg4cWKu6T7XPH+/9KEkXXnihevXqpVdffVX//ve/azWgxYkYY/Too496r1H7/PPP9frrrx8zX3l5uYYPH65nn31Wn332mV555RXv9j7Z/XAyKrfp+PHjdc0112jTpk3KyclR8+bNq7zOkX3mgQce0CWXXKKNGzcqJydHl19+eZV5j/xDh8vl8j4+ss8aYzRo0CDvdsnJydGOHTu8fwA40onmPbK2c845R5s2bdLw4cO1ceNGde3aVT/++KONTQXAAoIWgJPSsWNHPfbYY7r//vuPaZswYYLmzJmjzMxM77QtW7bonXfeUYsWLXT33Xdr3LhxKioqkiQdPnxYr7zyinewjEotWrRQWFiY5s+fL0navHmz1q9f7x1t7NfasWOH9//ff/99NW3aVBdeeOEx823fvl0PPfSQ/vWvfykkJESPPvqoxowZI2OMWrRoobvuuktjxozR999/731OaWlprWo4fPiwVq5c6T1y0K9fP82dO1fGGO3du1cLFixQ//79j7sNtm/fLpfLpSFDhuipp57SDz/8oOLiYrVs2VI//fRTrbdHu3bt9PXXX6ukpMS7L2pjy5YtuvTSS/X73/9ed999d40/5vv06aPHHntMffv2VZcuXbR582ZlZWV5BxU50snWfuTzOnbsqIULF0pyRtk73qAkNW1vyQmw2dnZkqT33ntPJSUlVZ774osvSpJ27typd999V7179z5m+d999533KOnu3bv13//+VxEREZKcIzg5OTnVjupX2z5/1VVXae3atd7gf7zBII73fqyUlJSkGTNmaOXKlVWOUO/YsUMdO3asdrl9+vTRvHnzVFFRodLS0ir9ZtCgQXr22We92660tFSff/75Mcs4cOCAKioqdNFFF0lyRhKtVNt+WZs+8/bbb2vnzp2SnP3Xr18/SVJJSYlCQ0MlSa+88oqKi4trXEZJSYnatm0rl8ulrKys4x7hrsmAAQP07rvvevvm4cOHtW7dumrX43jzHq2oqEj79+/XwIEDNW3aNLVo0UJ5eXknXR+A04OgBeCkjR8/XmFhYcdMj4iI0JtvvqnHH39cl156qbp27aqUlBTvMN1Tp07Vb3/7W8XGxqpz587q0qWLVq1apRYtWhyzrAULFig1NVXdunXTiBEjlJaWptatW5+wto8//lht27bVP/7xDz377LNq27at99St0aNHKywsTOHh4XriiSf05ptveo9wHWns2LG69957demll3of+/n56fnnn5ckTZs2TYMGDVLv3r3VqVMnxcTEKDMzU3/+859rrOuGG25QRESEunbtqsOHD+uhhx6SJE2ePFmHDh1SWFiYrr76ao0aNcp7ulxN2+DTTz/V1VdfrfDwcPXs2VP333+/zj//fPXt21d79uxReHh4jaMuHumiiy7SXXfdpcjISMXExKht27YnfI7kjPrYpUsXRUZG6plnntFjjz1W7Xx9+/bV9u3bFR8fL8k5leryyy+v9gjTydZ+pLS0NP3f//2funbtqlmzZqlTp07HHG2tdLzt/fjjj2v69OmKiIjQ8uXLdf7551d5bnBwsK688kpdffXVmjRpkrp27XrM8l977TV17dpVERERiouLU1JSkq699tparUdt+vx5552n2bNn69prr1VERMRxj/Kd6P0oOafWFRQUaNCgQWrZsqV3emFhoRo3blztcseNG6c2bdqoU6dO6t+/v3r27OltGz16tG666SbFxsaqW7duuvrqq6s9JfCcc87R5MmTdeWVV6pHjx5Vaqptv+zWrZvatWunsLAwjRw5stp5YmNjdcstt6hjx47auXOnHnzwQUnOacR33323IiIitHr1am/oqs7999+vf/7zn+rWrZuee+65KutbW5dffrlefPFFJSYmKjw8XF26dPH+ceDovn+8eY9WUFCgfv36KTw8XOHh4frtb38rt9t90vUBOD38zPEuUAAAoJ7bt2+fAgMD5efnp40bN8rj8Wjr1q36n//5H2uvcckllyg9Pb3Gozxnmn/84x8677zzNGrUKF+X8qs98sgjOnDggPcWAgBQ16r/cxUAAA3EBx98oEmTJskYo0aNGik1NdVqyDobHe/oLACgdjiiBQAAAACWcY0WAAAAAFhG0AIAAAAAyxrsNVqXXXaZd0QwAAAAAPCFrVu3eu+veaQGG7QuvfRSpaen+7oMAAAAAGexytuEHI1TBwEAAADAMoIWAAAAAFhG0AIAAAAAyxrsNVoAAAAAGo6ffvpJO3fu1KFDh3xdyq/SuHFj/eY3v1HLli1rN/9prgcAAAAA9P333+viiy+Wv7+/r0v5VcrLy/Xtt9/WOmhx6iAAAACAOtFQQ5Z08rUTtAAAAADAMoIWAAAAgDPauHHjlJCQUKevSdACAAAAcMb6+eeftXHjRrVo0UL5+fl19roELQAAAABnrHfffVeDBw/W6NGjlZaWprCwMO/IhwsWLNAjjzyiiooKjRgxQvHx8Zo4caI6dOhwyq9L0AIAAABQt/72NyktTSoslAYOdKaNGCF99pn0zjvSpEnOtG7dnH8fe0x69VXpm2+kIUOcaTfcIG3desKXevnll5WYmKhBgwZp6dKl6tevn5YsWSJJmj9/vm677Ta9+eabatmypVauXKlBgwZZGYKe4d0BAAAA1K177vnl/99/3/n3pZecf7t2la67zvn/3Fzn34ce+mX+N95w/n399RO+TElJiT766CONGzdOkpSXl6fHHntMs2bNktvtVllZmdq3b69XX31VbrdbkhQVFSU/P79fu2ZeHNECAAAAcEZatGiRJk2apPT0dKWnp+uFF17Qu+++q2+//Vb//Oc/NXLkSElShw4dtHbtWklSdna2jDGn/NoELQAAAABnpAULFsjj8Xgf9+rVS2+99ZaGDRump59+WrfccoskaciQISouLlZ8fLxee+01K/f74tRBAAAAAGekZcuWVXns7++vzZs3S5L+8pe/eKe7XC7NmzdPTZo00UcffeSd51QQtAAAAACc9YYPH66dO3eqvLxczz///Ckvj6AFAAAA4Kz32muvWV0e12gBAAAAqBM2BpnwlZOtnSNaOEZxWZlmZWcrKz9f0aGhSnG7FRQQ4OuyAAAA0IA1a9ZMe/bsUatWrawMn16XjDHas2ePmjVrVuvnELRQRXFZmbrNnq2i0lKVV1RoeV6e5qxbp9zkZMIWAAAAfrU2bdqosLBQRUVFvi7lV2nWrJnatGlT6/kJWqhiVna2N2RJUnlFhYpKSzUrO1uT4+J8XB0AAAAaqsaNGys0NNTXZdQZrtFCFVn5+d6QVam8okJZBQU+qggAAABoeE5L0EpNTVV0dLRiYmK0fv36Y9qnT5+ufv36KSEhwTu2/ZIlS+R2uxUbG6uRI0fq0KFDp6M0nEB0aKj8Xa4q0/xdLkWHhPioIgAAAKDhsR60iouLNXPmTK1YsULz58/XXXfdVaV9yZIlKikpUUZGhlasWKE+ffpIkiZPnqxFixbpww8/VJMmTbR06VLbpaEWUtxutQ4M9IYtf5dLrQMDleJ2+7gyAAAAoOGwfo3WmjVrFBsbq6ZNm6pdu3bau3evysvL5e/vL0lauHChgoKC1LdvX7Vp00azZs3SOeecoy5dumjPnj0KDQ1VSUmJWrdufcyy58+fr/nz50uSCgsLbZcOSUEBAcpNTnZGHSwoUHRICKMOAgAAACfJ+hGtXbt2KSgoyPu4VatW2r17t/dxYWGhGjVqpMzMTEVFRWnq1KmSpNtuu00ej0cdO3ZUkyZN1KNHj2OWPWrUKKWnpys9Pf2kRvzAyQkKCNDkuDgtGTlSk+PiCFkAAADASbIetIKDg7Vnzx7v45KSEgUHB1dp93g8kiSPx6Pc3FxJ0u9//3utWbNGX375pYKDg/Xqq6/aLg0AAAAA6oT1oBUVFaVVq1bp4MGDys/PV/Pmzb2nDUpSQkKC1q5dK0lau3atOnToIElyuVzeI2GtW7euchQMAAAAABoS69doBQUFafz48YqPj5efn59mzJihnJwcLV26VBMmTFBSUpLGjh2r3r17q0mTJkpLS5MkTZkyRX369FGzZs3UqlUr3XfffbZLAwAAAIA64WeMMb4u4tfweDxKT0/3dRkAAAAAzmI15RJuWAwAAAAAllk/dRDA6VVcVuYMv5+fr+jQUIbfBwAAqIcIWkADUlxWpm6zZ6uotFTlFRVanpenOevWKTc5mbAFAABQj3DqINCAzMrO9oYsSSqvqFBRaalmZWf7uDIAAAAciaAFNCBZ+fnekFWpvKJCWQUFPqoIAAAA1SFoAQ1IdGio/F2uKtP8XS5Fh4T4qCIAAABUh6AFNCApbrdaBwZ6w5a/y6XWgYFKcbt9XBkAAACOxGAYQAMSFBCg3ORkZ9TBggJFh4Qw6iAAAEA9RNACGpiggABNjovzdRkAAAA4Dk4dBAAAAADLCFoAAAAAYBmnDp6i4rIy53qZ/HxFh4ZyvQwAAAAAgtapKC4rU7fZs703kF2el6c569YpNzmZsAUAAACcxTh18BTMys72hizJuXFsUWmpZmVn+7gyAAAAAL5E0DoFWfn53pBVqbyiQlkFBT6qCAAAAEB9QNA6BdGhod4bx1byd7kUHRLio4oAAAAA1AcErVOQ4nardWCgN2z5u1xqHRioFLfbx5UBAAAA8CUGwzgFQQEByk1OdkYdLChQdEgIow4CAAAAIGidqqCAAE2Oi/N1GQAAAADqEU4dBAAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAMoIWAAAAAFhG0AIAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAlhG0AAAAAMAyghYAAAAAWEbQAgAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAMoIWAAAAAFhG0AIAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAlhG0AAAAAMAyghYAAAAAWEbQAgAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAMoIWAAAAAFhG0AIAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAlhG0AAAAAMAyghYAAAAAWEbQAgAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAMoIWAAAAAFhG0AIAAAAAywhaAAAAAGDZaQlaqampio6OVkxMjNavX39M+/Tp09WvXz8lJCRo2bJlkqT9+/drzJgx6tu3rxISElRcXHw6SgMAAACA066x7QUWFxdr5syZWr16tXbs2KHExEStWrXK275kyRKVlJQoIyOjyvMeffRR3XLLLRowYIDtkgAAAACgTlk/orVmzRrFxsaqadOmateunfbu3avy8nJv+8KFC3XgwAH17dtXiYmJKikpkSRlZGQoPT1dCQkJevjhh22XBQAAAAB1xnrQ2rVrl4KCgryPW7Vqpd27d3sfFxYWqlGjRsrMzFRUVJSmTp0qSfrss8/Up08fLV++XJ9//rnS09OPWfb8+fPl8Xjk8XhUWFhou3QAAAAAsMJ60AoODtaePXu8j0tKShQcHFyl3ePxSJI8Ho9yc3OrTPfz89PAgQO90480atQopaenKz09XW3atLFdOgAAAABYYT1oRUVFadWqVTp48KDy8/PVvHlz+fv7e9sTEhK0du1aSdLatWvVoUOH404HAAAAgIbG+mAYQUFBGj9+vOLj4+Xn56cZM2YoJydHS5cu1YQJE5SUlKSxY8eqd+/eatKkidLS0iRJ06ZN09ixY3XgwAFddtllGjJkiO3SAAAAAKBO+BljjK+L+DU8Hk+113EBAAAAQF2pKZdww2IAAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAljX2dQEAcKYpLivTrOxsZeXnKzo0VClut4ICAnxdFgAAqEMELQCwqLisTN1mz1ZRaanKKyq0PC9Pc9atU25yMmELAICzCKcOAoBFs7KzvSFLksorKlRUWqpZ2dk+rgwAANQlghYAWJSVn+8NWZXKKyqUVVDgo4oAAIAvELQAwKLo0FD5u1xVpvm7XIoOCfFRRQAAwBcIWgBgUYrbrdaBgd6w5e9yqXVgoFLcbh9XBgAA6hKDYQCARUEBAcpNTnZGHSwoUHRICKMOAgBwFiJoAYBlQQEBmhwX5+syAACAD3HqIAAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAlhG0AAAAAMAyghYAAAAAWEbQAgAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAssa+LgAAUL8Vl5VpVna2svLzFR0aqhS3W0EBAb4uCwCAeo2gBQCoUXFZmbrNnq2i0lKVV1RoeV6e5qxbp9zkZMIWAADHwamDAIAazcrO9oYsSSqvqFBRaalmZWf7uDIAAOo3ghYAoEZZ+fnekFWpvKJCWQUFPqoIAICGgaAFAKhRdGio/F2uKtP8XS5Fh4T4qCIAABoGghYAoEYpbrdaBwZ6w5a/y6XWgYFKcbt9XBkAAPUbg2EAAGoUFBCg3ORkZ9TBggJFh4Qw6iAAALVA0AIAHFdQQIAmx8X5ugwAABoUTh0EAAAAAMsIWgAAAABgGacOAgDOOsVlZc51Z/n5ig4N5bozAIB1BC0AwFmluKxM3WbP9t6IeXlenuasW6fc5GTCFgDAGk4dBACcVWZlZ3tDluTcgLmotFSzsrN9XBkA4ExC0AIAnFWy8vO9IatSeUWFsgoKfFQRAOBMRNACAJxVokNDvTdgruTvcik6JMRHFQEAzkQELQDAWSXF7VbrwEBv2PJ3udQ6MFApbrePKwMAnEkYDAMAcFYJCghQbnKyM+pgQYGiQ0IYdRAAYB1BCwBw1gkKCNDkuDhflwEAOINx6iAAAAAAWEbQAgAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAMoIWAAAAAFhG0AIAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsa+7oAAABwaorLyjQrO1tZ+fmKDg1VitutoIAAX5cFAGc1ghYAAA1YcVmZus2eraLSUpVXVGh5Xp7mrFun3ORkwhYA+BCnDgIA0IDNys72hixJKq+oUFFpqWZlZ/u4MgA4uxG0AABowLLy870hq1J5RYWyCgp8VBEAQCJoAQDQoEWHhsrf5aoyzd/lUnRIiI8qAgBIBC0AABq0FLdbrQMDvWHL3+VS68BApbjdPq4MAM5uDIYBAEADFhQQoNzkZGfUwYICRYeEMOogANQDBC0AABq4oIAATY6L83UZAIAjcOogAAAAAFhG0AIAAAAAywhaAAAAAGBZww1a27ZJaWlSYaE0cKAzbcQI6bPPpHfekSZNcqZ16+b8+9hj0quvSt98Iw0Z4ky74QZp61Zp0SKn/cj5J02S3n5b2rRJuvVWZ5rH47zevHnS//2fdPiwFBHhtP3pT1JGhrR2rfS//+tMi4+Xdu+W5syRZs2SSkulq65y2pKTpaws6cMPpTvucKb17CmVlUkzZkj/+pe0c6fUu7fTNnq0tGGDtHSp9Je/VK112jRpwQKpoED67W+dabfcIm3eLL31lvTgg1Xnf+QRafFiacsW6aabnGmDB0t5edJ//iM98YQzLSzM+fe++6QlS6SNG6VRo5xp/ftLP/wgvfii9I9/SAcPSlde6bTddZe0YoX0ySfS2LHOtF69pJ9+kp591vnvp5+caZIzzyefOM+56y5n2pVXOsv8xz+c1/jhB+c1JaeGjRudmu67r2qtTzzhrENenrNOkrOOW7Y46/zII1W3xYMPOtto82Znm0nONiwocLbptGlV5//LX5x9sGGDs08kZx/t3OnssxkznH3Ys6fTdscdzj7OynL2ueT0gdJSp0/MmeP0kfh4p+1//9fpQxkZTp+SnD52+LDT5+bNc/qgx+O03Xqr00fffrv6Pr9okdPHb7jBmTZkiPMeePXV6vv8O+8476ERI5xpAwc6r5eWJv3tb1JFhRQZ6bT98Y9SZqaUnS3dfrszLS5OKi6Wnn9e+uc/nfW8+mqn7fe/d7bDBx/80ufdbunAAenpp6UXXnC2Y58+Tttttznb+b//le65p2qt06ZJL73k7Kdrr3WmDR3q7Mc335QmT646/8MPS6+/Ln35pXTzzc60QYOkb7+VXnlFevLJqvPfe6+Uni7l5PzS5/v1k3780emPTz0l/fyz1KOH03bnndLKldLq1b/0+ZgYae9ep78/95xUUiLFxjptY8Y4fX75cunuu51p3btLhw5Jf/+7lJoqff+9NGCA0zZypJSbK733njRxYtVap0xx+vy2bb/0+RtvlL76SnrtNenRR6vO/8ADTp//4gtp2DBn2jXXSNu3O31++vSq8//5z06fX79eSkpypiUkSLt2SXPnSjNnSvv3S1FRTtv48dKqVdJHH0l/+IMz7aqrnHmeeUb6f//PeW5ln//d76R165w+/+c/O9PCwyVjpL/+VZo/X9qx45c+P3y49PnnTp+///6qtT76qNPnv/7a2QaSdP31zrZZuFB6/PGq80+cKL37rvTpp842lpw+/9130r//7fT5Q4d+6fN33y0tWyatWePsQ8np83v2SLNnO31+3z4pOtppGzdO+vhjp8+npDjT3G6pvNzpQy+8IBUVSX37Om2JiU6fe/99acKEqrVOnSq9/LKUny9dd50zbehQp0+/8Yb00EPOtMrPwocecqZ/+aUzn+Q8Lz/fWc7UqVWXP2GC87o5OU4dklNXUZFT51NPOXVXjmSYkuKs18cfO+spOeu9b5+zHWbPdrZL5XVjY8Y4223Zsl/6fGSks33/9jdne3/33S/f5yNHOvvl3XeP7fOPP+7sz23bnP0rOfv766+d/X90n7//fqe/fP65038kpz/t2OH0r7/+1elv4eFO25//7PTHdeuc/ik5/XXXLqf/PvOM058rv8//8Aenv69a5fR/yXk/7N/vvD/mznWem5DgtCUlOe+npUt/6fOVtU6f7rwPt2933peS8z794gvnffvAA1Xnf/RR533+1Ve/9PnBg51t85//OJ8PR84/caLzOZKb+0ufHzDA+bxJTXU+fw4dcj6PJGdfLV/ufF5V9vnYWOfz7LnnnM+3vXudzzvJ+fxbvdr5PLzzTmdajx7O5+VTTzmfnz/+6HyeSs7na06O83l7771Va33ySefz+dtvnc9ryfn8/vJL5/P84Yerzj95svP5v3nzL33+2mud74mXXjr2+/yee5zvlw0bnO8byfn+2bnT6fNPP+18P1X2+TvucPp8VpbzfSY532+lpU6ff/555/uvss/ffrvz/ZiZ6XxfSk6fr6hw+jy/YZ1/z5TfsDXwM8aYGlvrMY/Ho/T0dF+XAQAAAOAsVlMuabhHtAAAAACgniJoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAlhG0AAAAAMAyghYAAAAAWEbQAgAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGWnJWilpqYqOjpaMTExWr9+/THt06dPV79+/ZSQkKBly5ZVaUtISNCYMWNOR1kAAAAAGqDisjI9/sEHumb+fD3+wQcqLivzdUkn1LimhqefflpdunRR//79vdMyMjK0adMm3X333TUusLi4WDNnztTq1au1Y8cOJSYmatWqVd72JUuWqKSkRBkZGcc895133lGLFi1+7boAAIAzQHFZmWZlZysrP1/RoaFKcbsVFBDg67IA+EhxWZm6zZ6totJSlVdUaHlenuasW6fc5OR6/dlQ4xGtRYsWVQlZktSvXz+9+uqrx13gmjVrFBsbq6ZNm6pdu3bau3evysvLve0LFy7UgQMH1LdvXyUmJqqkpESSdPjwYf3zn//UHXfccSrrAwAAGrDKH1RPfPCB0rdu1RMffKBus2c3iL9eAzg9ZmVne0OWJJVXVKiotFSzsrN9XNnx1Ri0mjZtelLTK+3atUtBQUHex61atdLu3bu9jwsLC9WoUSNlZmYqKipKU6dOlST9+9//1o033qhmzZrVuOz58+fL4/HI4/GosLDwuHUAAICGp6H+oAJw+mTl53s/EyqVV1Qoq6DARxXVTo1Bq1mzZsrLy6sybdu2bfL39z/uAoODg7Vnzx7v45KSEgUHB1dp93g8kiSPx6Pc3FwdOHBACxYs0O9+97vjLnvUqFFKT09Xenq62rRpc9x5AQBAw9NQf1ABOH2iQ0Pl73JVmebvcik6JMRHFdVOjddoTZs2Tddff70GDx6skJAQffvtt3rnnXc0f/784y4wKipKDz74oA4ePKjvvvtOzZs3rxLOEhIStHbtWvXr109r165Vhw4dtG3bNu3Zs0fXXXeddu/ere+++05z585lUAwAAM4y0aGhWp6XVyVsNYQfVABOnxS3W3PWrfMe7fZ3udQ6MFApbrevSzsuP2OMqanxp59+0rvvvquCggKFhITo2muvVcuWLU+40BdeeEFz586Vn5+fZsyYocaNG2vp0qWaMGGCysvLNXbsWBUUFKhJkyZKS0vTBRdc4H3uihUrNH/+fM2dO/e4r+HxeJSenn4SqwoAAOq7oy96r/xBVd8vegdwenkHySkoUHRISL0aJKemXFJj0MrIyFBAQIBiYmK80z766CPvQBa+RtACAODMVJ9/UAHA0WrKJTWeOvjEE09oyZIlVaZdeeWVuuaaa+pF0AIAAGemoIAATY6L83UZAHBKagxako4ZAfB4IwICAAAAqB+4H53v1Ri0Dh8+rLKyMgUcsUNKS0t1+PDhOikMAAAAwMlrqDf4PdPUOLz7nXfeqUGDBikzM1NbtmzR0qVLNWjQIN111111WR8AAACAk8D96OqHGo9o3XzzzWrbtq1SU1O9ow5OnTpVUVFRdVkfAAAAgJPA/ejqhxqDVvv27dW4cWNVDkq4ZcsWZWZmys/PT1u2bKmzAgEAAADUHvejqx9qDFq9e/fW9u3bde2112r48OE677zz6rIuwBouBgUAAGeThnqD3zPNcW9Y/PPPP+udd97RwoULtX//fo0fP14ej6cu66sR99FCbXDjSwAAcDbifnR1p6ZcUuNgGJLUtGlTxcXFKTY2Vrt379bnn39+2goETgcuBgUAAGejyvvRLRk5UpPj4ghZPlDjqYMLFizQokWL1KRJEw0dOlSZmZny9/evy9qAU8bFoAAAAPCFGo9oJSYmqqCgQMXFxZozZ44GDRqkAQMGaMCAAXVZH3BKokND5e9yVZnGxaAAAAA43Wo8orVt27a6rAM4LbgYFAAAAL5QY9C6+OKL67IO4LQICghQbnIyF4MCAACgTtUYtIAzReXFoAAAAEBdOe6ogwAAAACAk0fQAgAAAADLOHUQAAAAZzXvzX3z8xUdGsr13LCCoAUAAICzVnFZmbrNnu0doXh5Xp7mrFun3ORkwhZOCacOAgAA4Kw1KzvbG7IkqbyiQkWlpZqVne3jytDQEbQAAABw1srKz/eGrErlFRXKKijwUUU4UxC0AAAAcNaKDg2Vv8tVZZq/y6XokBAfVYQzBUELAAAAZ60Ut1utAwO9Ycvf5VLrwECluN0+rgwNHYNhAAAA4KwVFBCg3ORkZ9TBggJFh4Qw6iCsIGgBAADgrBYUEKDJcXG+LgNnGE4dBAAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAMoIWAAAAAFhG0AIAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAlhG0AAAAAMAyghYAAAAAWEbQAgAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAMoIWAAAAAFhG0AIAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAlhG0AAAAAMAyghYAAAAAWEbQAgAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAMoIWAAAAAFhG0AIAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsa+7oAACguK9Os7Gxl5ecrOjRUKW63ggICfF0WAADAr0bQAuBTxWVl6jZ7topKS1VeUaHleXmas26dcpOTCVsAAKDB4tRBAD41KzvbG7IkqbyiQkWlpZqVne3jygAAAH49ghYAn8rKz/eGrErlFRXKKijwUUUAAACnjqAFwKeiQ0Pl73JVmebvcik6JMRHFQEAAJw6ghYAn0pxu9U6MNAbtvxdLrUODFSK2+3jygAAAH49BsMA4FNBAQHKTU52Rh0sKFB0SAijDgIAgAaPoAXA54ICAjQ5Ls7XZQAAAFjDqYMAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACw7LQErdTUVEVHRysmJkbr168/pn369Onq16+fEhIStGzZMknS0KFDFR0draioKKWmpp6OsgAAAACgTlgfdbC4uFgzZ87U6tWrtWPHDiUmJmrVqlXe9iVLlqikpEQZGRlVnvfkk0/qsssu04EDB9S1a1cNHz5czZo1s10eAAAAAJx21o9orVmzRrGxsWratKnatWunvXv3qry83Nu+cOFCHThwQH379lViYqJKSkokSZdddpkkqWnTpnK5XPLz87NdGgAAAADUCetBa9euXQoKCvI+btWqlXbv3u19XFhYqEaNGikzM1NRUVGaOnVqledPnTpVw4cPl7+//zHLnj9/vjwejzwejwoLC22XDgAAAABWWA9awcHB2rNnj/dxSUmJgoODq7R7PB5JksfjUW5urrctLS1Nubm5evjhh6td9qhRo5Senq709HS1adPGdukAAAAAYIX1oBUVFaVVq1bp4MGDys/PV/PmzascnUpISNDatWslSWvXrlWHDh0kSW+++aZeeuklzZs3T40aMRgiAAAAgIbL+mAYQUFBGj9+vOLj4+Xn56cZM2YoJydHS5cu1YQJE5SUlKSxY8eqd+/eatKkidLS0iRJI0eOVMeOHTVgwABJ0oIFC3TRRRfZLg8AAAAATjs/Y4zxdRG/hsfjUXp6uq/LAAAAAHAWqymXcI4eAAAAAFhG0AIAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAlhG0AAAAAMAyghYAAAAAWEbQAgAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAMoIWAAAAAFhG0AIAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBljX1dAAAAABqW4rIyzcrOVlZ+vqJDQ5XidisoIMDXZQH1CkELAAAAtVZcVqZus2erqLRU5RUVWp6Xpznr1ik3OZmwBRyBUwcBAABQa7Oys70hS5LKKypUVFqqWdnZPq4MqF8IWgAAAKi1rPx8b8iqVF5RoayCAh9VBNRPBC0AAADUWnRoqPxdrirT/F0uRYeE+KgioH4iaAEAAKDWUtxutQ4M9IYtf5dLrQMDleJ2+7gyoH5hMAwAAADUWlBAgHKTk51RBwsKFB0SwqiDQDUIWgAAADgpQQEBmhwX5+sygHqNUwcBAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAlhG0AAAAAMAyghYAAAAAWEbQAgAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAMoIWAAAAAFhG0AIAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAlhG0AAAAAMAyghYAAAAAWEbQAgAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAMoIWAAAAAFhG0AIAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAlhG0AAAAAMAyghYAAAAAWEbQAgAAAADLCFoAAAAAYBlBCwAAAAAsI2gBAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAstMStFJTUxUdHa2YmBitX7/+mPbp06erX79+SkhI0LJlyyRJeXl56tOnj2JiYvTkk0+ejrIAAAAAoE40tr3A4uJizZw5U6tXr9aOHTuUmJioVatWeduXLFmikpISZWRkVHnexIkT9eijjyo2Nlb9+vXTjTfeqI4dO9ouDwAAAABOO+tHtNasWaPY2Fg1bdpU7dq10969e1VeXu5tX7hwoQ4cOKC+ffsqMTFRJSUlkqScnBzFxsZKkq699lqtXLnymGXPnz9fHo9HHo9HhYWFtksHAAAAACusB61du3YpKCjI+7hVq1bavXu393FhYaEaNWqkzMxMRUVFaerUqZKkw4cP1/icSqNGjVJ6errS09PVpk0b26UDAAAAgBXWg1ZwcLD27NnjfVxSUqLg4OAq7R6PR5Lk8XiUm5vrFNKoUY3PAQAAAICGxHrQioqK0qpVq3Tw4EHl5+erefPm8vf397YnJCRo7dq1kqS1a9eqQ4cOkqTw8HBlZWVJcq7jiouLs10aAAAAANQJ64NhBAUFafz48YqPj5efn59mzJihnJwcLV26VBMmTFBSUpLGjh2r3r17q0mTJkpLS5MkTZ06Vbfffrt+/vlnXXPNNerUqZPt0gAAAACgTvgZY4yvi/g1PB6P0tPTfV0GAAAAgLNYTbmEGxYDAAAAgGUELQAAAACwjKAFAAAAAJYRtAAAAADAMoIWAAAAAFhG0AIAAAAAy6zfRwsAAABVFZeVaVZ2trLy8xUdGqoUt1tBAQG+LgvAaUTQAgAAOI2Ky8rUbfZsFZWWqryiQsvz8jRn3TrlJicTtoAzGKcOAgAAnEazsrO9IUuSyisqVFRaqlnZ2T6uDMDpRNACAAA4jbLy870hq1J5RYWyCgp8VBGAukDQAgAAOI2iQ0Pl73JVmebvcik6JMRHFQGoCwQtAACA0yjF7VbrwEBv2PJ3udQ6MFApbrePKwNwOjEYBgAAwGkUFBCg3ORkZ9TBggJFh4Qw6iBwFiBoAQAAnGZBAQGaHBfn6zIA1CFOHQQAAAAAywhaAAAAAGAZQQsAAAAALCNoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALCMoAUAAAAAlhG0AAAAAMAyghYAAAAAWEbQAgAAAADLCFoAAAAAYFljXxfwa23dulUej8fXZXgVFhaqTZs2vi4Dx8E+qv/YR/Ub+6f+Yx/Vf+yj+o39U//Vx320devWaqf7GWNMHddyRvJ4PEpPT/d1GTgO9lH9xz6q39g/9R/7qP5jH9Vv7J/6ryHtI04dBAAAAADLCFqWjBo1ytcl4ATYR/Uf+6h+Y//Uf+yj+o99VL+xf+q/hrSPOHUQAAAAACzjiBYAAAAAWEbQAgAAAADLCFoWpKamKjo6WjExMVq/fr2vy8FRNmzYoJiYGMXFxalPnz765ptvfF0SqrFlyxY1adJEq1at8nUpqMa6des0YMAA9e7dW/fee6+vy8FRjDFKSUnR1VdfLbfbrZdfftnXJUHSwIED1bp1a02ZMkWSs5/uvPNOxcbG6rrrrtPu3bt9XCGO3kdpaWnq2bOn4uLiNHz4cJWXl/u4wrPb0fun0osvvqgmTZr4qKraa7D30aoviouLNXPmTK1evVo7duxQYmIiPxTrmQsvvFDp6elq0aKF3nvvPT388MOaN2+er8vCUR5//HHFx8f7ugxU4+eff9bEiRO1ePFitWjRwtfloBqbNm3Spk2b9PHHH2vv3r2KiIjQrbfe6uuyznr/+te/lJGRoe3bt0uS3n//fe3fv18ffvih0tLS9Ne//lXTpk3zcZVnt6P3Ua9evTRy5Ei5XC7de++9mj9/vm6//XYfV3n2Onr/SNKBAwf02muvKTQ01IeV1Q5HtE7RmjVrFBsbq6ZNm6pdu3bau3cvf/2oZy644ALvj0N/f381bszfF+qbTz75RBdccIHatm3r61JQjY8//ljNmzfXiBEj1KdPH3344Ye+LglHadOmjZo2baqDBw9q7969Cg4O9nVJkI75TFu5cqWuu+46SdKgQYO0cuVKX5SFIxy9j9q3by+XyyWJ3wz1QXW/C2bOnKnk5GT5+fn5oKKTQ9A6Rbt27VJQUJD3catWrTgVoJ4qLS3Vgw8+qAkTJvi6FBzliSee0MSJE31dBmpQWFiojRs3asGCBZo3b57Gjh0rBqytX4KCgnTZZZfp8ssvV0REhB588EFfl4RqHPmboVWrViouLvZxRajJ5s2blZ6ermHDhvm6FByhuLhYH3zwgfcPFvUdMf0UBQcHa8+ePd7HJSUl/CWxHjp48KCGDRum++67T507d/Z1OTjCu+++qx49eujcc8/1dSmoQXBwsKKjo9WyZUu1bNlSv/nNb1RUVKTzzjvP16Xh/7d06VLt2LFDX3/9tUpKShQbGyuPxyN/f39fl4YjHPmboaSkpMofalF/bN++XaNHj9Yrr7yiZs2a+bocHGHq1KkN6jphjmidoqioKK1atUoHDx5Ufn6+mjdvzhdbPXP48GGNGjVKQ4YM0ZAhQ3xdDo6Sk5OjFStWyOPxaOnSpbrnnnv07bff+rosHCEqKkpbtmzRoUOHtHfvXv34448E43rGGKOgoCC5XC61aNFCP//8syoqKnxdFo4SHx+v9957T5L03nvvcV1qPbRz507ddNNNmj17ti699FJfl4OjbNmyRU8++aQ8Ho++++67en/EkRsWW/DCCy9o7ty58vPz04wZM9SjRw9fl4QjLFq0SElJSd79EhYWpmeeecbHVaE6SUlJGjNmjHr16uXrUnCUefPm6fnnn9fBgwc1ceJE3XDDDb4uCUeoqKjQ7bffrq+//lrl5eVKTEzUXXfd5euyznpjx45VVlaWysvL1bVrVy1evFh33nmncnNz1bJlS6WlpfFHCx87eh+1bdtWb7zxhjp06CBJSkxMZDAMHzp6/7zxxhvetg4dOujrr7/2XXG1QNACAAAAAMs4dRAAAAAALCNoAQAAAIBlBC0AAAAAsIygBQAAAACWEbQAAPVCXl6egoKClJCQoKioKD399NOnvMxLLrlEf/zjH72PExIStH379lNaZlJSklatWnWKlQEAznQELQBAvXHllVdqxYoVysrK0nPPPafS0tJTWl7jxo310Ucf6bvvvrNU4a/Hfa0A4OxC0AIA1Dv79+/33nQ3NTVVU6ZMkSRt375dCQkJkqRHHnlEI0eO1ODBgxUREaHNmzdXu6wJEyZo+vTpVaatWLFCY8aM8T6uvGdOamqqrr/+et14443q3LmzFi9erMGDB6tLly7KzMz0zj937lx5PB7Fx8d7Q9yrr76q2NhY9erVS4899pj3dQYOHKihQ4fqgQcesLNxAAANAkELAFBvrFu3TvHx8QoJCdEdd9yhli1bHnf+1q1b66233tK9996ruXPnVjvP0KFDT+qolsvl0uLFi/XQQw9pypQpev3117VgwQLNnDnTO88VV1yh9PR0jRs3TtOnT1dxcbH+/ve/a9myZVq1apU2bNigTz/9VJJUWFiol156SdOmTavlVgAAnAkIWgCAeuPKK6/UypUrtXLlSmVkZEiS/Pz8vO3GmGPml6TQ0FDt2rWr2mX6+fnp3nvvrRJ0jlzm0SIjIyVJbdu2VVhYmFwul9q2bavdu3d75+nZs6ckKSoqSl9++aW+/vprffvtt+rfv78SEhK0bds2ffvtt5KkHj16qEmTJrXeBgCAMwNBCwBQ74SHh6tNmzZ67733FBwc7B3AYt26dVXmO14IO9LNN9+sjz/+WN9//70kVVlmTk6ODh06VO0ya1r+2rVrJUnZ2dm6/PLL1b59e3Xo0EEZGRlasWKF1q9fr2uuuUaSc4QMAHD2aezrAgAAqM6f/vQn3XHHHfrvf/+rp556SgMGDPAebTpZlUe1hg4dKkkKCwtTy5YtFR8fr/j4eDVufHJfh1u3btXAgQNVVlaml19+Weeee67++Mc/qk+fPnK5XGrSpInS0tJ+Va0AgDODnznenwABAAAAACeNUwcBAAAAwDKCFgAAAABYRtACAAAAAMsIWgAAAABgGUELAAAAACwjaAEAAACAZQQtAAAAALDs/wOfTaPG346hKwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1040x650 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.6442569171600796\n"
     ]
    }
   ],
   "source": [
    "Score_list = []\n",
    "for i in range(0,15):\n",
    "    file = \"AC_dataset.csv\"\n",
    "    Training_Set, Testing_Set                     = Train_Test_Split(file)                                 #Create training and testing sets\n",
    "    d_test, TestData, TestLabels                  = test_matrix(Testing_Set)\n",
    "    # test(inData, classData, ValData, Vallabel)                                                          #Initial evaluation\n",
    "    IT_list, LT_list, IV_list, LV_list = CV(Training_Set)                #Cross-validate training set        \n",
    "\n",
    "    K_fold_score = []\n",
    "    all_prob_matrix = []\n",
    "    for i in range(len(IT_list)):          \n",
    "        inData = IT_list[i]\n",
    "        classData = LT_list[i]\n",
    "        ValData = IV_list[i]\n",
    "        Vallabel = LV_list[i]\n",
    "\n",
    "        minClass, minSize, maxSize  = find_minority_class(classData)                            #Determines imbalance\n",
    "        BF                          = Balance_ratio(maxSize, minSize)                           #Determins number of balancing folds needed\n",
    "        Input_folds, Output_folds   = Balance_Folds(BF, inData, classData, minClass, minSize)   # balance() and balance_data() functions are called under this\n",
    "        d_train_list, d_val         = model_training_data(BF, Input_folds, Output_folds, ValData, Vallabel)\n",
    "        # BF_GBC_HP                   = hyperparameter(BF, d_train_list, d_val)\n",
    "        BF_GBC                      = BF_fitting(BF, d_train_list, d_val)\n",
    "        Prob_matrix                 = BF_validate(BF_GBC, d_test)\n",
    "        all_prob_matrix.append(Prob_matrix)\n",
    "\n",
    "        Final_vote, Sum_PD, Sum_SNP = Weighted_Vote(Prob_matrix)\n",
    "        \n",
    "        evalutation(TestLabels, Final_vote)\n",
    "        MCC = fold_MCC(Final_vote, TestLabels)\n",
    "        \n",
    "    MCC_final = final_evaluation(all_prob_matrix, TestLabels)\n",
    "    Score_list.append(MCC_final)  \n",
    "\n",
    "plot(Score_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e5cd67c8584618c148c6f2b57de13817422ccd98975b320089863a41752ead79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
