{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d94d2bb",
   "metadata": {},
   "source": [
    "SAAPpred script that predicts protein pathogenicty from SAAPdap data, using XG Boost. Used on on \"AC_dataset\" (imbalance 2:1: ~2200 PD and ~1100 SNP) and \"Dataset_NoFeature\" (imbalance 18:1: ~460000 PD and ~25000 SNP)\n",
    "Goal is to predict SNP or PD with MCC > 0.7.\n",
    "        \n",
    "Scale branch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports the required libraries and packages \"\"\"\n",
    "\n",
    "import pandas as pd                                                              # Data manipulation in dataframes\n",
    "import numpy as np                                                               # Array manipulation\n",
    "import xgboost as xgb                                                            # Gradient boosting package\n",
    "import pickle                                                                    # Saving/loading GBM files\n",
    "import hyperopt\n",
    "\n",
    "import random as rd                                                              # Random seed generation\n",
    "import time                                                                      # Time program run time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,                                                           # MCC for evaluation\n",
    "    # balanced_accuracy_score, #hyperparameter evaluation\n",
    "    # f1_score,  #hyperparameter evaluation\n",
    "    accuracy_score,\n",
    "    confusion_matrix,                                                            # Confusion matrix for classification evalutation\n",
    "    classification_report                                                        # Return the F1, precision, and recall of a prediction\n",
    "    )\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,                                                            # Splits data frame into the training set and testing set\n",
    "    # GridSearchCV,  # Searches all hyperparameters\n",
    "    # RandomizedSearchCV, # Searches random range of hyperparameters\n",
    "    GroupKFold                                                                   # K-fold CV with as groups\n",
    "        )\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# from sklearn.ensemble import RandomForestClassifier                            # SK learn API for classificastion random forests\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK                                       # Functions for minimising cost functions\n",
    "from hyperopt.pyll.base import scope\n",
    "from functools import partial\n",
    "\n",
    "np.set_printoptions(precision = 3,threshold=np.inf, suppress=True)               # Full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9fb056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(file_train, file_test):\n",
    "    \"\"\"      \n",
    "     Returns:    Training_Set     Scaled 80% training set split\n",
    "                 Testing_Set      Scaled 20% testing set split\n",
    "            \n",
    "    Opens the scaled training and testing data\n",
    "    \"\"\"\n",
    "    Training_Set = pd.read_csv(file_train, index_col = 0)\n",
    "    Testing_Set = pd.read_csv(file_test,index_col = 0)\n",
    "    \n",
    "    return Training_Set, Testing_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466d455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dmatrix(Testing_Set):\n",
    "    \"\"\"      \n",
    "    Input:      Testing_Set      20% testing set split\n",
    "\n",
    "    Returns:    d_test           Testing data in dmatrix \n",
    "                TestData         Testing features \n",
    "                TestLabels       Testing labels\n",
    "            \n",
    "    Testing set as dmatrix for XGBoost API compatabillity\n",
    "    \"\"\"\n",
    "    TestData     = Testing_Set.drop(['AC Code','dataset'], axis =1)  \n",
    "    TestLabels   = Testing_Set['dataset']                                \n",
    "    \n",
    "    d_test = xgb.DMatrix(TestData, TestLabels)\n",
    "    \n",
    "    return (d_test, TestData, TestLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(Training_Set, d_test):\n",
    "    \"\"\" \n",
    "    Input:      Training_Set     80% training set split\n",
    "                d_test           Testing data in dmatrix\n",
    "\n",
    "    Evaluate training data before CV and balancing. Gradient boosting for prediction on the test data. \n",
    "    True values are testing data class labels\n",
    "    \"\"\"    \n",
    "    TrainData     = Training_Set.drop(['AC Code','dataset'], axis =1)  \n",
    "    TrainLabels   = Training_Set['dataset']\n",
    "    d_train = xgb.DMatrix(TrainData, TrainLabels)\n",
    "\n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:hinge', \n",
    "    }\n",
    "    XGB_initial = xgb.train(params, d_train)\n",
    "    \n",
    "    Output_pred = XGB_initial.predict(d_test)\n",
    "    print(f\"              **Initial Evaluation**\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(d_test.get_label(), Output_pred)}\")\n",
    "    print(f\"MCC              {matthews_corrcoef(d_test.get_label(), Output_pred)}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05b3a2df",
   "metadata": {},
   "source": [
    "# Outer Loop: Group Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975ff775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(Training_Set):\n",
    "    \"\"\"      \n",
    "    Input:      Training_Set     80% training set split\n",
    "            \n",
    "    Returns:    IT_list         List of training features for each fold\n",
    "                LT_list         List of training class labels for each fold\n",
    "                IV_list         List of validation features for each fold\n",
    "                LV_list         List of validation class labels for each fold\n",
    "\n",
    "    K-fold CV with protein groups separated between training and validation sets for each fold. Creates 5 folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    features     = Training_Set.drop(['dataset'], axis =1)         #Features for training\n",
    "    labels       = Training_Set['dataset']                         #Class labels for training\n",
    "    groups       = Training_Set['AC Code'].to_list()               #List of proteins for grouping\n",
    "    \n",
    "    CV           = GroupKFold(n_splits = 5)                        #Creates 5 splits\n",
    "    \n",
    "    IT_list      = []\n",
    "    LT_list      = []\n",
    "    IV_list      = []\n",
    "    LV_list      = []\n",
    "    \n",
    "    for train_idx, val_idx in CV.split(features, labels, groups):       #Generates the indices to be used for a training and validation split. Indicies are unique to train/ val sets\n",
    "\n",
    "        Input_train                        = features.loc[train_idx]    #New dataframe from selected indices\n",
    "        Classes_train                      = labels.loc[train_idx]\n",
    "        Input_train.drop(['AC Code'], axis = 1, inplace = True)         #Group identifer not needed for training\n",
    "\n",
    "                \n",
    "        Input_val                          = features.loc[val_idx]\n",
    "        Classes_val                        = labels.loc[val_idx]\n",
    "        Input_val.drop(['AC Code'], axis   = 1, inplace = True)\n",
    "        \n",
    "        Input_train.reset_index(drop = True, inplace = True)            #Reset index of each set for compatability with balancing\n",
    "        Classes_train.reset_index(drop = True, inplace = True)\n",
    "        Input_val.reset_index(drop = True, inplace = True)\n",
    "        Classes_val.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        IT_list.append(Input_train)       \n",
    "        LT_list.append(Classes_train)\n",
    "        IV_list.append(Input_val)\n",
    "        LV_list.append(Classes_val)\n",
    "    \n",
    "    return(IT_list, LT_list, IV_list, LV_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "# Inner Loop:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16250cbe",
   "metadata": {},
   "source": [
    "### Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" \n",
    "    Input:        classData  Array of class labels\n",
    "\n",
    "    Returns:      minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "\n",
    "    Find information about class size imbalance\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize  = Minority_count\n",
    "    maxSize  = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize  = Majority_count\n",
    "        maxSize  = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:        inData          Dataframe of input data\n",
    "                  classData       Series of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "\n",
    "    Returns:      usedLines       array of indexes that are of interest for a balanced dataset\n",
    "\n",
    "    Perform the actual balancing for a fold between SNPs and PDs\n",
    "    \"\"\"\n",
    "    usedLines = [False] * len(inData)      #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData[i] == minClass:       #Balance directly with dataframe\n",
    "            usedLines[i] = True            #True lines are SNP\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedLines[i] = True\n",
    "            usedCount += 1                 #Set PD lines \"True\", until equal to number of SNP lines\n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    \"\"\"     \n",
    "    Input:      inData         Datframe of input training data\n",
    "                classData      Series of classes assigned to training data\n",
    "                usedLines      Array of line indexes to print\n",
    "\n",
    "    Returns:    input_balance  Dataframe of balanced training features\n",
    "                label_balance  Dataframe of balanced training labels\n",
    "                       \n",
    "    Create dataframe of the input training data and classes used. Index_list tracks the indicies between usedLines and inData, used to pull the required5 lines.\n",
    "    \"\"\"\n",
    "    input_balance = []\n",
    "    label_balance = []\n",
    "    index_list = []\n",
    "    \n",
    "    for i in range(len(usedLines)):\n",
    "        if usedLines[i] == True:\n",
    "            index_list.append(i)\n",
    "             \n",
    "    input_balance = inData.iloc[index_list].reset_index(inplace = False, drop = True)\n",
    "    label_balance = classData.iloc[index_list].reset_index(inplace = False, drop = True) \n",
    "    \n",
    "    return input_balance, label_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_ratio(maxSize, minSize): \n",
    "    \"\"\" \n",
    "    Input:      maxSize     The number of items in the majority class\n",
    "                minSize     The number of items in the minority class\n",
    "\n",
    "    Returns:    BF          Number of balancing folds\n",
    "\n",
    "    Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "    majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "    \"\"\"\n",
    "    Divide = maxSize/minSize\n",
    "    BF = (2 * round(Divide)) + 1    #Double ratio to nearest integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Balance_Folds(BF, inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                inData            Datframe of input training data\n",
    "                classData         Series of classes assigned to training data\n",
    "                minClass          The label for the minority class\n",
    "                minSize           The number of items in the minority class\n",
    "                                  \n",
    "    Returns:    Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "\n",
    "    Runs balance_data() for the number of balancing folds. Return lists of balanced folds features and labels\n",
    "    where each item is the output of balance_data()\n",
    "    \"\"\"\n",
    "    Input_folds  = []\n",
    "    Output_folds = []\n",
    "\n",
    "    for i in range(BF):\n",
    "        usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "        input_balance, label_balance = balance_data(inData, classData, usedLines)\n",
    "        \n",
    "        Input_folds.append(input_balance)\n",
    "        Output_folds.append(label_balance)\n",
    "            \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21cd1aaa",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ede39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBM_dmatrix(BF, Input_folds, Output_folds, ValData, Vallabel):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "                ValData           Validation features from CV fold\n",
    "                ValLabel          Valiadation labels from CV fold\n",
    "                                  \n",
    "    Returns:    d_train_list      List of balanced training feature folds as DMatrix\n",
    "                d_val             Validation data as Dmatrix\n",
    "\n",
    "    Converts the balanced training data and validation data into Dmatrix for model training and evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    d_train_list =[]\n",
    "    \n",
    "    for i in range(BF):\n",
    "        d_train = xgb.DMatrix(Input_folds[i], Output_folds[i])      #Create DMatrix for each training balanced fold\n",
    "        d_train_list.append(d_train)\n",
    "    d_val = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "    return (d_train_list, d_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cb2003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCC_eval_metric(pred, d_val):\n",
    "    \"\"\" \n",
    "    Input:      pred              Prediction from a boosted tree during training\n",
    "                d_val             Validation data as Dmatrix\n",
    "    \n",
    "    Returns:    mcc               The MCC from a boosted tree round\n",
    "\n",
    "    MCC as a custom evaluation metric to evaluate model training during cross validation. This is different from the final weighted vote evaluation.\n",
    "    \"\"\"\n",
    "    true_label = d_val.get_label()   \n",
    "    pred_label = np.round(pred) \n",
    "    \n",
    "    return 'mcc', matthews_corrcoef(pred_label, true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0840d9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hyperopt_space():\n",
    "    \"\"\" \n",
    "    Returns:    Space         Parameter space for hyperopt searching\n",
    "\n",
    "    Define paramater psace for hyperopt tuning\n",
    "   \"\"\"  \n",
    "#   params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:logistic', \n",
    "#     # 'learning_rate': 0.3,\n",
    "#     # 'max_depth': 5,\n",
    "#     }\n",
    "#   for i in range(BF):        \n",
    "#     BF_GBC_HP = xgb.cv(\n",
    "#         params,\n",
    "#         d_train_list[i],\n",
    "#         nfold = 5,\n",
    "#         num_boost_round= 500,\n",
    "#         early_stopping_rounds= 20,\n",
    "#         custom_metric = CM, \n",
    "#         as_pandas=True,\n",
    "#     )\n",
    "  \n",
    "#   return(BF_GBC_HP) \n",
    "\n",
    "    space = {\n",
    "        'num_boost_round': scope.int(hp.quniform('num_boost_round', 1000, 2000, 100)),\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 3, 10, 1)),\n",
    "        'eta': hp.loguniform('eta', -1, -0.523),\n",
    "        # 'min_child_weight': hp.loguniform('min_child_weight', -1, 7),\n",
    "        # 'gamma': hp.loguniform ('gamma', -10, 10),\n",
    "        # 'reg_alpha': hp.loguniform('reg_alpha', -10, 10),\n",
    "        # 'reg_lambda': hp.loguniform('reg_lambda', -10, 10),\n",
    "    }\n",
    "     \n",
    "    return space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54010b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, d_train_list, d_val): \n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds                      \n",
    "                d_train_list      List of balanced training feature folds in DMatrix\n",
    "                d_val             Validation data as Dmatrix\n",
    "                \n",
    "    Returns:    BF_GBC            List of gradient boosted models trained on each balancing fold\n",
    "\n",
    "    Create GBC model that returns probability predictions for each fold, using output of Balance_Folds() as training data (as Dmatrix)\n",
    "    \"\"\"     \n",
    "    num_boost_round = params['num_boost_round']\n",
    "    max_depth = params['max_depth']\n",
    "    eta = params['eta']\n",
    "    # min_child_weight = params['min_child_weight']\n",
    "    # gamma = params['gamma']\n",
    "    # reg_alpha = params['reg_alpha']\n",
    "    # reg_lambda = params['reg_lambda']\n",
    "    \n",
    "    param = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'max_depth': max_depth,\n",
    "        'eta': eta,\n",
    "        # 'min_child_weight':min_child_weight,\n",
    "        # 'gamma': gamma,\n",
    "        # 'reg_alpha':reg_alpha,\n",
    "        # 'reg_lambda': reg_lambda,\n",
    "              } \n",
    "\n",
    "    BF_models = []\n",
    "    pred_list = []\n",
    "    for fold_i in range(len(d_train_list)):\n",
    "        d_train = d_train_list[fold_i]                              #Dmatrix for each balanced fold\n",
    "        BF_models = xgb.train(param,\n",
    "                            d_train,\n",
    "                            num_boost_round = num_boost_round\n",
    "                            )\n",
    "                                                                    #Generates and fits a GBC for each training balanced fold\n",
    "        pred = BF_models[fold_i].predict(d_val)\n",
    "        MCC = matthews_corrcoef(d_val.get_label(), pred.round())\n",
    "        pred_list.append(MCC)\n",
    "    mean = np.mean(pred_list)\n",
    "    \n",
    "                                                                      \n",
    "    return {'loss': -mean, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_fitting(BF, d_train_list, d_val, MCC_eval_metric, fold, pickle_file): \n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds                      \n",
    "                d_train_list      List of balanced training feature folds in DMatrix\n",
    "                d_val             Validation data as Dmatrix\n",
    "                \n",
    "    Returns:    BF_GBC            List of gradient boosted models trained on each balancing fold\n",
    "\n",
    "    Create GBC model that returns probability predictions for each fold, using output of Balance_Folds() as training data (as Dmatrix)\n",
    "    \"\"\"     \n",
    "        \n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'tree_method': 'hist',\n",
    "    'objective': 'binary:logistic', \n",
    "    'disable_default_eval_metric': 1,\n",
    "    'verbosity': 0,\n",
    "    # 'eval_metric':['error'],\n",
    "    } \n",
    "    \n",
    "    \n",
    "    BF_GBC = []\n",
    "    \n",
    "    for fold_i in range(BF):\n",
    "        d_train = d_train_list[fold_i]                              #Dmatrix for each balanced fold\n",
    "        model = xgb.train(params,                                   #Generates and fits a GBC for each training balanced fold\n",
    "                          d_train, \n",
    "                          num_boost_round = 1500,\n",
    "                          evals  = [(d_val,'Model')],\n",
    "                          verbose_eval = False,               #Print evaluation metrics every 50 trees\n",
    "                          early_stopping_rounds = 100,\n",
    "                          custom_metric = MCC_eval_metric,\n",
    "                          )\n",
    "        \n",
    "        filename = f\"CV_{fold + 1}_model_{fold_i + 1}.pkl\"\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "            \n",
    "        BF_GBC.append(model)\n",
    "        pickle_file.append(filename)\n",
    "        \n",
    "    return BF_GBC, pickle_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0dd278c",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_predict(BF_GBC, d_val):\n",
    "    \"\"\" \n",
    "    Input:      BF_RFC            List of RFCs trained on balancing folds\n",
    "                d_val             Validation data as Dmatrix\n",
    "\n",
    "                \n",
    "    Returns:    Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "    Predicts the probabilty for every datapoint in the validation set.\n",
    "    \"\"\"\n",
    "    \n",
    "    Prob_matrix = []\n",
    "    for i in range(len(BF_GBC)):\n",
    "        Prob = BF_GBC[i].predict(d_val)     #Predicts the probability of an instance belonging to the major/ positive class (PD/ 1). Output has shape (n_predictions,)\n",
    "        Prob_matrix.append(Prob)   \n",
    "        \n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Vote(Prob_matrix):\n",
    "    \"\"\" \n",
    "    Input:      Prob_matrix     List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "\n",
    "    Returns:    Final_vote      Weighted vote classification\n",
    "\n",
    "    Calculate the final weighted vote using confidence scores (Sc) from Prob_matrix. Binary classification formula for:\n",
    "    Predictor states its prediction/ confidence scores are between 0.0 and 1.0 for each class\n",
    "    \"\"\"\n",
    "    PD_prob_matrix = Prob_matrix \n",
    "    \n",
    "    SNP_prob_matrix = []\n",
    "    for i in range(len(Prob_matrix)):               #SNP probabilites are 1 - (PD probabilites)\n",
    "        sub = 1 - Prob_matrix[i]\n",
    "        SNP_prob_matrix.append(sub)\n",
    "            \n",
    "    Sum_SNP = np.sum(SNP_prob_matrix, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(PD_prob_matrix, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "                                                    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                    #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                    #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)                 #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()                 #Flattens 2D array to 1D array\n",
    "\n",
    "    return(Final_vote, Sum_PD, Sum_SNP)             #Returns the final confidence scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CV_evaluation(d_val, Final_vote):\n",
    "    \"\"\" \n",
    "    Input:      d_val             Validation data as Dmatrix\n",
    "                Final_vote        Weighted vote classification\n",
    "                fold              CV fold number, defined in main program\n",
    "\n",
    "    Evaluates a CV fold's trained model with a classificaiton report, including the MCC\n",
    "    \"\"\"\n",
    "    Output_pred = Final_vote\n",
    "    TrueLabel   = d_val.get_label()\n",
    "        \n",
    "    # print(f\"-----------------------------------------------------\\n              ***CV Fold Evaluation***\\n\")\n",
    "    # print(f\"Confusion Matrix:\\n {confusion_matrix(TrueLabel, Output_pred)}\")\n",
    "    # print(f\"{classification_report(TrueLabel, Output_pred)}\\nMCC                  \n",
    "    CV_MCC = print(f\"CM:\\n{confusion_matrix(TrueLabel, Output_pred)}\\nMCC: {matthews_corrcoef(TrueLabel, Output_pred)}\\n\")\n",
    "    \n",
    "    return CV_MCC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6263665e",
   "metadata": {},
   "source": [
    "# Outer Loop: Final evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e2da2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_predict(d_test, pickle_file):\n",
    "    \"\"\" \n",
    "    Input:      all_model_list    List of all GBM models from all fold. 25 total\n",
    "                d_test            Unseen testing data as Dmatrix\n",
    "\n",
    "                \n",
    "    Returns:    fold_prob_matrix  List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                  2nd dimension is predicted probability\n",
    "    \n",
    "    Predicts the probabilty for every datapoint in the testing set.\n",
    "    \"\"\"\n",
    "    all_prob_matrix = []\n",
    "    all_models = []\n",
    "    \n",
    "    for file in pickle_file:\n",
    "        with open(file, \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "            all_models.append(model)\n",
    "            \n",
    "    for i in range(len(all_models)):\n",
    "        Prob = all_models[i].predict(d_test)     #Predicts the probability of an instance belonging to the major/ positive class (PD/ 1). Output has shape (n_predictions,)\n",
    "        all_prob_matrix.append(Prob)  \n",
    "        \n",
    "    return all_prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5ce9bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation(all_prob_matrix, TestLabels):\n",
    "    \"\"\" \n",
    "    Input:      all_prob_matrix    List of all predicted probabilites from all optimised models\n",
    "                TestLabels         True labels from unseen 20% testing data\n",
    "\n",
    "    Returns:    MCC_final          Final MCC evaluation\n",
    "\n",
    "    Calculate the final weighted vote using confidence scores (Sc) from all_prob_matrix. Then evaluates votes agains true labels to give the final MCC\n",
    "    \"\"\"\n",
    "    \n",
    "    # flat_list = [matrix for proba in all_prob_matrix for matrix in proba]\n",
    "    \n",
    "    PD_prob_matrix = all_prob_matrix\n",
    "\n",
    "    SNP_prob_matrix = []\n",
    "    for i in range(len(all_prob_matrix)):                 #SNP probabilites are 1 - (PD probabilites)\n",
    "        sub = 1 - all_prob_matrix[i]\n",
    "        SNP_prob_matrix.append(sub)\n",
    "            \n",
    "    Sum_SNP = np.sum(SNP_prob_matrix, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(PD_prob_matrix, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "                                                    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                    #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                    #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)                 #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()                 #Flattens 2D array to 1D array\n",
    "    \n",
    "    MCC_final = matthews_corrcoef(TestLabels, Final_vote)\n",
    "        \n",
    "    return(MCC_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53993642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(Score_list):\n",
    "     \"\"\" \n",
    "     Input:      Score_list        List of MCC scores\n",
    "\n",
    "     Plots the MCCs of 15 runs, and the average\n",
    "     \"\"\"\n",
    "     fig, ax = plt.subplots(figsize=(16,10), dpi= 65)\n",
    "     x_axis = range(len(Score_list))\n",
    "     y_axis = Score_list\n",
    "\n",
    "     plt.scatter(x_axis, y_axis, color = 'teal')\n",
    "     plt.axhline(y=np.nanmean(Score_list), color = 'red', linestyle = 'dotted', linewidth = '1', label ='Avg')\n",
    "     plt.xlabel('Run Number')\n",
    "     plt.ylabel('MCC')\n",
    "     plt.legend()\n",
    "     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e232",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a74965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.674588460710715\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.6755337554982468\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.6936972569025802\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.6817340528685172\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.6704438245588187\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.7022907167253678\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.6992673237149062\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.6920705415868966\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.6951677278236612\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.6776230875674507\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.6838012956264214\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.682222995805027\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.6910682675704842\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.6951677278236612\n",
      "Opening dataset...\n",
      "Performing Group fold validation...\n",
      "[Fold 0] Balancing...\n",
      "[Fold 0] Training...\n",
      "[Fold 1] Balancing...\n",
      "[Fold 1] Training...\n",
      "[Fold 2] Balancing...\n",
      "[Fold 2] Training...\n",
      "[Fold 3] Balancing...\n",
      "[Fold 3] Training...\n",
      "[Fold 4] Balancing...\n",
      "[Fold 4] Training...\n",
      "Testing...\n",
      "0.6981787810010054\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1040x650 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation:0.6981787810010054 ± 0.0\n",
      "\n",
      "Lowest score:0.6981787810010054\n",
      "Highest score:0.6981787810010054\n",
      "\n",
      "Run time: 279.2712264060974\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "Score_list = []\n",
    "pickle_file = []\n",
    "\n",
    "file_train = input(\"Enter file for training: \")\n",
    "file_test = input(\"Enter file for testing: \")\n",
    "    \n",
    "for i in range(0,15):\n",
    "    print(\"Opening dataset...\")\n",
    "    Training_Set, Testing_Set    = open_data(file_train, file_test)\n",
    "    d_test, TestData, TestLabels = test_dmatrix(Testing_Set)   \n",
    "\n",
    "    # test(Training_Set, d_test)\n",
    "    print(\"Performing Group fold cross validation...\")\n",
    "                \n",
    "    IT_list, LT_list, IV_list, LV_list = CV(Training_Set)     \n",
    "\n",
    "    for fold in range(len(IT_list)):          \n",
    "        inData = IT_list[fold]\n",
    "        classData = LT_list[fold]\n",
    "        ValData = IV_list[fold]\n",
    "        Vallabel = LV_list[fold]\n",
    "\n",
    "        #Validation\n",
    "        print(f\"[Fold {fold}] Balancing...\")\n",
    "        minClass, minSize, maxSize  = find_minority_class(classData)   \n",
    "        BF                          = Balance_ratio(maxSize, minSize)                        \n",
    "        Input_folds, Output_folds   = Balance_Folds(BF, inData, classData, minClass, minSize)\n",
    "        d_train_list, d_val         = GBM_dmatrix(BF, Input_folds, Output_folds, ValData, Vallabel)\n",
    "        \n",
    "        print(f\"[Fold {fold}] Training...\")\n",
    "        # space = hyperopt_space()\n",
    "        # trials = Trials()\n",
    "        # fmin_objective = partial(objective, d_train_list = d_train_list, d_val = d_val)\n",
    "        # best = fmin(fn = fmin_objective,\n",
    "        #             space = space,\n",
    "        #             algo = tpe.suggest,\n",
    "        #             max_evals = 100,\n",
    "        #             trials = trials,\n",
    "        #             )\n",
    "        # print(best)\n",
    "        BF_GBC, pickle_file         = BF_fitting(BF, d_train_list, d_val, MCC_eval_metric, fold, pickle_file)\n",
    "\n",
    "        Prob_matrix                 = BF_predict(BF_GBC, d_val)\n",
    "        Final_vote, Sum_PD, Sum_SNP = Weighted_Vote(Prob_matrix)\n",
    "        # CV_MCC = CV_evaluation(d_val, Final_vote)                        #prints classification report for all 5 folds\n",
    "        # CV_MCC\n",
    "        \n",
    "    #Testing\n",
    "    print(\"Testing...\") \n",
    "    all_prob_matrix = fold_predict(d_test, pickle_file) \n",
    "\n",
    "    MCC_final = final_evaluation(all_prob_matrix, TestLabels) \n",
    "    print(MCC_final) \n",
    "#loop  \n",
    "Score_list.append(MCC_final) \n",
    "     \n",
    "end = time.time()\n",
    "plot(Score_list)\n",
    "print(f\"Final evaluation:{np.mean(Score_list)} \\u00B1 {np.std(Score_list)}\\n\\nLowest score:{min(Score_list)}\\nHighest score:{max(Score_list)}\\n\\nRun time: {end-start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e5cd67c8584618c148c6f2b57de13817422ccd98975b320089863a41752ead79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
