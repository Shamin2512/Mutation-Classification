{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b71b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d94d2bb",
   "metadata": {},
   "source": [
    "Example 2 dataset \"AC_dataset\" is imbalanced 2:1: ~2200 PD and ~1100 SNP\n",
    "Full dataset \"Dataset_NoFeature\" is imbalanced 18:1: ~460000 PD and ~25000 SNP\n",
    "    Goal is to predict if mutation is SNP or PD\n",
    "    XG Boost\n",
    "        \n",
    "    Total samples: 3368\n",
    "    2254 PD samples\n",
    "    1111 SNP samples\n",
    "    3 NA samples\n",
    "\n",
    "Main branch (MCC ~0.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports the required libraries and packages \"\"\"\n",
    "\n",
    "import pandas as pd                                                              # Data manipulation in dataframes\n",
    "import numpy as np                                                               # Array manipulation\n",
    "import xgboost as xgb                                                            # Gradient boosting package\n",
    "import hyperopt\n",
    "\n",
    "import random as rd                                                              # Random seed generation\n",
    "import time                                                                      # Time program run time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,                                                           # MCC for evaluation\n",
    "    # balanced_accuracy_score, #hyperparameter evaluation\n",
    "    # f1_score,  #hyperparameter evaluation\n",
    "    accuracy_score,\n",
    "    confusion_matrix,                                                            # Confusion matrix for classification evalutation\n",
    "    classification_report                                                        # Return the F1, precision, and recall of a prediction\n",
    "    )\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,                                                            # Splits data frame into the training set and testing set\n",
    "    # GridSearchCV,  # Searches all hyperparameters\n",
    "    # RandomizedSearchCV, # Searches random range of hyperparameters\n",
    "    GroupKFold                                                                   # K-fold CV with as groups\n",
    "        )\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# from sklearn.ensemble import RandomForestClassifier                            # SK learn API for classificastion random forests\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK                                       # Functions for minimising cost functions\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "np.set_printoptions(precision = 3,threshold=np.inf, suppress=True)               # Full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbfacd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test_Split(file):\n",
    "    \"\"\"      \n",
    "    Input:      file             Pre-processed dataset done by PDB2AC script\n",
    "\n",
    "    Returns:    Training_Set     80% training set split\n",
    "                Testing_Set      20% testing set split\n",
    "                \n",
    "    80% training and 20% testing split. Splits are shuffled randomly and index reset\n",
    "    \"\"\"\n",
    "    AC_dataset                  = pd.read_csv(file, index_col=0)  \n",
    "    Training_Set                = AC_dataset\n",
    "        \n",
    "    Training_Set, Testing_Set   = train_test_split(AC_dataset,train_size = 0.8)\n",
    "        \n",
    "    Training_Set.reset_index(drop=True, inplace = True)         #Drop index to avoid training on index values\n",
    "    Testing_Set.reset_index(drop=True, inplace = True)          #Reset index after splitting for compatability with group fold CV\n",
    "    \n",
    "    Training_Set                = Training_Set.sample(frac = 1) #Shuffle data after splitting\n",
    "    Testing_Set                 = Testing_Set.sample(frac = 1)\n",
    "    \n",
    "    \n",
    "    return Training_Set, Testing_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466d455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dmatrix(Testing_Set):\n",
    "    \"\"\"      \n",
    "    Input:      Testing_Set      20% testing set split\n",
    "\n",
    "    Returns:    d_test           Testing data in dmatrix \n",
    "                TestData         Testing features \n",
    "                TestLabels       Testing labels\n",
    "            \n",
    "    Testing set as dmatrix for XGBoost API compatabillity\n",
    "    \"\"\"\n",
    "    TestData     = Testing_Set.drop(['AC Code','dataset'], axis =1)  \n",
    "    TestLabels   = Testing_Set['dataset']                                \n",
    "    \n",
    "    d_test = xgb.DMatrix(TestData, TestLabels)\n",
    "    \n",
    "    return (d_test, TestData, TestLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(Training_Set, d_test):\n",
    "    \"\"\" \n",
    "    Input:      Training_Set     80% training set split\n",
    "                d_test           Testing data in dmatrix\n",
    "\n",
    "    Evaluate training data before CV and balancing. Gradient boosting for prediction on the test data. \n",
    "    True values are testing data class labels\n",
    "    \"\"\"    \n",
    "    TrainData     = Training_Set.drop(['AC Code','dataset'], axis =1)  \n",
    "    TrainLabels   = Training_Set['dataset']\n",
    "    d_train = xgb.DMatrix(TrainData, TrainLabels)\n",
    "\n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:hinge', \n",
    "    }\n",
    "    XGB_initial = xgb.train(params, d_train)\n",
    "    \n",
    "    Output_pred = XGB_initial.predict(d_test)\n",
    "    print(f\"              **Initial Evaluation**\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(d_test.get_label(), Output_pred)}\")\n",
    "    print(f\"MCC              {matthews_corrcoef(d_test.get_label(), Output_pred)}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05b3a2df",
   "metadata": {},
   "source": [
    "# Outer Loop: Group Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975ff775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(Training_Set):\n",
    "    \"\"\"      \n",
    "    Input:      Training_Set     80% training set split\n",
    "            \n",
    "    Returns:    IT_list         List of training features for each fold\n",
    "                LT_list         List of training class labels for each fold\n",
    "                IV_list         List of validation features for each fold\n",
    "                LV_list         List of validation class labels for each fold\n",
    "\n",
    "    K-fold CV with protein groups separated between training and validation sets for each fold. Creates 5 folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    features     = Training_Set.drop(['dataset'], axis =1)         #Features for training\n",
    "    labels       = Training_Set['dataset']                         #Class labels for training\n",
    "    groups       = Training_Set['AC Code'].to_list()               #List of proteins for grouping\n",
    "    \n",
    "    CV           = GroupKFold(n_splits = 5)                        #Creates 5 splits\n",
    "    \n",
    "    IT_list      = []\n",
    "    LT_list      = []\n",
    "    IV_list      = []\n",
    "    LV_list      = []\n",
    "    \n",
    "    for train_idx, val_idx in CV.split(features, labels, groups):       #Generates the indices to be used for a training and validation split. Indicies are unique to train/ val sets\n",
    "\n",
    "        Input_train                        = features.loc[train_idx]    #New dataframe from selected indices\n",
    "        Classes_train                      = labels.loc[train_idx]\n",
    "        Input_train.drop(['AC Code'], axis = 1, inplace = True)         #Group identifer not needed for training\n",
    "\n",
    "                \n",
    "        Input_val                          = features.loc[val_idx]\n",
    "        Classes_val                        = labels.loc[val_idx]\n",
    "        Input_val.drop(['AC Code'], axis   = 1, inplace = True)\n",
    "        \n",
    "        Input_train.reset_index(drop = True, inplace = True)            #Reset index of each set for compatability with balancing\n",
    "        Classes_train.reset_index(drop = True, inplace = True)\n",
    "        Input_val.reset_index(drop = True, inplace = True)\n",
    "        Classes_val.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        IT_list.append(Input_train)       \n",
    "        LT_list.append(Classes_train)\n",
    "        IV_list.append(Input_val)\n",
    "        LV_list.append(Classes_val)\n",
    "    \n",
    "    return(IT_list, LT_list, IV_list, LV_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "# Inner Loop:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16250cbe",
   "metadata": {},
   "source": [
    "### Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" \n",
    "    Input:        classData  Array of class labels\n",
    "\n",
    "    Returns:      minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "\n",
    "    Find information about class size imbalance\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize  = Minority_count\n",
    "    maxSize  = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize  = Majority_count\n",
    "        maxSize  = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:        inData          Dataframe of input data\n",
    "                  classData       Series of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "\n",
    "    Returns:      usedLines       array of indexes that are of interest for a balanced dataset\n",
    "\n",
    "    Perform the actual balancing for a fold between SNPs and PDs\n",
    "    \"\"\"\n",
    "    usedLines = [False] * len(inData)      #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData[i] == minClass:       #Balance directly with dataframe\n",
    "            usedLines[i] = True            #True lines are SNP\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedLines[i] = True\n",
    "            usedCount += 1                 #Set PD lines \"True\", until equal to number of SNP lines\n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    \"\"\"     \n",
    "    Input:      inData         Datframe of input training data\n",
    "                classData      Series of classes assigned to training data\n",
    "                usedLines      Array of line indexes to print\n",
    "\n",
    "    Returns:    input_balance  Dataframe of balanced training features\n",
    "                label_balance  Dataframe of balanced training labels\n",
    "                       \n",
    "    Create dataframe of the input training data and classes used. Index_list tracks the indicies between usedLines and inData, used to pull the required5 lines.\n",
    "    \"\"\"\n",
    "    input_balance = []\n",
    "    label_balance = []\n",
    "    index_list = []\n",
    "    \n",
    "    for i in range(len(usedLines)):\n",
    "        if usedLines[i] == True:\n",
    "            index_list.append(i)\n",
    "             \n",
    "    input_balance = inData.iloc[index_list].reset_index(inplace = False, drop = True)\n",
    "    label_balance = classData.iloc[index_list].reset_index(inplace = False, drop = True) \n",
    "    \n",
    "    return input_balance, label_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_ratio(maxSize, minSize): \n",
    "    \"\"\" \n",
    "    Input:      maxSize     The number of items in the majority class\n",
    "                minSize     The number of items in the minority class\n",
    "\n",
    "    Returns:    BF          Number of balancing folds\n",
    "\n",
    "    Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "    majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "    \"\"\"\n",
    "    Divide = maxSize/minSize\n",
    "    BF = (2 * round(Divide)) + 1    #Double ratio to nearest integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Balance_Folds(BF, inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                inData            Datframe of input training data\n",
    "                classData         Series of classes assigned to training data\n",
    "                minClass          The label for the minority class\n",
    "                minSize           The number of items in the minority class\n",
    "                                  \n",
    "    Returns:    Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "\n",
    "    Runs balance_data() for the number of balancing folds. Return lists of balanced folds features and labels\n",
    "    where each item is the output of balance_data()\n",
    "    \"\"\"\n",
    "    Input_folds  = []\n",
    "    Output_folds = []\n",
    "\n",
    "    for i in range(BF):\n",
    "        usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "        input_balance, label_balance = balance_data(inData, classData, usedLines)\n",
    "        \n",
    "        Input_folds.append(input_balance)\n",
    "        Output_folds.append(label_balance)\n",
    "            \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21cd1aaa",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ede39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBM_dmatrix(BF, Input_folds, Output_folds, ValData, Vallabel):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "                ValData           Validation features from CV fold\n",
    "                ValLabel          Valiadation labels from CV fold\n",
    "                                  \n",
    "    Returns:    d_train_list      List of balanced training feature folds as DMatrix\n",
    "                d_val             Validation data as Dmatrix\n",
    "\n",
    "    Converts the balanced training data and validation data into Dmatrix for model training and evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    d_train_list =[]\n",
    "    \n",
    "    for i in range(BF):\n",
    "        d_train = xgb.DMatrix(Input_folds[i], Output_folds[i])      #Create DMatrix for each training balanced fold\n",
    "        d_train_list.append(d_train)\n",
    "    d_val = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "    return (d_train_list, d_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb2003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCC_eval_metric(pred, d_val):\n",
    "    \"\"\" \n",
    "    Input:      pred              Prediction from a boosted tree during training\n",
    "                d_val             Validation data as Dmatrix\n",
    "    \n",
    "    Returns:    mcc               The MCC from a boosted tree round\n",
    "\n",
    "    MCC as a custom evaluation metric to evaluate model training during cross validation. This is different from the final weighted vote evaluation.\n",
    "    \"\"\"\n",
    "    true_label = d_val.get_label()   \n",
    "    pred_label = np.round(pred) \n",
    "    \n",
    "    return 'mcc', matthews_corrcoef(pred_label, true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0840d9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hyperopt_space():\n",
    "    \"\"\" \n",
    "    Returns:    Space         Parameter space for hyperopt searching\n",
    "\n",
    "    Define paramater psace for hyperopt tuning\n",
    "   \"\"\"  \n",
    "#   params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:logistic', \n",
    "#     # 'learning_rate': 0.3,\n",
    "#     # 'max_depth': 5,\n",
    "#     }\n",
    "#   for i in range(BF):        \n",
    "#     BF_GBC_HP = xgb.cv(\n",
    "#         params,\n",
    "#         d_train_list[i],\n",
    "#         nfold = 5,\n",
    "#         num_boost_round= 500,\n",
    "#         early_stopping_rounds= 20,\n",
    "#         custom_metric = CM, \n",
    "#         as_pandas=True,\n",
    "#     )\n",
    "  \n",
    "#   return(BF_GBC_HP) \n",
    "\n",
    "    space = {\n",
    "        'max_depth': hp.quniform('max_depth', 3, 18),\n",
    "        # 'eta': hp.loguniform('eta', -7, 0),\n",
    "        # 'min_child_weight': hp.loguniform('min_child_weight', -1, 7),\n",
    "        # 'gamma': hp.loguniform ('gamma', -10, 10),\n",
    "        # 'reg_alpha': hp.loguniform('reg_alpha', -10, 10),\n",
    "        # 'reg_lambda': hp.loguniform('reg_lambda', -10, 10),\n",
    "        }     \n",
    "    \n",
    "    return space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54010b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_optimise(BF, d_train_list, d_val, space): \n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds                      \n",
    "                d_train_list      List of balanced training feature folds in DMatrix\n",
    "                d_val             Validation data as Dmatrix\n",
    "                \n",
    "    Returns:    BF_GBC            List of gradient boosted models trained on each balancing fold\n",
    "\n",
    "    Create GBC model that returns probability predictions for each fold, using output of Balance_Folds() as training data (as Dmatrix)\n",
    "    \"\"\"     \n",
    "    \n",
    "    params = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'error',\n",
    "        'disable_default_eval_metric': 0,\n",
    "        'verbosity': 1,\n",
    "        'max_depth': space['max_depth'],\n",
    "              } \n",
    "        # 'gamma': space['gamma'],\n",
    "        # 'alpha': space['alpha'],\n",
    "        # 'lambda': space['lambda'],\n",
    "        # 'colsample_bytree': space['colsample_bytree'],\n",
    "        # 'min_child_weight': space['min_child_weight'],\n",
    "    \n",
    "    BF_models = []\n",
    "    # for fold_i in range(BF):\n",
    "    d_train = d_train_list[0]                              #Dmatrix for each balanced fold\n",
    "    BF_models = xgb.train(params,\n",
    "                          d_train,\n",
    "                          num_boost_round = 1000,\n",
    "                          evals  = [(d_val,'Model')],\n",
    "                          verbose_eval = False,\n",
    "                          early_stopping_rounds = 10,\n",
    "                          )\n",
    "                                                                 #Generates and fits a GBC for each training balanced fold\n",
    "    # pred_list = []\n",
    "    # for i in len(range(BF_models)):\n",
    "    pred = BF_models.predict(d_val)\n",
    "    accuracy_score = (d_val.get_label(), pred > 0.5)\n",
    "                                                                      \n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_fitting(BF, d_train_list, d_val, MCC_eval_metric): \n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds                      \n",
    "                d_train_list      List of balanced training feature folds in DMatrix\n",
    "                d_val             Validation data as Dmatrix\n",
    "                \n",
    "    Returns:    BF_GBC            List of gradient boosted models trained on each balancing fold\n",
    "\n",
    "    Create GBC model that returns probability predictions for each fold, using output of Balance_Folds() as training data (as Dmatrix)\n",
    "    \"\"\"     \n",
    "        \n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic', \n",
    "    'disable_default_eval_metric': 1,\n",
    "    'verbosity': 0,\n",
    "    # 'eval_metric':['error'],\n",
    "    } \n",
    "    \n",
    "    \n",
    "    BF_GBC = []\n",
    "    for fold_i in range(BF):\n",
    "        d_train = d_train_list[fold_i]                              #Dmatrix for each balanced fold\n",
    "        BF_GBC.append(xgb.train(params, \n",
    "                                d_train, \n",
    "                                num_boost_round = 1500,\n",
    "                                evals  = [(d_val,'Model')],\n",
    "                                verbose_eval = False,               #Print evaluation metrics every 50 trees\n",
    "                                early_stopping_rounds = 100,\n",
    "                                custom_metric = MCC_eval_metric, \n",
    "                                )\n",
    "                      )                                             #Generates and fits a GBC for each training balanced fold\n",
    "    return BF_GBC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0dd278c",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_predict(BF_GBC, d_val):\n",
    "    \"\"\" \n",
    "    Input:      BF_RFC            List of RFCs trained on balancing folds\n",
    "                d_val             Validation data as Dmatrix\n",
    "\n",
    "                \n",
    "    Returns:    Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "    Predicts the probabilty for every datapoint in the validation set.\n",
    "    \"\"\"\n",
    "    \n",
    "    Prob_matrix = []\n",
    "    for i in range(len(BF_GBC)):\n",
    "        Prob = BF_GBC[i].predict(d_val)     #Predicts the probability of an instance belonging to the major/ positive class (PD/ 1). Output has shape (n_predictions,)\n",
    "        Prob_matrix.append(Prob)   \n",
    "        \n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Vote(Prob_matrix):\n",
    "    \"\"\" \n",
    "    Input:      Prob_matrix     List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "\n",
    "    Returns:    Final_vote      Weighted vote classification\n",
    "\n",
    "    Calculate the final weighted vote using confidence scores (Sc) from Prob_matrix. Binary classification formula for:\n",
    "    Predictor states its prediction/ confidence scores are between 0.0 and 1.0 for each class\n",
    "    \"\"\"\n",
    "    PD_prob_matrix = Prob_matrix \n",
    "    \n",
    "    SNP_prob_matrix = []\n",
    "    for i in range(len(Prob_matrix)):               #SNP probabilites are 1 - (PD probabilites)\n",
    "        sub = 1 - Prob_matrix[i]\n",
    "        SNP_prob_matrix.append(sub)\n",
    "            \n",
    "    Sum_SNP = np.sum(SNP_prob_matrix, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(PD_prob_matrix, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "                                                    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                    #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                    #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)                 #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()                 #Flattens 2D array to 1D array\n",
    "\n",
    "    return(Final_vote, Sum_PD, Sum_SNP)             #Returns the final confidence scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CV_evaluation(d_val, Final_vote):\n",
    "    \"\"\" \n",
    "    Input:      d_val             Validation data as Dmatrix\n",
    "                Final_vote        Weighted vote classification\n",
    "                fold              CV fold number, defined in main program\n",
    "\n",
    "    Evaluates a CV fold's trained model with a classificaiton report, including the MCC\n",
    "    \"\"\"\n",
    "    Output_pred = Final_vote\n",
    "    TrueLabel   = d_val.get_label()\n",
    "        \n",
    "    # print(f\"-----------------------------------------------------\\n              ***CV Fold Evaluation***\\n\")\n",
    "    # print(f\"Confusion Matrix:\\n {confusion_matrix(TrueLabel, Output_pred)}\")\n",
    "    # print(f\"{classification_report(TrueLabel, Output_pred)}\\nMCC                  \n",
    "    CV_MCC = matthews_corrcoef(TrueLabel, Output_pred)\n",
    "    \n",
    "    return CV_MCC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6263665e",
   "metadata": {},
   "source": [
    "# Outer Loop: Final evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e2da2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_predict(BF_GBC, d_test):\n",
    "    \"\"\" \n",
    "    Input:      BF_RFC            List of RFCs trained on balancing folds\n",
    "                d_test            Unseen testing data as Dmatrix\n",
    "\n",
    "                \n",
    "    Returns:    Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "    Predicts the probabilty for every datapoint in the testing set.\n",
    "    \"\"\"\n",
    "    \n",
    "    fold_prob_matrix = []\n",
    "    for i in range(len(BF_GBC)):\n",
    "        Prob = BF_GBC[i].predict(d_test)     #Predicts the probability of an instance belonging to the major/ positive class (PD/ 1). Output has shape (n_predictions,)\n",
    "        fold_prob_matrix.append(Prob)   \n",
    "        \n",
    "    return fold_prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5ce9bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation(all_prob_matrix, TestLabels):\n",
    "    \"\"\" \n",
    "    Input:      all_prob_matrix    List of all predicted probabilites from all optimised models\n",
    "                TestLabels         True labels from unseen 20% testing data\n",
    "\n",
    "    Returns:    MCC_final          Final MCC evaluation\n",
    "\n",
    "    Calculate the final weighted vote using confidence scores (Sc) from all_prob_matrix. Then evaluates votes agains true labels to give the final MCC\n",
    "    \"\"\"\n",
    "    \n",
    "    flat_list = [matrix for proba in all_prob_matrix for matrix in proba]\n",
    "    \n",
    "    PD_prob_matrix = flat_list \n",
    "\n",
    "    SNP_prob_matrix = []\n",
    "    for i in range(len(flat_list)):                 #SNP probabilites are 1 - (PD probabilites)\n",
    "        sub = 1 - flat_list[i]\n",
    "        SNP_prob_matrix.append(sub)\n",
    "            \n",
    "    Sum_SNP = np.sum(SNP_prob_matrix, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(PD_prob_matrix, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "                                                    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                    #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                    #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)                 #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()                 #Flattens 2D array to 1D array\n",
    "    \n",
    "    MCC_final = matthews_corrcoef(TestLabels, Final_vote)\n",
    "        \n",
    "    return(MCC_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53993642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(Score_list):\n",
    "     \"\"\" \n",
    "     Input:      Score_list        List of MCC scores\n",
    "\n",
    "     Plots the MCCs of 15 runs, and the average\n",
    "     \"\"\"\n",
    "     fig, ax = plt.subplots(figsize=(16,10), dpi= 65)\n",
    "     x_axis = range(len(Score_list))\n",
    "     y_axis = Score_list\n",
    "\n",
    "     plt.scatter(x_axis, y_axis, color = 'teal')\n",
    "     plt.axhline(y=np.nanmean(Score_list), color = 'red', linestyle = 'dotted', linewidth = '1', label ='Avg')\n",
    "     plt.xlabel('Run Number')\n",
    "     plt.ylabel('MCC')\n",
    "     plt.legend()\n",
    "     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e232",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a74965e",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "Invalid Parameter format for max_depth expect int but value='0 float\n1   hyperopt_param\n2     Literal{max_depth}\n3     quniform\n4       Literal{3}\n5       Literal{18}'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m d_train_list, d_val         \u001b[39m=\u001b[39m GBM_dmatrix(BF, Input_folds, Output_folds, ValData, Vallabel)\n\u001b[0;32m     23\u001b[0m space \u001b[39m=\u001b[39m hyperopt_space()\n\u001b[1;32m---> 25\u001b[0m accuracy_score \u001b[39m=\u001b[39m BF_optimise(BF, d_train_list, d_val, space)\n\u001b[0;32m     26\u001b[0m trials \u001b[39m=\u001b[39m Trials()\n\u001b[0;32m     27\u001b[0m best \u001b[39m=\u001b[39m fmin(fn \u001b[39m=\u001b[39m accuracy_score,\n\u001b[0;32m     28\u001b[0m             space \u001b[39m=\u001b[39m space,\n\u001b[0;32m     29\u001b[0m             algo \u001b[39m=\u001b[39m tpe\u001b[39m.\u001b[39msuggest,\n\u001b[0;32m     30\u001b[0m             max_evals \u001b[39m=\u001b[39m \u001b[39m140\u001b[39m,\n\u001b[0;32m     31\u001b[0m             trials \u001b[39m=\u001b[39m trials,\n\u001b[0;32m     32\u001b[0m             )\n",
      "Cell \u001b[1;32mIn[15], line 29\u001b[0m, in \u001b[0;36mBF_optimise\u001b[1;34m(BF, d_train_list, d_val, space)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39m# for fold_i in range(BF):\u001b[39;00m\n\u001b[0;32m     28\u001b[0m d_train \u001b[39m=\u001b[39m d_train_list[\u001b[39m0\u001b[39m]                              \u001b[39m#Dmatrix for each balanced fold\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m BF_models \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39;49mtrain(params,\n\u001b[0;32m     30\u001b[0m                       d_train,\n\u001b[0;32m     31\u001b[0m                       num_boost_round \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m,\n\u001b[0;32m     32\u001b[0m                       evals  \u001b[39m=\u001b[39;49m [(d_val,\u001b[39m'\u001b[39;49m\u001b[39mModel\u001b[39;49m\u001b[39m'\u001b[39;49m)],\n\u001b[0;32m     33\u001b[0m                       verbose_eval \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     34\u001b[0m                       early_stopping_rounds \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m,\n\u001b[0;32m     35\u001b[0m                       )\n\u001b[0;32m     36\u001b[0m                                                              \u001b[39m#Generates and fits a GBC for each training balanced fold\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39m# pred_list = []\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39m# for i in len(range(BF_models)):\u001b[39;00m\n\u001b[0;32m     39\u001b[0m pred \u001b[39m=\u001b[39m BF_models\u001b[39m.\u001b[39mpredict(d_val)\n",
      "File \u001b[1;32mc:\\Users\\Shamin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Shamin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:180\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    168\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    169\u001b[0m         EarlyStopping(rounds\u001b[39m=\u001b[39mearly_stopping_rounds, maximize\u001b[39m=\u001b[39mmaximize)\n\u001b[0;32m    170\u001b[0m     )\n\u001b[0;32m    171\u001b[0m cb_container \u001b[39m=\u001b[39m CallbackContainer(\n\u001b[0;32m    172\u001b[0m     callbacks,\n\u001b[0;32m    173\u001b[0m     metric\u001b[39m=\u001b[39mmetric_fn,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m     output_margin\u001b[39m=\u001b[39m\u001b[39mcallable\u001b[39m(obj) \u001b[39mor\u001b[39;00m metric_fn \u001b[39mis\u001b[39;00m feval,\n\u001b[0;32m    178\u001b[0m )\n\u001b[1;32m--> 180\u001b[0m bst \u001b[39m=\u001b[39m cb_container\u001b[39m.\u001b[39;49mbefore_training(bst)\n\u001b[0;32m    182\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_iteration, num_boost_round):\n\u001b[0;32m    183\u001b[0m     \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n",
      "File \u001b[1;32mc:\\Users\\Shamin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\callback.py:148\u001b[0m, in \u001b[0;36mCallbackContainer.before_training\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Function called before training.'''\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m--> 148\u001b[0m     model \u001b[39m=\u001b[39m c\u001b[39m.\u001b[39;49mbefore_training(model\u001b[39m=\u001b[39;49mmodel)\n\u001b[0;32m    149\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbefore_training should return the model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    150\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_cv:\n",
      "File \u001b[1;32mc:\\Users\\Shamin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\callback.py:350\u001b[0m, in \u001b[0;36mEarlyStopping.before_training\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbefore_training\u001b[39m(\u001b[39mself\u001b[39m, model: _Model) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _Model:\n\u001b[1;32m--> 350\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarting_round \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mnum_boosted_rounds()\n\u001b[0;32m    351\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Shamin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:2469\u001b[0m, in \u001b[0;36mBooster.num_boosted_rounds\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2467\u001b[0m rounds \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[0;32m   2468\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2469\u001b[0m _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterBoostedRounds(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, ctypes\u001b[39m.\u001b[39;49mbyref(rounds)))\n\u001b[0;32m   2470\u001b[0m \u001b[39mreturn\u001b[39;00m rounds\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\Shamin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: Invalid Parameter format for max_depth expect int but value='0 float\n1   hyperopt_param\n2     Literal{max_depth}\n3     quniform\n4       Literal{3}\n5       Literal{18}'"
     ]
    }
   ],
   "source": [
    "Score_list = []\n",
    "start = time.time()\n",
    "# for i in range(0,15):\n",
    "file                               = \"AC_dataset.csv\"\n",
    "Training_Set, Testing_Set          = Train_Test_Split(file)\n",
    "d_test, TestData, TestLabels = test_dmatrix(Testing_Set)   \n",
    "\n",
    "# test(Training_Set, d_test)               \n",
    "IT_list, LT_list, IV_list, LV_list = CV(Training_Set)     \n",
    "\n",
    "all_prob_matrix = []\n",
    "for fold in range(len(IT_list)):          \n",
    "    inData = IT_list[fold]\n",
    "    classData = LT_list[fold]\n",
    "    ValData = IV_list[fold]\n",
    "    Vallabel = LV_list[fold]\n",
    "\n",
    "    #Validation\n",
    "    minClass, minSize, maxSize  = find_minority_class(classData)   \n",
    "    BF                          = Balance_ratio(maxSize, minSize)                        \n",
    "    Input_folds, Output_folds   = Balance_Folds(BF, inData, classData, minClass, minSize)\n",
    "    d_train_list, d_val         = GBM_dmatrix(BF, Input_folds, Output_folds, ValData, Vallabel)\n",
    "    space = hyperopt_space()\n",
    "    \n",
    "    accuracy_score = BF_optimise(BF, d_train_list, d_val, space)\n",
    "    trials = Trials()\n",
    "    best = fmin(fn = accuracy_score,\n",
    "                space = space,\n",
    "                algo = tpe.suggest,\n",
    "                max_evals = 140,\n",
    "                trials = trials,\n",
    "                )\n",
    "    \n",
    "    BF_GBC                      = BF_fitting(BF, d_train_list, d_val, MCC_eval_metric)\n",
    "    Prob_matrix                 = BF_predict(BF_GBC, d_val)\n",
    "    Final_vote, Sum_PD, Sum_SNP = Weighted_Vote(Prob_matrix)\n",
    "    CV_MCC = CV_evaluation(d_val, Final_vote)                #prints classification report for all 5 folds\n",
    "\n",
    "    #Testing\n",
    "    fold_prob_matrix = fold_predict(BF_GBC, d_test)\n",
    "    all_prob_matrix.append(fold_prob_matrix)\n",
    "    MCC_final = final_evaluation(all_prob_matrix, TestLabels)\n",
    "    print(MCC_final)\n",
    "    \n",
    "    Score_list.append(MCC_final)  \n",
    "end = time.time()\n",
    "# plot(Score_list)\n",
    "print(f\"Final evaluation:{np.mean(Score_list)} \\u00B1 {np.std(Score_list)}\\n\\nLowest score:{min(Score_list)}\\nHighest score:{max(Score_list)}\\n\\nRun time: {end-start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e5cd67c8584618c148c6f2b57de13817422ccd98975b320089863a41752ead79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
