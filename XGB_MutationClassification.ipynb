{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d94d2bb",
   "metadata": {},
   "source": [
    "Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "    Goal is to predict if mutation is SNP or PD\n",
    "    XG Boost\n",
    "        \n",
    "    Total samples: 3368\n",
    "    2254 PD samples\n",
    "    1111 SNP samples\n",
    "    3 NA samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports the required libraries and packages \"\"\"\n",
    "\n",
    "import pandas as pd                                                              # Data manipulation in dataframes\n",
    "import numpy as np                                                               # Array manipulation\n",
    "import xgboost as xgb                                                            # Gradient boosting package\n",
    "\n",
    "import random as rd                                                              # Random seed generation\n",
    "import time                                                                      # Time program run time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,                                                           # MCC for evaluation\n",
    "    # balanced_accuracy_score, #hyperparameter evaluation\n",
    "    # f1_score,  #hyperparameter evaluation\n",
    "    confusion_matrix,                                                            # Confusion matrix for classification evalutation\n",
    "    classification_report                                                        # Return the F1, precision, and recall of a prediction\n",
    "    )\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,                                                            # Splits data frame into the training set and testing set\n",
    "    # GridSearchCV,  # Searches all hyperparameters\n",
    "    # RandomizedSearchCV, # Searches random range of hyperparameters\n",
    "    GroupKFold                                                                   # K-fold CV with as groups\n",
    "        )\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# from sklearn.ensemble import RandomForestClassifier                              # SK learn API for classificastion random forests\n",
    "\n",
    "np.set_printoptions(precision = 3,threshold=np.inf, suppress=True)               # Full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfacd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test_Split(file):\n",
    "    \"\"\"      \n",
    "    Input:      file             Pre-processed dataset done by PDB2AC script\n",
    "\n",
    "    Returns:    Training_Set     80% training set split\n",
    "                Testing_Set      20% testing set split\n",
    "                \n",
    "    80% training and 20% testing split. Splits are shuffled randomly and index reset\n",
    "    \"\"\"\n",
    "    AC_dataset                  = pd.read_csv(file, index_col=0)  \n",
    "    Training_Set, Testing_Set   = train_test_split(AC_dataset,train_size = 0.8)\n",
    "    \n",
    "    Training_Set.reset_index(drop=True, inplace = True) #Drop index to avoid training on index values\n",
    "    Testing_Set.reset_index(drop=True, inplace = True)  #Reset index after splitting for compatability with CV()\n",
    "        \n",
    "    Training_Set                = Training_Set.sample(frac = 1) #Shuffle data after splitting\n",
    "    Testing_Set                 = Testing_Set.sample(frac = 1)\n",
    "    \n",
    "    return Training_Set, Testing_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89126467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(Training_Set, Testing_Set):\n",
    "    \n",
    "    train_features     = Training_Set.drop(['AC Code','dataset'], axis =1)        #Features for training\n",
    "    train_labels       = Training_Set['dataset']                                  #Class labels for training\n",
    "    groups             = Training_Set['AC Code'].to_list()                        #List of proteins for grouping\n",
    "    \n",
    "    test_features     = Testing_Set.drop(['AC Code','dataset'], axis =1)         #Features for testing\n",
    "    test_labels       = Testing_Set['dataset']                                   #Class labels for testing\n",
    "        \n",
    "    return(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(inData, classData, ValData, Vallabel):\n",
    "    \"\"\" \n",
    "    Input:  Training_Set   Training data\n",
    "            Testing_Set    Testing data\n",
    "\n",
    "    Evaluate training data before CV and balancing. Gradient boosting for prediction on the test data. \n",
    "    True values are testing data class labels\n",
    "    \"\"\"    \n",
    "    d_train = xgb.DMatrix(inData, classData)\n",
    "    d_test = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:hinge', \n",
    "    }\n",
    "    XGB_initial = xgb.train(params, d_train)\n",
    "    \n",
    "    Output_pred = XGB_initial.predict(d_test)\n",
    "    print(f\"              **Initial Evaluation**\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(Vallabel, Output_pred)}\")\n",
    "    print(f\"MCC              {matthews_corrcoef(Vallabel, Output_pred)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3a2df",
   "metadata": {},
   "source": [
    "## Group K-fold CV (outer loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975ff775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def CV(Training_Set):\n",
    "#     \"\"\"      \n",
    "#     Input:      Training_Set     80% training set split\n",
    "            \n",
    "#     Returns:    IT_list         List of training features for each fold\n",
    "#                 LT_list         List of training class labels for each fold\n",
    "#                 IV_list         List of validation features for each fold\n",
    "#                 LV_list         List of validation class labels for each fold\n",
    "\n",
    "#     K-fold CV with protein groups separated between training and validation sets for each fold. Creates 5 folds.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     features     = Training_Set.drop(['AC Code','dataset'], axis =1)         #Features for training\n",
    "#     labels       = Training_Set['dataset']                         #Class labels for training\n",
    "#     groups       = Training_Set['AC Code'].to_list()               #List of proteins for grouping\n",
    "    \n",
    "#     params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:hinge', \n",
    "#     }\n",
    "    \n",
    "#     d_train = xgb.DMatrix(features, labels)\n",
    "#     xgb_model = xgb.train(params, d_train)\n",
    "        \n",
    "#     CV = xgb.cv(\n",
    "#         params=params,\n",
    "#         dtrain = d_train,\n",
    "#         nfold = 5,\n",
    "#         early_stopping_rounds= 20,\n",
    "#         metrics='error',\n",
    "#         as_pandas=True,\n",
    "#     )\n",
    "    \n",
    "#     print(CV)\n",
    "        \n",
    "#     # CV             = GroupKFold(n_splits = 5)                           #Creates 5 splits\n",
    "    \n",
    "#     # IT_list = []\n",
    "#     # LT_list = []\n",
    "#     # IV_list = []\n",
    "#     # LV_list = []\n",
    "    \n",
    "#     # for train_idx, val_idx in CV.split(Input_CV, Output_CV, Protein_Groups): #Generates the indices to be used for a training and validation split. Indicies are unique to train/ val sets\n",
    "        \n",
    "#     #     Rd = np.random.randint(time.time())                                  #Random number from 1 to time since epoch\n",
    "\n",
    "#     #     Input_train                        = Input_CV.loc[train_idx]         #New dataframe from selected indices\n",
    "#     #     Classes_train                      = Output_CV.loc[train_idx]\n",
    "#     #     Input_train.drop(['AC Code'], axis = 1, inplace = True)              #Group identifer not needed for training\n",
    "                \n",
    "#     #     Input_val                          = Input_CV.loc[val_idx]\n",
    "#     #     Classes_val                        = Output_CV.loc[val_idx]\n",
    "#     #     Input_val.drop(['AC Code'], axis   = 1, inplace = True)\n",
    "\n",
    "#     #     IT_list.append(Input_train.sample(frac=1, random_state=Rd))          #Shuffles lists, random state to ensure features and labels match for each fold\n",
    "#     #     LT_list.append(Classes_train.sample(frac=1, random_state=Rd))\n",
    "#     #     IV_list.append(Input_val.sample(frac=1, random_state=(Rd-1)))\n",
    "#     #     LV_list.append(Classes_val.sample(frac=1, random_state=(Rd-1)))\n",
    "        \n",
    "\n",
    "#     return(xgb_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "## Balancing (inner loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" \n",
    "    Input:        classData  Array of class labels\n",
    "\n",
    "    Returns:      minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "\n",
    "    Find information about class size imbalance\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize  = Minority_count\n",
    "    maxSize  = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize  = Majority_count\n",
    "        maxSize  = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:        inData          array of input data\n",
    "                  classData       array of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "\n",
    "    Returns:      array of indexes that are of interest for a balanced dataset\n",
    "\n",
    "    Perform the actual balancing for a fold between SNPs and PDs\n",
    "    \"\"\"\n",
    "    usedLines = [False] * len(inData) #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData.values[i] == minClass:\n",
    "            usedLines[i] = True            #True lines are SNP\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedLines[i] = True\n",
    "            usedCount += 1          #Set PD lines \"True\", until equal to number of SNP lines\n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    \"\"\"     \n",
    "    Input:      inData      array of input training data\n",
    "                classData   array of classes assigned to training data\n",
    "                usedLines   array of line indexes to print\n",
    "\n",
    "    Returns:    input_balance  Dataframe of balanced training features\n",
    "                label_balance  Dataframe of balanced training labels\n",
    "                       \n",
    "    Create dataframe of the input training data and classes used. The index [i] is the identifier between the two arrays.\n",
    "    \"\"\"\n",
    "    Rd = np.random.randint(time.time())\n",
    "    index_list = []\n",
    "    newframe1 = inData.reset_index(inplace = False, drop = True)\n",
    "    newframe2 = classData.reset_index(inplace = False, drop = True)\n",
    "    \n",
    "    for i in range(len(usedLines)):\n",
    "        if usedLines[i] == True:\n",
    "            index_list.append(i)\n",
    "             \n",
    "    input_balance = newframe1.loc[index_list] \n",
    "    label_balance = newframe2.loc[index_list]   \n",
    "    \n",
    "    input_balance = input_balance.sample(frac=1, random_state=Rd).reset_index(inplace = False, drop = True)\n",
    "    label_balance = label_balance.sample(frac=1, random_state=Rd).reset_index(inplace = False, drop = True)\n",
    "    \n",
    "    return input_balance, label_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27419a33",
   "metadata": {},
   "source": [
    "### Balance for n folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_ratio(maxSize, minSize): \n",
    "    \"\"\" \n",
    "    Input:      maxSize     The number of items in the majority class\n",
    "                minSize     The number of items in the minority class\n",
    "\n",
    "    Returns:    BF          Number of balancing folds\n",
    "\n",
    "    Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "    majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "    \"\"\"\n",
    "    Divide = maxSize/minSize\n",
    "    BF = (2 * round(Divide)) + 1 #Double ratio to nearest integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Balance_Folds(BF, inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                usedLines         Array of line indices to use\n",
    "                input_balance     Dataframe of balanced training features\n",
    "                label_balance     Dataframe of balanced training labels\n",
    "                    \n",
    "    Returns:    Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "\n",
    "    Perform the balance_data() function n number of balancing fold times. Return lists for feature data and labels\n",
    "    where each item is the output of balance_data()\n",
    "    \"\"\"\n",
    "    Input_folds  = []\n",
    "    Output_folds = []\n",
    "\n",
    "    for i in range(BF):\n",
    "        usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "        input_balance, label_balance = balance_data(inData, classData, usedLines)\n",
    "        \n",
    "        Input_folds.append(input_balance)\n",
    "        Output_folds.append(label_balance)\n",
    "            \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21cd1aaa",
   "metadata": {},
   "source": [
    "### XGB hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0840d9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def Hyperparameter(BF, Input_folds, Output_folds):\n",
    "#     \"\"\" Input:      BF                Number of balancing folds needed\n",
    "#                     Input_folds       List of 5 balanced arrays of training data\n",
    "#                     Output_folds      List of 5 balanced arrays of training data's labels\n",
    "\n",
    "#         Returns:    BF_RFC_HP         List of optimized hyperparameters for each RFC\n",
    "\n",
    "#         Perform RandomSearchCV on each RFC to optimize number of trees, max depth and max samples\n",
    "#     \"\"\"  \n",
    "#     estimator = RandomForestClassifier()\n",
    "#     param_grid = {\n",
    "#                 'n_estimators':np.arange(50,500,50),\n",
    "#                 'max_depth': np.arange(2, 10, 2),\n",
    "#                 'max_samples': np.arange(0.2, 1.2, 0.2)\n",
    "#                   }\n",
    "#     BF_RFC_HP = []\n",
    "\n",
    "#     for i in range(BF):\n",
    "#         HPtuning = RandomizedSearchCV(\n",
    "#             estimator,\n",
    "#             param_grid, \n",
    "#             scoring = 'balanced_accuracy',\n",
    "#             cv = 10,\n",
    "#             n_jobs = 6, #how many cores to run in parallel\n",
    "#             verbose = 2\n",
    "#             ).fit(Input_folds[i], Output_folds[i])\n",
    "#         BF_RFC_HP.append(HPtuning.best_params_)\n",
    "    \n",
    "#     return(BF_RFC_HP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "796af0e8",
   "metadata": {},
   "source": [
    "### Train XGB on the trainings folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_fitting(BF, Input_folds, Output_folds): \n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds                      \n",
    "                Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "\n",
    "    Returns:    BF_GBC            List of gradient boosted trees trained on each balancing fold\n",
    "\n",
    "    Create GBC model that returns probability predictions for each fold, using output of Balance_Folds() as training data\n",
    "    \"\"\"    \n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic', \n",
    "    }\n",
    "    \n",
    "    BF_GBC = []\n",
    "    for i in range(BF):\n",
    "        d_train = xgb.DMatrix(Input_folds[i], Output_folds[i]) #Create DMatrix for each training balanced fold\n",
    "        BF_GBC.append(xgb.train(params, d_train)) #Generates and fits a GBC for each training balanced fold\n",
    "        \n",
    "    return BF_GBC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0dd278c",
   "metadata": {},
   "source": [
    "#### Validate each GBC on validation set, for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_validate(BF_GBC, ValData):\n",
    "    \"\"\" \n",
    "    Input:      BF_RFC          List of RFCs trained on balancing folds\n",
    "                ValData         Unseen validation features from CV fold\n",
    "                \n",
    "    Returns:    Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "    Test the trained RFCs on the test set, then for every instance, outputs the predicted probability for each class\n",
    "    \"\"\"\n",
    "    \n",
    "    Prob_matrix = []\n",
    "    \n",
    "    for i in range(len(BF_GBC)):\n",
    "        Prob = BF_GBC[i].inplace_predict(ValData.values) #Predicts the probability of an instance belonging to major or minor class. .Values convert to array\n",
    "        Prob_matrix.append(Prob)   \n",
    "        \n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Vote(Prob_matrix):\n",
    "    \"\"\" \n",
    "    Input:      Prob_matrix     List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "\n",
    "    Returns:    Final_vote      Weighted vote classification\n",
    "\n",
    "    Calculate the final weighted vote using confidence scores (Sc) from Prob_matrix. Binary classification formula:\n",
    "    Sc = (S0 -T)/(1-T) if S0> T\n",
    "    Sc = (T-S0)/T if S0 < T\n",
    "    \"\"\"\n",
    "    PD_prob_matrix = Prob_matrix \n",
    "    \n",
    "    SNP_prob_matrix = []\n",
    "    for i in range(len(Prob_matrix)):\n",
    "        sub = 1 - Prob_matrix[i]\n",
    "        SNP_prob_matrix.append(sub)\n",
    "                                            #**Predictor states its prediction/ confidence scores are between 0.0 and 1.0 for each class**#\n",
    "    \n",
    "    Sum_SNP = np.sum(SNP_prob_matrix, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(PD_prob_matrix, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "    \n",
    "                                                        #**Predictor outputs 0. . . 1 as a prediction**#\n",
    "                                                        \n",
    "    # T = 0.45               #Lower threshold gives more sensitivity to PDs over SNPs\n",
    "    # Sc_SNP = []\n",
    "    # Sc_PD = []\n",
    "\n",
    "    # for fold in range(len(Prob_matrix)):        #Calculates SNP Sc all instances in each fold\n",
    "\n",
    "    #     Sc_SNP_fold = []                        #List of the Sc for each fold\n",
    "    #     for value in range(len(SNP_prob_matrix[fold])):\n",
    "    #         S0 = Prob_matrix[fold][value]  #Each SNP's confidence in prob matrix fold\n",
    "    #         if S0 < T:\n",
    "    #             Sc = (T - S0)/T\n",
    "    #         elif S0 >= T:\n",
    "    #             Sc = (S0 - T)/(1 - T)        \n",
    "    #         Sc_SNP_fold.append(Sc)              #List of Sc for each fold\n",
    "    #     Sc_SNP.append(Sc_SNP_fold)              #List of folds with Sc\n",
    "\n",
    "    # for fold in range(len(PD_prob_matrix)):        #Calculates PD Sc all instances in each fold\n",
    "    #     Sc_PD_fold = []\n",
    "    #     for value in range(len(Prob_matrix[fold])):\n",
    "    #         S0 = Prob_matrix[fold][value]  #Each PD's confidence in prob matrix fold\n",
    "    #         if S0 < T:\n",
    "    #             Sc = (T - S0)/T\n",
    "    #         elif S0 >= T:\n",
    "    #             Sc = (S0 - T)/(1 - T)        \n",
    "    #         Sc_PD_fold.append(Sc)\n",
    "    #     Sc_PD.append(Sc_PD_fold)\n",
    "    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)             #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()             #Flattens 2D array to 1D array\n",
    "\n",
    "    return(Final_vote, Sum_PD, Sum_SNP)         #Returns the final confidence scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ae1157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Final_score(Sum_PD, Sum_SNP, BF):\n",
    "#     \"\"\" \n",
    "#     Input:      Sum_PD      Sum of confidence score for PD predictions\n",
    "#                 Sum_SNP     Sum of confidence score for SNP predictions\n",
    "\n",
    "#     Returns:    S_out       Final confidence score\n",
    "\n",
    "#     Calculate the final confidence score\n",
    "#     \"\"\"\n",
    "    \n",
    "#     S_Out = np.abs((Sum_PD - Sum_SNP) /(BF*2))\n",
    "        \n",
    "#     return S_Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evalutation(Final_vote, Vallabel):\n",
    "    \"\"\" \n",
    "    Input:      Testing_Set        Unseen 20% testing data\n",
    "\n",
    "    Evaluate each fold with confusion matrix and MCC\n",
    "    \"\"\"\n",
    "\n",
    "    Output_pred = Final_vote\n",
    "    MCC = matthews_corrcoef(Vallabel, Output_pred)\n",
    "    print(f\"-----------------------------------------------------\\n              ***Fold Evaluation***\\n\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(Vallabel, Output_pred)}\")\n",
    "    print(f\"{classification_report(Vallabel, Output_pred)}\\nMCC                           {MCC}\\n\")\n",
    "    \n",
    "    return MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53993642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(Score_list):\n",
    "     \"\"\" \n",
    "     Input:      Score_list        List of MCC scores\n",
    "\n",
    "     Plots the MCCs of n runs, and calculates the average MCC\n",
    "     \"\"\"\n",
    "     fig, ax = plt.subplots(figsize=(16,10), dpi= 65)\n",
    "     x_axis = range(len(Score_list))\n",
    "     y_axis = Score_list\n",
    "\n",
    "     plt.scatter(x_axis, y_axis, color = 'teal')\n",
    "     plt.axhline(y=np.nanmean(Score_list), color = 'red', linestyle = 'dotted', linewidth = '1', label ='Avg')\n",
    "     plt.title('MCC of 15 XG Boost runs, no CV')\n",
    "     plt.xlabel('Run Number')\n",
    "     plt.ylabel('MCC')\n",
    "     plt.legend()\n",
    "     plt.show()\n",
    "     print(f\"Average: {np.nanmean(Score_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e232",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a74965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 891\n",
      "891 891\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[181  39]\n",
      " [115 338]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.82      0.70       220\n",
      "           1       0.90      0.75      0.81       453\n",
      "\n",
      "    accuracy                           0.77       673\n",
      "   macro avg       0.75      0.78      0.76       673\n",
      "weighted avg       0.80      0.77      0.78       673\n",
      "\n",
      "MCC                           0.5375915910737424\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[192  39]\n",
      " [101 341]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.83      0.73       231\n",
      "           1       0.90      0.77      0.83       442\n",
      "\n",
      "    accuracy                           0.79       673\n",
      "   macro avg       0.78      0.80      0.78       673\n",
      "weighted avg       0.81      0.79      0.80       673\n",
      "\n",
      "MCC                           0.5771189784456551\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[190  38]\n",
      " [110 335]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.83      0.72       228\n",
      "           1       0.90      0.75      0.82       445\n",
      "\n",
      "    accuracy                           0.78       673\n",
      "   macro avg       0.77      0.79      0.77       673\n",
      "weighted avg       0.81      0.78      0.79       673\n",
      "\n",
      "MCC                           0.5581301277086212\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[185  46]\n",
      " [ 99 343]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.80      0.72       231\n",
      "           1       0.88      0.78      0.83       442\n",
      "\n",
      "    accuracy                           0.78       673\n",
      "   macro avg       0.77      0.79      0.77       673\n",
      "weighted avg       0.80      0.78      0.79       673\n",
      "\n",
      "MCC                           0.554589410588183\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[180  39]\n",
      " [103 351]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.82      0.72       219\n",
      "           1       0.90      0.77      0.83       454\n",
      "\n",
      "    accuracy                           0.79       673\n",
      "   macro avg       0.77      0.80      0.77       673\n",
      "weighted avg       0.81      0.79      0.79       673\n",
      "\n",
      "MCC                           0.5647739836344454\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[171  42]\n",
      " [108 352]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.80      0.70       213\n",
      "           1       0.89      0.77      0.82       460\n",
      "\n",
      "    accuracy                           0.78       673\n",
      "   macro avg       0.75      0.78      0.76       673\n",
      "weighted avg       0.80      0.78      0.78       673\n",
      "\n",
      "MCC                           0.5362818022772516\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[197  28]\n",
      " [105 343]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.88      0.75       225\n",
      "           1       0.92      0.77      0.84       448\n",
      "\n",
      "    accuracy                           0.80       673\n",
      "   macro avg       0.79      0.82      0.79       673\n",
      "weighted avg       0.83      0.80      0.81       673\n",
      "\n",
      "MCC                           0.6081632641666398\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[177  35]\n",
      " [106 355]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.83      0.72       212\n",
      "           1       0.91      0.77      0.83       461\n",
      "\n",
      "    accuracy                           0.79       673\n",
      "   macro avg       0.77      0.80      0.77       673\n",
      "weighted avg       0.82      0.79      0.80       673\n",
      "\n",
      "MCC                           0.5692817209822131\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[179  36]\n",
      " [112 346]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71       215\n",
      "           1       0.91      0.76      0.82       458\n",
      "\n",
      "    accuracy                           0.78       673\n",
      "   macro avg       0.76      0.79      0.77       673\n",
      "weighted avg       0.81      0.78      0.79       673\n",
      "\n",
      "MCC                           0.5534309209256786\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[189  44]\n",
      " [ 99 341]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73       233\n",
      "           1       0.89      0.78      0.83       440\n",
      "\n",
      "    accuracy                           0.79       673\n",
      "   macro avg       0.77      0.79      0.78       673\n",
      "weighted avg       0.81      0.79      0.79       673\n",
      "\n",
      "MCC                           0.5636285429489285\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[172  36]\n",
      " [111 354]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.83      0.70       208\n",
      "           1       0.91      0.76      0.83       465\n",
      "\n",
      "    accuracy                           0.78       673\n",
      "   macro avg       0.76      0.79      0.76       673\n",
      "weighted avg       0.81      0.78      0.79       673\n",
      "\n",
      "MCC                           0.5506397205801954\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[201  42]\n",
      " [ 80 350]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77       243\n",
      "           1       0.89      0.81      0.85       430\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.80      0.82      0.81       673\n",
      "weighted avg       0.83      0.82      0.82       673\n",
      "\n",
      "MCC                           0.624419446158716\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[162  41]\n",
      " [113 357]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.80      0.68       203\n",
      "           1       0.90      0.76      0.82       470\n",
      "\n",
      "    accuracy                           0.77       673\n",
      "   macro avg       0.74      0.78      0.75       673\n",
      "weighted avg       0.80      0.77      0.78       673\n",
      "\n",
      "MCC                           0.5206129475968997\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[181  43]\n",
      " [ 94 355]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73       224\n",
      "           1       0.89      0.79      0.84       449\n",
      "\n",
      "    accuracy                           0.80       673\n",
      "   macro avg       0.78      0.80      0.78       673\n",
      "weighted avg       0.81      0.80      0.80       673\n",
      "\n",
      "MCC                           0.5738986498566557\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[187  47]\n",
      " [102 337]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.80      0.72       234\n",
      "           1       0.88      0.77      0.82       439\n",
      "\n",
      "    accuracy                           0.78       673\n",
      "   macro avg       0.76      0.78      0.77       673\n",
      "weighted avg       0.80      0.78      0.78       673\n",
      "\n",
      "MCC                           0.5453242048970612\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1040x650 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.5625256874560591\n"
     ]
    }
   ],
   "source": [
    "file = \"AC_dataset.csv\"\n",
    "Score_list = []\n",
    "for i in range(0,15):\n",
    "    Training_Set, Testing_Set          = Train_Test_Split(file)                                 #Create training and testing sets\n",
    "    train_features, train_labels, test_features, test_labels = data(Training_Set, Testing_Set )\n",
    "    # xgb_model = CV(Training_Set)                                                              #Cross-validate training set                              \n",
    "    classData                   = train_labels                                            #Training labels\n",
    "    inData                      = train_features                                           #Training features\n",
    "    ValData                     = test_features                                            #Validation features\n",
    "    Vallabel                    = test_labels                                            #Validation labels\n",
    "\n",
    "    # test(inData, classData, ValData, Vallabel)                                                          #Initial evaluation\n",
    "    \n",
    "    minClass, minSize, maxSize  = find_minority_class(classData)                            #Determines imbalance\n",
    "    BF                          = Balance_ratio(maxSize, minSize)                           #Determins number of balancing folds needed\n",
    "    Input_folds, Output_folds   = Balance_Folds(BF, inData, classData, minClass, minSize)   # balance() and balance_data() functions are called under this\n",
    "        # BF_RFC_HP = Hyperparameter(BF, Input_folds, Output_folds)\n",
    "    BF_GBC                      = BF_fitting(BF, Input_folds, Output_folds)\n",
    "    Prob_matrix                 = BF_validate(BF_GBC, ValData)\n",
    "\n",
    "    Final_vote, Sum_PD, Sum_SNP = Weighted_Vote(Prob_matrix)\n",
    "    # S_Out                       = Final_score(Sum_PD, Sum_SNP, BF)\n",
    "\n",
    "    MCC = evalutation(Final_vote, test_labels)\n",
    "    Score_list.append(MCC)\n",
    "    \n",
    "plot(Score_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e5cd67c8584618c148c6f2b57de13817422ccd98975b320089863a41752ead79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
