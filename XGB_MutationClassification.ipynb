{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d94d2bb",
   "metadata": {},
   "source": [
    "Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "    Goal is to predict if mutation is SNP or PD\n",
    "    XG Boost\n",
    "        \n",
    "    Total samples: 3368\n",
    "    2254 PD samples\n",
    "    1111 SNP samples\n",
    "    3 NA samples\n",
    "\n",
    "CV branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports the required libraries and packages \"\"\"\n",
    "\n",
    "import pandas as pd                                                              # Data manipulation in dataframes\n",
    "import numpy as np                                                               # Array manipulation\n",
    "import xgboost as xgb                                                            # Gradient boosting package\n",
    "\n",
    "import random as rd                                                              # Random seed generation\n",
    "import time                                                                      # Time program run time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,                                                           # MCC for evaluation\n",
    "    # balanced_accuracy_score, #hyperparameter evaluation\n",
    "    # f1_score,  #hyperparameter evaluation\n",
    "    confusion_matrix,                                                            # Confusion matrix for classification evalutation\n",
    "    classification_report                                                        # Return the F1, precision, and recall of a prediction\n",
    "    )\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,                                                            # Splits data frame into the training set and testing set\n",
    "    # GridSearchCV,  # Searches all hyperparameters\n",
    "    # RandomizedSearchCV, # Searches random range of hyperparameters\n",
    "    GroupKFold                                                                   # K-fold CV with as groups\n",
    "        )\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# from sklearn.ensemble import RandomForestClassifier                              # SK learn API for classificastion random forests\n",
    "\n",
    "np.set_printoptions(precision = 3,threshold=np.inf, suppress=True)               # Full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfacd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test_Split(file):\n",
    "    \"\"\"      \n",
    "    Input:      file             Pre-processed dataset done by PDB2AC script\n",
    "\n",
    "    Returns:    Training_Set     80% training set split\n",
    "                Testing_Set      20% testing set split\n",
    "                \n",
    "    80% training and 20% testing split. Splits are shuffled randomly and index reset\n",
    "    \"\"\"\n",
    "    AC_dataset                  = pd.read_csv(file, index_col=0)  \n",
    "    Training_Set, Testing_Set   = train_test_split(AC_dataset,train_size = 0.8)\n",
    "        \n",
    "    Training_Set.reset_index(drop=True, inplace = True) #Drop index to avoid training on index values\n",
    "    Testing_Set.reset_index(drop=True, inplace = True)  #Reset index after splitting for compatability with group fold CV\n",
    "    \n",
    "    Training_Set                = Training_Set.sample(frac = 1) #Shuffle data after splitting\n",
    "    Testing_Set                 = Testing_Set.sample(frac = 1)\n",
    "    \n",
    "    \n",
    "    return Training_Set, Testing_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89126467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data(Training_Set, Testing_Set):\n",
    "#     \"\"\"      \n",
    "#     Input:      Training_Set     80% training set split\n",
    "#                 Testing_Set      20% testing set split\n",
    "\n",
    "#     Returns:    train_features   Features for training\n",
    "#                 train labels     Class lables for training\n",
    "#                 test_features    Features for testing\n",
    "#                 test_labels      Class labels for testing\n",
    "                \n",
    "#     Creates the datasets needed for GBC model training and predictions\n",
    "#     \"\"\"\n",
    "    \n",
    "#     train_features     = Training_Set.drop(['AC Code','dataset'], axis =1)      \n",
    "#     train_labels       = Training_Set['dataset']                                  \n",
    "        \n",
    "#     test_features     = Testing_Set.drop(['AC Code','dataset'], axis =1)         \n",
    "#     test_labels       = Testing_Set['dataset']                                  \n",
    "        \n",
    "#     return(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(inData, classData, ValData, Vallabel):\n",
    "#     \"\"\" \n",
    "#     Input:      inData          Features for training\n",
    "#                 classData       Class lables for training\n",
    "#                 valData         Features for testing\n",
    "#                 Vallabel        Class labels for testing\n",
    "\n",
    "#     Evaluate training data before CV and balancing. Gradient boosting for prediction on the test data. \n",
    "#     True values are testing data class labels\n",
    "#     \"\"\"    \n",
    "#     d_train = xgb.DMatrix(inData, classData)\n",
    "#     d_test = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "#     params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:hinge', \n",
    "#     }\n",
    "#     XGB_initial = xgb.train(params, d_train)\n",
    "    \n",
    "#     Output_pred = XGB_initial.predict(d_test)\n",
    "#     print(f\"              **Initial Evaluation**\")\n",
    "#     print(f\"Confusion Matrix:\\n {confusion_matrix(Vallabel, Output_pred)}\")\n",
    "#     print(f\"MCC              {matthews_corrcoef(Vallabel, Output_pred)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3a2df",
   "metadata": {},
   "source": [
    "## Group K-fold CV (outer loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975ff775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(Training_Set):\n",
    "    \"\"\"      \n",
    "    Input:      Training_Set     80% training set split\n",
    "            \n",
    "    Returns:    IT_list         List of training features for each fold\n",
    "                LT_list         List of training class labels for each fold\n",
    "                IV_list         List of validation features for each fold\n",
    "                LV_list         List of validation class labels for each fold\n",
    "\n",
    "    K-fold CV with protein groups separated between training and validation sets for each fold. Creates 5 folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    features     = Training_Set.drop(['dataset'], axis =1)         #Features for training\n",
    "    labels       = Training_Set['dataset']                         #Class labels for training\n",
    "    groups       = Training_Set['AC Code'].to_list()               #List of proteins for grouping\n",
    "    \n",
    "    IT_list = []\n",
    "    LT_list = []\n",
    "    IV_list = []\n",
    "    LV_list = []\n",
    "    \n",
    "    CV             = GroupKFold(n_splits = 5)                           #Creates 5 splits\n",
    "\n",
    "    for train_idx, val_idx in CV.split(features, labels, groups):       #Generates the indices to be used for a training and validation split. Indicies are unique to train/ val sets\n",
    "\n",
    "        Rd = np.random.randint(time.time())                                  #Random number from 1 to time since epoch\n",
    "\n",
    "        Input_train                        = features.loc[train_idx]   #New dataframe from selected indices\n",
    "        Classes_train                      = labels.loc[train_idx]\n",
    "        Input_train.drop(['AC Code'], axis = 1, inplace = True)              #Group identifer not needed for training\n",
    "\n",
    "                \n",
    "        Input_val                          = features.loc[val_idx]\n",
    "        Classes_val                        = labels.loc[val_idx]\n",
    "        Input_val.drop(['AC Code'], axis   = 1, inplace = True)\n",
    "        \n",
    "        Input_train.reset_index(drop = True, inplace = True)\n",
    "        Classes_train.reset_index(drop = True, inplace = True)\n",
    "        Input_val.reset_index(drop = True, inplace = True)\n",
    "        Classes_val.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        IT_list.append(Input_train.sample(frac=1, random_state=Rd))          #Shuffles lists, random state to ensure features and labels match for each fold\n",
    "        LT_list.append(Classes_train.sample(frac=1, random_state=Rd))\n",
    "        IV_list.append(Input_val.sample(frac=1, random_state=(Rd-1)))\n",
    "        LV_list.append(Classes_val.sample(frac=1, random_state=(Rd-1)))\n",
    "    \n",
    "    # params = {\n",
    "    # 'booster': 'gbtree',\n",
    "    # 'objective': 'binary:logistic', \n",
    "    # }\n",
    "    \n",
    "    # d_train = xgb.DMatrix(features, labels)\n",
    "    # xgb_model = xgb.train(params, d_train)\n",
    "        \n",
    "    # CV = xgb.cv(\n",
    "    #     params=params,\n",
    "    #     dtrain = d_train,\n",
    "    #     nfold = 5,\n",
    "    #     early_stopping_rounds= 20,\n",
    "    #     metrics='error',\n",
    "    #     as_pandas=True,\n",
    "    # )\n",
    "    \n",
    "    # print(CV)\n",
    "        \n",
    "    # CV             = GroupKFold(n_splits = 5)                           #Creates 5 splits\n",
    "    \n",
    "  \n",
    "    \n",
    "    # for train_idx, val_idx in CV.split(Input_CV, Output_CV, Protein_Groups): #Generates the indices to be used for a training and validation split. Indicies are unique to train/ val sets\n",
    "        \n",
    "    #     Rd = np.random.randint(time.time())                                  #Random number from 1 to time since epoch\n",
    "\n",
    "    #     Input_train                        = Input_CV.loc[train_idx]         #New dataframe from selected indices\n",
    "    #     Classes_train                      = Output_CV.loc[train_idx]\n",
    "    #     Input_train.drop(['AC Code'], axis = 1, inplace = True)              #Group identifer not needed for training\n",
    "                \n",
    "    #     Input_val                          = Input_CV.loc[val_idx]\n",
    "    #     Classes_val                        = Output_CV.loc[val_idx]\n",
    "    #     Input_val.drop(['AC Code'], axis   = 1, inplace = True)\n",
    "\n",
    "    #     IT_list.append(Input_train.sample(frac=1, random_state=Rd))          #Shuffles lists, random state to ensure features and labels match for each fold\n",
    "    #     LT_list.append(Classes_train.sample(frac=1, random_state=Rd))\n",
    "    #     IV_list.append(Input_val.sample(frac=1, random_state=(Rd-1)))\n",
    "    #     LV_list.append(Classes_val.sample(frac=1, random_state=(Rd-1)))\n",
    "        \n",
    "\n",
    "    return(IT_list, LT_list, IV_list, LV_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "## Balancing (inner loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" \n",
    "    Input:        classData  Array of class labels\n",
    "\n",
    "    Returns:      minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "\n",
    "    Find information about class size imbalance\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize  = Minority_count\n",
    "    maxSize  = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize  = Majority_count\n",
    "        maxSize  = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:        inData          array of input data\n",
    "                  classData       array of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "\n",
    "    Returns:      usedLines       array of indexes that are of interest for a balanced dataset\n",
    "\n",
    "    Perform the actual balancing for a fold between SNPs and PDs\n",
    "    \"\"\"\n",
    "    usedLines = [False] * len(inData) #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData[i] == minClass:        #Balance directly with dataframe\n",
    "            usedLines[i] = True            #True lines are SNP\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedLines[i] = True\n",
    "            usedCount += 1          #Set PD lines \"True\", until equal to number of SNP lines\n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    # \"\"\"     \n",
    "    # Input:      inData      array of input training data\n",
    "    #             classData   array of classes assigned to training data\n",
    "    #             usedLines   array of line indexes to print\n",
    "\n",
    "    # Returns:    input_balance  Dataframe of balanced training features\n",
    "    #             label_balance  Dataframe of balanced training labels\n",
    "                       \n",
    "    # Create dataframe of the input training data and classes used. The index [i] is the identifier between the two arrays.\n",
    "    # \"\"\"\n",
    "    # input_balance = []\n",
    "    # label_balance = []\n",
    "    \n",
    "    # for i in range(len(inData)):\n",
    "    #     if usedLines[i] == True:\n",
    "    #         input_i = inData.iloc[i]\n",
    "    #         input_balance.append(input_i)\n",
    "            \n",
    "    #         label_i = classData.iloc[i]\n",
    "    #         label_balance.append(label_i)\n",
    "    \n",
    "    # return input_balance, label_balance\n",
    "\n",
    "    \"\"\"     \n",
    "    Input:      inData      array of input training data\n",
    "                classData   array of classes assigned to training data\n",
    "                usedLines   array of line indexes to print\n",
    "\n",
    "    Returns:    input_balance  Dataframe of balanced training features\n",
    "                label_balance  Dataframe of balanced training labels\n",
    "                       \n",
    "    Create dataframe of the input training data and classes used. Index_list preserves the indicies between usedLines and inData, used to pull the needed lines.\n",
    "    \"\"\"\n",
    "    Rd = np.random.randint(time.time())\n",
    "    index_list = []\n",
    "    \n",
    "    for i in range(len(usedLines)):\n",
    "        if usedLines[i] == True:\n",
    "            index_list.append(i)\n",
    "             \n",
    "    input_balance = inData.iloc[index_list] \n",
    "    label_balance = classData.iloc[index_list]   \n",
    "    \n",
    "    input_balance = input_balance.sample(frac=1, random_state=Rd).reset_index(inplace = False, drop = True)\n",
    "    label_balance = label_balance.sample(frac=1, random_state=Rd).reset_index(inplace = False, drop = True)\n",
    "    \n",
    "    return input_balance, label_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_ratio(maxSize, minSize): \n",
    "    \"\"\" \n",
    "    Input:      maxSize     The number of items in the majority class\n",
    "                minSize     The number of items in the minority class\n",
    "\n",
    "    Returns:    BF          Number of balancing folds\n",
    "\n",
    "    Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "    majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "    \"\"\"\n",
    "    Divide = maxSize/minSize\n",
    "    BF = (2 * round(Divide)) + 1 #Double ratio to nearest integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Balance_Folds(BF, inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                inData            Features for training\n",
    "                classData         Class labels for training\n",
    "                minClass          The label for the minority class\n",
    "                minSize           The number of items in the minority class\n",
    "                                  \n",
    "    Returns:    Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "\n",
    "    Perform the balance_data() function n number of balancing fold times. Return lists for feature data and labels\n",
    "    where each item is the output of balance_data()\n",
    "    \"\"\"\n",
    "    Input_folds  = []\n",
    "    Output_folds = []\n",
    "\n",
    "    for i in range(BF):\n",
    "        usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "        input_balance, label_balance = balance_data(inData, classData, usedLines)\n",
    "        \n",
    "        Input_folds.append(input_balance)\n",
    "        Output_folds.append(label_balance)\n",
    "            \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21cd1aaa",
   "metadata": {},
   "source": [
    "### XGB hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0840d9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def Hyperparameter(BF, Input_folds, Output_folds):\n",
    "#     \"\"\" Input:      BF                Number of balancing folds needed\n",
    "#                     Input_folds       List of 5 balanced arrays of training data\n",
    "#                     Output_folds      List of 5 balanced arrays of training data's labels\n",
    "\n",
    "#         Returns:    BF_RFC_HP         List of optimized hyperparameters for each RFC\n",
    "\n",
    "#         Perform RandomSearchCV on each RFC to optimize number of trees, max depth and max samples\n",
    "#     \"\"\"  \n",
    "#     estimator = RandomForestClassifier()\n",
    "#     param_grid = {\n",
    "#                 'n_estimators':np.arange(50,500,50),\n",
    "#                 'max_depth': np.arange(2, 10, 2),\n",
    "#                 'max_samples': np.arange(0.2, 1.2, 0.2)\n",
    "#                   }\n",
    "#     BF_RFC_HP = []\n",
    "\n",
    "#     for i in range(BF):\n",
    "#         HPtuning = RandomizedSearchCV(\n",
    "#             estimator,\n",
    "#             param_grid, \n",
    "#             scoring = 'balanced_accuracy',\n",
    "#             cv = 10,\n",
    "#             n_jobs = 6, #how many cores to run in parallel\n",
    "#             verbose = 2\n",
    "#             ).fit(Input_folds[i], Output_folds[i])\n",
    "#         BF_RFC_HP.append(HPtuning.best_params_)\n",
    "    \n",
    "#     return(BF_RFC_HP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "796af0e8",
   "metadata": {},
   "source": [
    "### Train XGB on the trainings folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ede39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_data(BF, Input_folds, Output_folds, ValData, Vallabel):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "                ValData           Unseen validation features from CV fold\n",
    "                ValLabel          Unseen valiadation labels from CV fold\n",
    "                                  \n",
    "    Returns:    d_train_list      List of balanced training feature folds in DMatrix\n",
    "                d_test            Validation data as Dmatrix\n",
    "\n",
    "    Converts the balanced and validation data into Dmatrix for model training and evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    d_train_list =[]\n",
    "    for i in range(BF):\n",
    "            d_train = xgb.DMatrix(Input_folds[i], Output_folds[i])      #Create DMatrix for each training balanced fold\n",
    "            d_train_list.append(d_train)\n",
    "    d_test = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "    return (d_train_list, d_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb2003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CM(pred, d_test):\n",
    "    \"\"\" \n",
    "    Input:      pred              Prediction from a boosted tree during training\n",
    "                d_test            Validation data as Dmatrix\n",
    "\n",
    "    MCC as a custom evaluation metric for evaluating the model during training. This is different from the final weighted evaluation\n",
    "    \"\"\"\n",
    "    true_label = d_test.get_label()   \n",
    "    pred_label = np.round(pred) \n",
    "    \n",
    "    # CM = confusion_matrix(true_label, pred_label)\n",
    "    # error = (CM[0, 1] + CM[1,0])/(CM[0, 1] + CM[1,0] + CM[1, 1] + CM[0,0])\n",
    "\n",
    "    \n",
    "    return 'mcc', matthews_corrcoef(pred_label, true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_fitting(BF, d_train_list, d_test): \n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds                      \n",
    "                d_train_list      List of balanced training feature folds in DMatrix\n",
    "                d_test            Validation data as Dmatrix\n",
    "                \n",
    "    Returns:    BF_GBC            List of gradient boosted trees trained on each balancing fold\n",
    "\n",
    "    Create GBC model that returns probability predictions for each fold, using output of Balance_Folds() as training data (as a Dmatrix)\n",
    "    \"\"\"     \n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic', \n",
    "    'disable_default_eval_metric': 1,\n",
    "    'verbosity': 1,\n",
    "    # 'eval_metric':['error'],\n",
    "    } \n",
    "    \n",
    "    BF_GBC = []\n",
    "    for fold_i in range(BF):\n",
    "        d_train = d_train_list[fold_i]                          #Dmatrix for each balanced fold\n",
    "        BF_GBC.append(xgb.train(params, \n",
    "                                d_train, \n",
    "                                num_boost_round = 1000,\n",
    "                                evals  = [(d_test,'Model')],\n",
    "                                verbose_eval = 50,               #Print evaluation metrics every 50 trees\n",
    "                                early_stopping_rounds = 10,\n",
    "                                custom_metric = CM, \n",
    "                                )\n",
    "                      )                                         #Generates and fits a GBC for each training balanced fold\n",
    "        \n",
    "        \n",
    "    return BF_GBC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0dd278c",
   "metadata": {},
   "source": [
    "#### Validate each GBC on validation set, for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_validate(BF_GBC, d_test):\n",
    "    \"\"\" \n",
    "    Input:      BF_RFC            List of RFCs trained on balancing folds\n",
    "                d_test            Validation data as Dmatrix\n",
    "\n",
    "                \n",
    "    Returns:    Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "    Test the trained RFCs on the test set, then for every instance, outputs the predicted probability for each class\n",
    "    \"\"\"\n",
    "    \n",
    "    Prob_matrix = []\n",
    "    for i in range(len(BF_GBC)):\n",
    "        Prob = BF_GBC[i].predict(d_test) #Predicts the probability of an instance belonging to the major/ positive class (PD/ 1). Output has shape (n_predictions,)\n",
    "        Prob_matrix.append(Prob)   \n",
    "        \n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Vote(Prob_matrix):\n",
    "    \"\"\" \n",
    "    Input:      Prob_matrix     List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "\n",
    "    Returns:    Final_vote      Weighted vote classification\n",
    "\n",
    "    Calculate the final weighted vote using confidence scores (Sc) from Prob_matrix. Binary classification formula for:\n",
    "    Predictor states its prediction/ confidence scores are between 0.0 and 1.0 for each class\n",
    "    \"\"\"\n",
    "    PD_prob_matrix = Prob_matrix \n",
    "    \n",
    "    SNP_prob_matrix = []\n",
    "    for i in range(len(Prob_matrix)):               #SNP probabilites are 1 - (PD probabilites)\n",
    "        sub = 1 - Prob_matrix[i]\n",
    "        SNP_prob_matrix.append(sub)\n",
    "            \n",
    "    Sum_SNP = np.sum(SNP_prob_matrix, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(PD_prob_matrix, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "                                                    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)             #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()             #Flattens 2D array to 1D array\n",
    "\n",
    "    return(Final_vote, Sum_PD, Sum_SNP)         #Returns the final confidence scores\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd9d48f0",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evalutation(Final_vote, Vallabel):\n",
    "    \"\"\" \n",
    "    Input:      Final Vote      Weighted vote classification\n",
    "                ValLabel        Unseen 20% testing data labels\n",
    "\n",
    "    Evaluate each fold with confusion matrix and MCC\n",
    "    \"\"\"\n",
    "\n",
    "    Output_pred = Final_vote\n",
    "    MCC = matthews_corrcoef(Vallabel, Output_pred)\n",
    "    print(f\"-----------------------------------------------------\\n              ***Fold Evaluation***\\n\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(Vallabel, Output_pred)}\")\n",
    "    print(f\"{classification_report(Vallabel, Output_pred)}\\nMCC                           {MCC}\\n\")\n",
    "    \n",
    "    return MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53993642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(Score_list):\n",
    "     \"\"\" \n",
    "     Input:      Score_list        List of MCC scores\n",
    "\n",
    "     Plots the MCCs of n runs, and calculates the average MCC\n",
    "     \"\"\"\n",
    "     fig, ax = plt.subplots(figsize=(16,10), dpi= 65)\n",
    "     x_axis = range(len(Score_list))\n",
    "     y_axis = Score_list\n",
    "\n",
    "     plt.scatter(x_axis, y_axis, color = 'teal')\n",
    "     plt.axhline(y=np.nanmean(Score_list), color = 'red', linestyle = 'dotted', linewidth = '1', label ='Avg')\n",
    "     plt.title('MCC of 15 XG Boost runs, group CV')\n",
    "     plt.xlabel('Run Number')\n",
    "     plt.ylabel('MCC')\n",
    "     plt.legend()\n",
    "     plt.show()\n",
    "     print(f\"Average: {np.nanmean(Score_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e232",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a74965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tModel-error:0.25417\n",
      "[44]\tModel-error:0.16883\n",
      "[0]\tModel-error:0.27087\n",
      "[49]\tModel-error:0.15399\n",
      "[0]\tModel-error:0.28571\n",
      "[35]\tModel-error:0.18367\n",
      "[0]\tModel-error:0.26531\n",
      "[32]\tModel-error:0.17996\n",
      "[0]\tModel-error:0.24675\n",
      "[47]\tModel-error:0.16327\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[129  51]\n",
      " [ 28 331]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77       180\n",
      "           1       0.87      0.92      0.89       359\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.84      0.82      0.83       539\n",
      "weighted avg       0.85      0.85      0.85       539\n",
      "\n",
      "MCC                           0.662948828491369\n",
      "\n",
      "[0]\tModel-error:0.29870\n",
      "[50]\tModel-error:0.16512\n",
      "[51]\tModel-error:0.16698\n",
      "[0]\tModel-error:0.27829\n",
      "[50]\tModel-error:0.18553\n",
      "[63]\tModel-error:0.17254\n",
      "[0]\tModel-error:0.28942\n",
      "[20]\tModel-error:0.21707\n",
      "[0]\tModel-error:0.30612\n",
      "[40]\tModel-error:0.18924\n",
      "[0]\tModel-error:0.28942\n",
      "[50]\tModel-error:0.18182\n",
      "[77]\tModel-error:0.18553\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[127  53]\n",
      " [ 33 326]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75       180\n",
      "           1       0.86      0.91      0.88       359\n",
      "\n",
      "    accuracy                           0.84       539\n",
      "   macro avg       0.83      0.81      0.82       539\n",
      "weighted avg       0.84      0.84      0.84       539\n",
      "\n",
      "MCC                           0.6334509282141869\n",
      "\n",
      "[0]\tModel-error:0.28625\n",
      "[34]\tModel-error:0.19517\n",
      "[0]\tModel-error:0.31413\n",
      "[47]\tModel-error:0.17472\n",
      "[0]\tModel-error:0.28625\n",
      "[43]\tModel-error:0.16543\n",
      "[0]\tModel-error:0.31784\n",
      "[38]\tModel-error:0.18216\n",
      "[0]\tModel-error:0.29740\n",
      "[38]\tModel-error:0.17100\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[121  68]\n",
      " [ 21 328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.64      0.73       189\n",
      "           1       0.83      0.94      0.88       349\n",
      "\n",
      "    accuracy                           0.83       538\n",
      "   macro avg       0.84      0.79      0.81       538\n",
      "weighted avg       0.84      0.83      0.83       538\n",
      "\n",
      "MCC                           0.6282168559710193\n",
      "\n",
      "[0]\tModel-error:0.26766\n",
      "[41]\tModel-error:0.15056\n",
      "[0]\tModel-error:0.27138\n",
      "[35]\tModel-error:0.15613\n",
      "[0]\tModel-error:0.27509\n",
      "[50]\tModel-error:0.16357\n",
      "[0]\tModel-error:0.27138\n",
      "[47]\tModel-error:0.15985\n",
      "[0]\tModel-error:0.29368\n",
      "[37]\tModel-error:0.17286\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[127  47]\n",
      " [ 32 332]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76       174\n",
      "           1       0.88      0.91      0.89       364\n",
      "\n",
      "    accuracy                           0.85       538\n",
      "   macro avg       0.84      0.82      0.83       538\n",
      "weighted avg       0.85      0.85      0.85       538\n",
      "\n",
      "MCC                           0.6581484929804478\n",
      "\n",
      "[0]\tModel-error:0.25651\n",
      "[48]\tModel-error:0.16914\n",
      "[0]\tModel-error:0.28810\n",
      "[43]\tModel-error:0.14312\n",
      "[0]\tModel-error:0.25093\n",
      "[50]\tModel-error:0.15799\n",
      "[52]\tModel-error:0.15613\n",
      "[0]\tModel-error:0.27138\n",
      "[50]\tModel-error:0.14312\n",
      "[57]\tModel-error:0.13755\n",
      "[0]\tModel-error:0.25836\n",
      "[50]\tModel-error:0.16357\n",
      "[53]\tModel-error:0.15799\n",
      "-----------------------------------------------------\n",
      "              ***Fold Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[122  55]\n",
      " [ 20 341]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.76       177\n",
      "           1       0.86      0.94      0.90       361\n",
      "\n",
      "    accuracy                           0.86       538\n",
      "   macro avg       0.86      0.82      0.83       538\n",
      "weighted avg       0.86      0.86      0.86       538\n",
      "\n",
      "MCC                           0.6756852990456867\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1040x650 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.6516900809405419\n"
     ]
    }
   ],
   "source": [
    "file = \"AC_dataset.csv\"\n",
    "Score_list = []\n",
    "Training_Set, Testing_Set          = Train_Test_Split(file)                                 #Create training and testing sets\n",
    "# test(inData, classData, ValData, Vallabel)                                                          #Initial evaluation\n",
    "IT_list, LT_list, IV_list, LV_list = CV(Training_Set)                #Cross-validate training set        \n",
    "\n",
    "for i in range(len(IT_list)):          \n",
    "    inData = IT_list[i]\n",
    "    classData = LT_list[i]\n",
    "    ValData = IV_list[i]\n",
    "    Vallabel = LV_list[i]\n",
    "\n",
    "    minClass, minSize, maxSize  = find_minority_class(classData)                            #Determines imbalance\n",
    "    BF                          = Balance_ratio(maxSize, minSize)                           #Determins number of balancing folds needed\n",
    "    Input_folds, Output_folds   = Balance_Folds(BF, inData, classData, minClass, minSize)   # balance() and balance_data() functions are called under this\n",
    "    d_train_list, d_test        = model_training_data(BF, Input_folds, Output_folds, ValData, Vallabel)\n",
    "    # BF_RFC_HP = Hyperparameter(BF, Input_folds, Output_folds)\n",
    "    BF_GBC                      = BF_fitting(BF, d_train_list, d_test)\n",
    "    Prob_matrix                 = BF_validate(BF_GBC, d_test)\n",
    "\n",
    "    Final_vote, Sum_PD, Sum_SNP = Weighted_Vote(Prob_matrix)\n",
    "\n",
    "    MCC = evalutation(Final_vote, Vallabel)\n",
    "    Score_list.append(MCC)  \n",
    "        \n",
    "plot(Score_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e5cd67c8584618c148c6f2b57de13817422ccd98975b320089863a41752ead79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
