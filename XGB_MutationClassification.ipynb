{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcba82d",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d94d2bb",
   "metadata": {},
   "source": [
    "Example 2 is inbalanced data set; ~2200 in PD and ~1100 in SNP\n",
    "    Goal is to predict if mutation is SNP or PD\n",
    "    XG Boost\n",
    "        \n",
    "    Total samples: 3368\n",
    "    2254 PD samples\n",
    "    1111 SNP samples\n",
    "    3 NA samples\n",
    "\n",
    "CV branch (best performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5737f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imports the required libraries and packages \"\"\"\n",
    "\n",
    "import pandas as pd                                                              # Data manipulation in dataframes\n",
    "import numpy as np                                                               # Array manipulation\n",
    "import xgboost as xgb                                                            # Gradient boosting package\n",
    "\n",
    "import random as rd                                                              # Random seed generation\n",
    "import time                                                                      # Time program run time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from sklearn.metrics import(\n",
    "    matthews_corrcoef,                                                           # MCC for evaluation\n",
    "    # balanced_accuracy_score, #hyperparameter evaluation\n",
    "    # f1_score,  #hyperparameter evaluation\n",
    "    confusion_matrix,                                                            # Confusion matrix for classification evalutation\n",
    "    classification_report                                                        # Return the F1, precision, and recall of a prediction\n",
    "    )\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    train_test_split,                                                            # Splits data frame into the training set and testing set\n",
    "    # GridSearchCV,  # Searches all hyperparameters\n",
    "    # RandomizedSearchCV, # Searches random range of hyperparameters\n",
    "    GroupKFold                                                                   # K-fold CV with as groups\n",
    "        )\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# from sklearn.ensemble import RandomForestClassifier                              # SK learn API for classificastion random forests\n",
    "\n",
    "np.set_printoptions(precision = 3,threshold=np.inf, suppress=True)               # Full array printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb451c9e",
   "metadata": {},
   "source": [
    "### Split dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfacd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Test_Split(file):\n",
    "    \"\"\"      \n",
    "    Input:      file             Pre-processed dataset done by PDB2AC script\n",
    "\n",
    "    Returns:    Training_Set     80% training set split\n",
    "                Testing_Set      20% testing set split\n",
    "                \n",
    "    80% training and 20% testing split. Splits are shuffled randomly and index reset\n",
    "    \"\"\"\n",
    "    AC_dataset                  = pd.read_csv(file, index_col=0)  \n",
    "    Training_Set                = AC_dataset\n",
    "        \n",
    "    Training_Set, Testing_Set   = train_test_split(AC_dataset,train_size = 0.8)\n",
    "        \n",
    "    Training_Set.reset_index(drop=True, inplace = True) #Drop index to avoid training on index values\n",
    "    Testing_Set.reset_index(drop=True, inplace = True)  #Reset index after splitting for compatability with group fold CV\n",
    "    \n",
    "    Training_Set                = Training_Set.sample(frac = 1) #Shuffle data after splitting\n",
    "    Testing_Set                 = Testing_Set.sample(frac = 1)\n",
    "    \n",
    "    \n",
    "    return Training_Set, Testing_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466d455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_matrix(Testing_Set):\n",
    "    TestData     = Testing_Set.drop(['AC Code','dataset'], axis =1)         #Features for testing\n",
    "    TestLabels   = Testing_Set['dataset']     #Class labels for testing\n",
    "    \n",
    "    d_test = xgb.DMatrix(TestData, TestLabels)\n",
    "\n",
    "    return (d_test, TestData, TestLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89126467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data(Training_Set, Testing_Set):\n",
    "#     \"\"\"      \n",
    "#     Input:      Training_Set     80% training set split\n",
    "#                 Testing_Set      20% testing set split\n",
    "\n",
    "#     Returns:    train_features   Features for training\n",
    "#                 train labels     Class lables for training\n",
    "#                 test_features    Features for testing\n",
    "#                 test_labels      Class labels for testing\n",
    "                \n",
    "#     Creates the datasets needed for GBC model training and predictions\n",
    "#     \"\"\"\n",
    "    \n",
    "#     train_features     = Training_Set.drop(['AC Code','dataset'], axis =1)      \n",
    "#     train_labels       = Training_Set['dataset']                                  \n",
    "        \n",
    "#     test_features     = Testing_Set.drop(['AC Code','dataset'], axis =1)         \n",
    "#     test_labels       = Testing_Set['dataset']                                  \n",
    "        \n",
    "#     return(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8b7f5",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8d9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(inData, classData, ValData, Vallabel):\n",
    "#     \"\"\" \n",
    "#     Input:      inData          Features for training\n",
    "#                 classData       Class lables for training\n",
    "#                 valData         Features for testing\n",
    "#                 Vallabel        Class labels for testing\n",
    "\n",
    "#     Evaluate training data before CV and balancing. Gradient boosting for prediction on the test data. \n",
    "#     True values are testing data class labels\n",
    "#     \"\"\"    \n",
    "#     d_train = xgb.DMatrix(inData, classData)\n",
    "#     d_test = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "#     params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:hinge', \n",
    "#     }\n",
    "#     XGB_initial = xgb.train(params, d_train)\n",
    "    \n",
    "#     Output_pred = XGB_initial.predict(d_test)\n",
    "#     print(f\"              **Initial Evaluation**\")\n",
    "#     print(f\"Confusion Matrix:\\n {confusion_matrix(Vallabel, Output_pred)}\")\n",
    "#     print(f\"MCC              {matthews_corrcoef(Vallabel, Output_pred)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3a2df",
   "metadata": {},
   "source": [
    "## Group K-fold CV (outer loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975ff775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(Training_Set):\n",
    "    \"\"\"      \n",
    "    Input:      Training_Set     80% training set split\n",
    "            \n",
    "    Returns:    IT_list         List of training features for each fold\n",
    "                LT_list         List of training class labels for each fold\n",
    "                IV_list         List of validation features for each fold\n",
    "                LV_list         List of validation class labels for each fold\n",
    "\n",
    "    K-fold CV with protein groups separated between training and validation sets for each fold. Creates 5 folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    features     = Training_Set.drop(['dataset'], axis =1)         #Features for training\n",
    "    labels       = Training_Set['dataset']                         #Class labels for training\n",
    "    groups       = Training_Set['AC Code'].to_list()               #List of proteins for grouping\n",
    "    \n",
    "    IT_list = []\n",
    "    LT_list = []\n",
    "    IV_list = []\n",
    "    LV_list = []\n",
    "    \n",
    "    CV             = GroupKFold(n_splits = 5)                           #Creates 5 splits\n",
    "\n",
    "    for train_idx, val_idx in CV.split(features, labels, groups):       #Generates the indices to be used for a training and validation split. Indicies are unique to train/ val sets\n",
    "\n",
    "        Rd = np.random.randint(time.time())                                  #Random number from 1 to time since epoch\n",
    "\n",
    "        Input_train                        = features.loc[train_idx]   #New dataframe from selected indices\n",
    "        Classes_train                      = labels.loc[train_idx]\n",
    "        Input_train.drop(['AC Code'], axis = 1, inplace = True)              #Group identifer not needed for training\n",
    "\n",
    "                \n",
    "        Input_val                          = features.loc[val_idx]\n",
    "        Classes_val                        = labels.loc[val_idx]\n",
    "        Input_val.drop(['AC Code'], axis   = 1, inplace = True)\n",
    "        \n",
    "        Input_train.reset_index(drop = True, inplace = True)\n",
    "        Classes_train.reset_index(drop = True, inplace = True)\n",
    "        Input_val.reset_index(drop = True, inplace = True)\n",
    "        Classes_val.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        IT_list.append(Input_train.sample(frac=1, random_state=Rd))          #Shuffles lists, random state to ensure features and labels match for each fold\n",
    "        LT_list.append(Classes_train.sample(frac=1, random_state=Rd))\n",
    "        IV_list.append(Input_val.sample(frac=1, random_state=(Rd-1)))\n",
    "        LV_list.append(Classes_val.sample(frac=1, random_state=(Rd-1)))\n",
    "    \n",
    "    return(IT_list, LT_list, IV_list, LV_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335a585",
   "metadata": {},
   "source": [
    "## Balancing (inner loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b6924e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minority_class(classData):\n",
    "    \"\"\" \n",
    "    Input:        classData  Array of class labels\n",
    "\n",
    "    Returns:      minClass   The label for the minority class\n",
    "                  minSize    The number of items in the minority class\n",
    "                  maxSize    The number of items in the majority class\n",
    "\n",
    "    Find information about class size imbalance\n",
    "    \"\"\"\n",
    "    \n",
    "    Minority_count = 0\n",
    "    Majority_count = 0\n",
    "    for datum in classData:\n",
    "        if datum == 1:\n",
    "            Majority_count += 1\n",
    "        elif datum == 0:\n",
    "            Minority_count += 1\n",
    "\n",
    "    minClass = 0\n",
    "    minSize  = Minority_count\n",
    "    maxSize  = Majority_count\n",
    "    if Minority_count > Majority_count:\n",
    "        minClass = 1\n",
    "        minSize  = Majority_count\n",
    "        maxSize  = Minority_count\n",
    "\n",
    "    return minClass, minSize, maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:        inData          array of input data\n",
    "                  classData       array of classes assigned\n",
    "                  minorityClass   class label for the minority class\n",
    "                  minoritySize    size of the minority class\n",
    "\n",
    "    Returns:      usedLines       array of indexes that are of interest for a balanced dataset\n",
    "\n",
    "    Perform the actual balancing for a fold between SNPs and PDs\n",
    "    \"\"\"\n",
    "    usedLines = [False] * len(inData) #Array of false for length of data\n",
    "    for i in range(len(inData)):\n",
    "        if classData[i] == minClass:        #Balance directly with dataframe\n",
    "            usedLines[i] = True            #True lines are SNP\n",
    "            \n",
    "    usedCount = 0\n",
    "    while usedCount < minSize:\n",
    "        i = rd.randrange(len(inData))\n",
    "        if usedLines[i] == False:\n",
    "            usedLines[i] = True\n",
    "            usedCount += 1          #Set PD lines \"True\", until equal to number of SNP lines\n",
    "\n",
    "    return usedLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(inData, classData, usedLines):\n",
    "    \"\"\"     \n",
    "    Input:      inData      array of input training data\n",
    "                classData   array of classes assigned to training data\n",
    "                usedLines   array of line indexes to print\n",
    "\n",
    "    Returns:    input_balance  Dataframe of balanced training features\n",
    "                label_balance  Dataframe of balanced training labels\n",
    "                       \n",
    "    Create dataframe of the input training data and classes used. Index_list preserves the indicies between usedLines and inData, used to pull the needed lines.\n",
    "    \"\"\"\n",
    "    input_balance = []\n",
    "    label_balance = []\n",
    "    \n",
    "    # for i in range(len(inData)):\n",
    "    #     if usedLines[i] == True:\n",
    "    #         input_i = inData.iloc[i]\n",
    "    #         input_balance.append(input_i)\n",
    "            \n",
    "    #         label_i = classData.iloc[i]\n",
    "    #         label_balance.append(label_i)\n",
    "            \n",
    "    Rd = np.random.randint(time.time())\n",
    "    index_list = []\n",
    "    \n",
    "    for i in range(len(usedLines)):\n",
    "        if usedLines[i] == True:\n",
    "            index_list.append(i)\n",
    "             \n",
    "    input_balance = inData.iloc[index_list] \n",
    "    label_balance = classData.iloc[index_list]   \n",
    "    \n",
    "    input_balance = input_balance.sample(frac=1, random_state=Rd).reset_index(inplace = False, drop = True)\n",
    "    label_balance = label_balance.sample(frac=1, random_state=Rd).reset_index(inplace = False, drop = True)\n",
    "    \n",
    "    return input_balance, label_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6746be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Balance_ratio(maxSize, minSize): \n",
    "    \"\"\" \n",
    "    Input:      maxSize     The number of items in the majority class\n",
    "                minSize     The number of items in the minority class\n",
    "\n",
    "    Returns:    BF          Number of balancing folds\n",
    "\n",
    "    Calculate the number of balancing folds needed using ratio of majority to minority class size. Double to ensure sufficient\n",
    "    majority class instances are sampled, then + 1 to make odd to allow weighted vote.\n",
    "    \"\"\"\n",
    "    Divide = maxSize/minSize\n",
    "    BF = (2 * round(Divide)) + 1 #Double ratio to nearest integer\n",
    "    return BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12239dc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Balance_Folds(BF, inData, classData, minClass, minSize):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                inData            Features for training\n",
    "                classData         Class labels for training\n",
    "                minClass          The label for the minority class\n",
    "                minSize           The number of items in the minority class\n",
    "                                  \n",
    "    Returns:    Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "\n",
    "    Perform the balance_data() function n number of balancing fold times. Return lists for feature data and labels\n",
    "    where each item is the output of balance_data()\n",
    "    \"\"\"\n",
    "    Input_folds  = []\n",
    "    Output_folds = []\n",
    "\n",
    "    for i in range(BF):\n",
    "        usedLines                    = balance(inData, classData, minClass, minSize)\n",
    "        input_balance, label_balance = balance_data(inData, classData, usedLines)\n",
    "        \n",
    "        Input_folds.append(input_balance)\n",
    "        Output_folds.append(label_balance)\n",
    "            \n",
    "    return Input_folds, Output_folds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21cd1aaa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ede39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_data(BF, Input_folds, Output_folds, ValData, Vallabel):\n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds\n",
    "                Input_folds       List of balanced training feature folds\n",
    "                Output_folds      List of balanced training label folds\n",
    "                ValData           Unseen validation features from CV fold\n",
    "                ValLabel          Unseen valiadation labels from CV fold\n",
    "                                  \n",
    "    Returns:    d_train_list      List of balanced training feature folds as DMatrix\n",
    "                d_val             Validation data as Dmatrix\n",
    "\n",
    "    Converts the balanced and validation data into Dmatrix for model training and evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    d_train_list =[]\n",
    "    for i in range(BF):\n",
    "            d_train = xgb.DMatrix(Input_folds[i], Output_folds[i])      #Create DMatrix for each training balanced fold\n",
    "            d_train_list.append(d_train)\n",
    "    d_val = xgb.DMatrix(ValData, Vallabel)\n",
    "\n",
    "    return (d_train_list, d_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb2003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CM(pred, d_val):\n",
    "    \"\"\" \n",
    "    Input:      pred              Prediction from a boosted tree during training\n",
    "                d_test            Validation data as Dmatrix\n",
    "\n",
    "    MCC as a custom evaluation metric for evaluating the model during training. This is different from the final weighted evaluation\n",
    "    \"\"\"\n",
    "    true_label = d_val.get_label()   \n",
    "    pred_label = np.round(pred) \n",
    "    \n",
    "    # CM = confusion_matrix(true_label, pred_label)\n",
    "    # error = (CM[0, 1] + CM[1,0])/(CM[0, 1] + CM[1,0] + CM[1, 1] + CM[0,0])\n",
    "\n",
    "    \n",
    "    return 'mcc', matthews_corrcoef(pred_label, true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0840d9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def hyperparameter(BF, d_train_list, d_val):\n",
    "#   \"\"\" Input:      BF                Number of balancing folds needed\n",
    "#                   d_train_list      List of balanced training feature folds as DMatrix\n",
    "#                   d_val             Validation data as Dmatrix\n",
    "\n",
    "#       Returns:    BF_GBC_HP         List of optimized hyperparameters for each GBC\n",
    "\n",
    "#       Use XGB in-built cross validaiton for hyperparameter turning\n",
    "#   \"\"\"  \n",
    "#   params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:logistic', \n",
    "#     # 'learning_rate': 0.3,\n",
    "#     # 'max_depth': 5,\n",
    "#     }\n",
    "#   for i in range(BF):        \n",
    "#     BF_GBC_HP = xgb.cv(\n",
    "#         params,\n",
    "#         d_train_list[i],\n",
    "#         nfold = 5,\n",
    "#         num_boost_round= 500,\n",
    "#         early_stopping_rounds= 20,\n",
    "#         custom_metric = CM, \n",
    "#         as_pandas=True,\n",
    "#     )\n",
    "  \n",
    "#   return(BF_GBC_HP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1decd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_fitting(BF, d_train_list, d_val): \n",
    "    \"\"\" \n",
    "    Input:      BF                Number of balancing folds                      \n",
    "                d_train_list      List of balanced training feature folds in DMatrix\n",
    "                d_test            Validation data as Dmatrix\n",
    "                \n",
    "    Returns:    BF_GBC            List of gradient boosted trees trained on each balancing fold\n",
    "\n",
    "    Create GBC model that returns probability predictions for each fold, using output of Balance_Folds() as training data (as a Dmatrix)\n",
    "    \"\"\"     \n",
    "    params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic', \n",
    "    'disable_default_eval_metric': 1,\n",
    "    'verbosity': 0,\n",
    "    # 'eval_metric':['MCC'],\n",
    "    } \n",
    "    \n",
    "    BF_GBC = []\n",
    "    for fold_i in range(BF):\n",
    "        d_train = d_train_list[fold_i]                          #Dmatrix for each balanced fold\n",
    "        BF_GBC.append(xgb.train(params, \n",
    "                                d_train, \n",
    "                                num_boost_round = 250,\n",
    "                                evals  = [(d_val,'Model')],\n",
    "                                verbose_eval = False,               #Print evaluation metrics every 50 trees\n",
    "                                early_stopping_rounds = 50,\n",
    "                                custom_metric = CM, \n",
    "                                )\n",
    "                      )                                         #Generates and fits a GBC for each training balanced fold\n",
    "        \n",
    "        \n",
    "    return BF_GBC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0dd278c",
   "metadata": {},
   "source": [
    "#### Test each GBC on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc41cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BF_validate(BF_GBC, d_test):\n",
    "    \"\"\" \n",
    "    Input:      BF_RFC            List of RFCs trained on balancing folds\n",
    "                d_test            Testing data as Dmatrix\n",
    "\n",
    "                \n",
    "    Returns:    Prob_matrix     List of arrays. Each item is 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "    \n",
    "    Test the trained RFCs on the test set, then for every instance, outputs the predicted probability for each class\n",
    "    \"\"\"\n",
    "    \n",
    "    Prob_matrix = []\n",
    "    for i in range(len(BF_GBC)):\n",
    "        Prob = BF_GBC[i].predict(d_test) #Predicts the probability of an instance belonging to the major/ positive class (PD/ 1). Output has shape (n_predictions,)\n",
    "        Prob_matrix.append(Prob)   \n",
    "        \n",
    "    return Prob_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b8fdd",
   "metadata": {},
   "source": [
    "### Weighted voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71033215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Vote(Prob_matrix):\n",
    "    \"\"\" \n",
    "    Input:      Prob_matrix     List of arrays. 2D matrix where the 1st dimension is each subset in balancing fold, \n",
    "                                2nd dimension is predicted probability\n",
    "\n",
    "    Returns:    Final_vote      Weighted vote classification\n",
    "\n",
    "    Calculate the final weighted vote using confidence scores (Sc) from Prob_matrix. Binary classification formula for:\n",
    "    Predictor states its prediction/ confidence scores are between 0.0 and 1.0 for each class\n",
    "    \"\"\"\n",
    "    PD_prob_matrix = Prob_matrix \n",
    "    \n",
    "    SNP_prob_matrix = []\n",
    "    for i in range(len(Prob_matrix)):               #SNP probabilites are 1 - (PD probabilites)\n",
    "        sub = 1 - Prob_matrix[i]\n",
    "        SNP_prob_matrix.append(sub)\n",
    "            \n",
    "    Sum_SNP = np.sum(SNP_prob_matrix, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(PD_prob_matrix, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "                                                    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)             #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()             #Flattens 2D array to 1D array\n",
    "\n",
    "    return(Final_vote, Sum_PD, Sum_SNP)         #Returns the final confidence scores\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd9d48f0",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92f36545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evalutation(TestLabels, Final_vote):\n",
    "    \"\"\" \n",
    "    Input:      Vallabel           Unseen validation class labels from CV fold\n",
    "                Final_vote         Weighted vote classification\n",
    "\n",
    "    Evaluate each fold with confusion matrix and MCC\n",
    "    \"\"\"\n",
    "    Output_pred = Final_vote\n",
    "        \n",
    "    print(f\"-----------------------------------------------------\\n              ***Fold {i + 1} Evaluation***\\n\")\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(TestLabels, Output_pred)}\")\n",
    "    print(f\"{classification_report(TestLabels, Output_pred)}\\nMCC                  {matthews_corrcoef(TestLabels, Output_pred)})\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7de56398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_MCC(TestLabels, Final_vote):\n",
    "    \"\"\" \n",
    "    Input:      Vallabel           Unseen validation class labels from CV fold\n",
    "                Final_vote         Weighted vote classification\n",
    "\n",
    "    Return fold MCC value\n",
    "    \"\"\"\n",
    "    Output_pred = Final_vote\n",
    "    MCC = matthews_corrcoef(TestLabels, Output_pred)\n",
    "    \n",
    "    return MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5ce9bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation(all_prob_matrix, TestLabels):\n",
    "    \n",
    "    flat_list = [matrix for proba in all_prob_matrix for matrix in proba]\n",
    "    \n",
    "    PD_prob_matrix = flat_list \n",
    "\n",
    "    SNP_prob_matrix = []\n",
    "    for i in range(len(flat_list)):               #SNP probabilites are 1 - (PD probabilites)\n",
    "        sub = 1 - flat_list[i]\n",
    "        SNP_prob_matrix.append(sub)\n",
    "            \n",
    "    Sum_SNP = np.sum(SNP_prob_matrix, axis = 0)     #Sum of all SNP confidence scores. 1D Array\n",
    "    Sum_PD  = np.sum(PD_prob_matrix, axis = 0)      #Sum of all PD confidence scores. 1D Array\n",
    "                                                    \n",
    "    Vote_arr  = [] \n",
    "\n",
    "    for i in range(len(Sum_PD)):\n",
    "        if Sum_PD[i] >= Sum_SNP[i]:\n",
    "            Vote_arr.append([1])                #Append PD classifications to list\n",
    "        elif Sum_SNP[i] > Sum_PD[i]:\n",
    "            Vote_arr.append([0])                #Append SNP classifications to list\n",
    "\n",
    "    Final_vote = np.stack(Vote_arr)             #Converts list of arrays to a 2D array\n",
    "    Final_vote = Final_vote.ravel()             #Flattens 2D array to 1D array\n",
    "    \n",
    "    MCC_final = matthews_corrcoef(TestLabels, Final_vote)\n",
    "    # print(f\"\\n\\n\\nFinal MCC: {MCC_final}\")\n",
    "    \n",
    "    return(MCC_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53993642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(Score_list):\n",
    "     \"\"\" \n",
    "     Input:      Score_list        List of MCC scores\n",
    "\n",
    "     Plots the MCCs of n runs, and calculates the average MCC\n",
    "     \"\"\"\n",
    "     fig, ax = plt.subplots(figsize=(16,10), dpi= 65)\n",
    "     x_axis = range(len(Score_list))\n",
    "     y_axis = Score_list\n",
    "\n",
    "     plt.scatter(x_axis, y_axis, color = 'teal')\n",
    "     plt.axhline(y=np.nanmean(Score_list), color = 'red', linestyle = 'dotted', linewidth = '1', label ='Avg')\n",
    "     plt.title('MCC of 15 XG Boost runs with group 5-fold CV, default parameters')\n",
    "     plt.xlabel('Run Number')\n",
    "     plt.ylabel('MCC')\n",
    "     plt.legend()\n",
    "     plt.show()\n",
    "     print(f\"Average: {np.nanmean(Score_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e232",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a74965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[155  72]\n",
      " [ 36 410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74       227\n",
      "           1       0.85      0.92      0.88       446\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6314080999556588)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[159  68]\n",
      " [ 44 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74       227\n",
      "           1       0.86      0.90      0.88       446\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.80      0.81       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6199053154375355)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[154  73]\n",
      " [ 44 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.72       227\n",
      "           1       0.85      0.90      0.87       446\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.81      0.79      0.80       673\n",
      "weighted avg       0.82      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6015181666846484)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  78]\n",
      " [ 39 407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72       227\n",
      "           1       0.84      0.91      0.87       446\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.78      0.80       673\n",
      "weighted avg       0.82      0.83      0.82       673\n",
      "\n",
      "MCC                  0.5995147481958496)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[156  71]\n",
      " [ 51 395]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       227\n",
      "           1       0.85      0.89      0.87       446\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.80      0.79      0.79       673\n",
      "weighted avg       0.82      0.82      0.82       673\n",
      "\n",
      "MCC                  0.5868971717194102)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[141  84]\n",
      " [ 29 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.63      0.71       225\n",
      "           1       0.83      0.94      0.88       448\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.78      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6101091350995145)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[146  79]\n",
      " [ 21 427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.65      0.74       225\n",
      "           1       0.84      0.95      0.90       448\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.86      0.80      0.82       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6575113937139443)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[154  71]\n",
      " [ 29 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.68      0.75       225\n",
      "           1       0.86      0.94      0.89       448\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6570475471667213)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  67]\n",
      " [ 33 415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       225\n",
      "           1       0.86      0.93      0.89       448\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.81      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6577151495389283)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[148  77]\n",
      " [ 27 421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.66      0.74       225\n",
      "           1       0.85      0.94      0.89       448\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.80      0.82       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6426014345384855)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[153  83]\n",
      " [ 26 411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.65      0.74       236\n",
      "           1       0.83      0.94      0.88       437\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.79      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6358882696635717)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157  79]\n",
      " [ 30 407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.74       236\n",
      "           1       0.84      0.93      0.88       437\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6355419159641588)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[160  76]\n",
      " [ 34 403]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.68      0.74       236\n",
      "           1       0.84      0.92      0.88       437\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6322622350180375)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[161  75]\n",
      " [ 18 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.68      0.78       236\n",
      "           1       0.85      0.96      0.90       437\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.87      0.82      0.84       673\n",
      "weighted avg       0.87      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6922673959520637)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[153  83]\n",
      " [ 25 412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.65      0.74       236\n",
      "           1       0.83      0.94      0.88       437\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.85      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6395032588348871)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[153  65]\n",
      " [ 29 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.77       218\n",
      "           1       0.87      0.94      0.90       455\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6722724219460945)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[162  56]\n",
      " [ 31 424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.79       218\n",
      "           1       0.88      0.93      0.91       455\n",
      "\n",
      "    accuracy                           0.87       673\n",
      "   macro avg       0.86      0.84      0.85       673\n",
      "weighted avg       0.87      0.87      0.87       673\n",
      "\n",
      "MCC                  0.6984419827115796)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[154  64]\n",
      " [ 26 429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.77       218\n",
      "           1       0.87      0.94      0.91       455\n",
      "\n",
      "    accuracy                           0.87       673\n",
      "   macro avg       0.86      0.82      0.84       673\n",
      "weighted avg       0.87      0.87      0.86       673\n",
      "\n",
      "MCC                  0.6864449229061372)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[154  64]\n",
      " [ 31 424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.76       218\n",
      "           1       0.87      0.93      0.90       455\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6690465146068787)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  60]\n",
      " [ 35 420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77       218\n",
      "           1       0.88      0.92      0.90       455\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6703590902295093)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  74]\n",
      " [ 36 414]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.67      0.73       223\n",
      "           1       0.85      0.92      0.88       450\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.79      0.81       673\n",
      "weighted avg       0.83      0.84      0.83       673\n",
      "\n",
      "MCC                  0.62009675427434)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  74]\n",
      " [ 39 411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.67      0.73       223\n",
      "           1       0.85      0.91      0.88       450\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6100349345374181)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[147  76]\n",
      " [ 37 413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.66      0.72       223\n",
      "           1       0.84      0.92      0.88       450\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6093250508658848)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[139  84]\n",
      " [ 37 413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.70       223\n",
      "           1       0.83      0.92      0.87       450\n",
      "\n",
      "    accuracy                           0.82       673\n",
      "   macro avg       0.81      0.77      0.78       673\n",
      "weighted avg       0.82      0.82      0.81       673\n",
      "\n",
      "MCC                  0.5795602816060516)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[146  77]\n",
      " [ 48 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.70       223\n",
      "           1       0.84      0.89      0.87       450\n",
      "\n",
      "    accuracy                           0.81       673\n",
      "   macro avg       0.80      0.77      0.78       673\n",
      "weighted avg       0.81      0.81      0.81       673\n",
      "\n",
      "MCC                  0.5695131983397308)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[138  71]\n",
      " [ 28 436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.74       209\n",
      "           1       0.86      0.94      0.90       464\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.80      0.82       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6439965783453713)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[134  75]\n",
      " [ 29 435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72       209\n",
      "           1       0.85      0.94      0.89       464\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.79      0.81       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6249826248277666)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[142  67]\n",
      " [ 32 432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.68      0.74       209\n",
      "           1       0.87      0.93      0.90       464\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6451559046835729)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[133  76]\n",
      " [ 29 435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72       209\n",
      "           1       0.85      0.94      0.89       464\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.79      0.80       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6211162361373027)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[136  73]\n",
      " [ 35 429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.65      0.72       209\n",
      "           1       0.85      0.92      0.89       464\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.611457856861207)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[131  85]\n",
      " [ 26 431]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.61      0.70       216\n",
      "           1       0.84      0.94      0.89       457\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.77      0.79       673\n",
      "weighted avg       0.83      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6066638197612944)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[140  76]\n",
      " [ 30 427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.73       216\n",
      "           1       0.85      0.93      0.89       457\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.79      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6258559938751127)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[130  86]\n",
      " [ 28 429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.60      0.70       216\n",
      "           1       0.83      0.94      0.88       457\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.77      0.79       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.5954084103299399)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[143  73]\n",
      " [ 31 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.66      0.73       216\n",
      "           1       0.85      0.93      0.89       457\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.80      0.81       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6335708193683259)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[145  71]\n",
      " [ 31 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74       216\n",
      "           1       0.86      0.93      0.89       457\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.80      0.82       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6410631388617006)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[138  62]\n",
      " [ 47 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       200\n",
      "           1       0.87      0.90      0.89       473\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.81      0.80      0.80       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.604600385925403)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[138  62]\n",
      " [ 53 420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.71       200\n",
      "           1       0.87      0.89      0.88       473\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.80      0.79      0.79       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.5858616595751516)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[139  61]\n",
      " [ 41 432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.73       200\n",
      "           1       0.88      0.91      0.89       473\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.82      0.80      0.81       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6280835337847035)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[129  71]\n",
      " [ 38 435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.65      0.70       200\n",
      "           1       0.86      0.92      0.89       473\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.82      0.78      0.80       673\n",
      "weighted avg       0.83      0.84      0.83       673\n",
      "\n",
      "MCC                  0.5974484398564913)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[137  63]\n",
      " [ 41 432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.69      0.72       200\n",
      "           1       0.87      0.91      0.89       473\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.82      0.80      0.81       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6199632343909889)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[138  72]\n",
      " [ 28 435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.73       210\n",
      "           1       0.86      0.94      0.90       463\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.80      0.82       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6413197934933184)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[148  62]\n",
      " [ 29 434]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.76       210\n",
      "           1       0.88      0.94      0.91       463\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.86      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6757616564758405)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[150  60]\n",
      " [ 36 427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76       210\n",
      "           1       0.88      0.92      0.90       463\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.84      0.82      0.83       673\n",
      "weighted avg       0.85      0.86      0.85       673\n",
      "\n",
      "MCC                  0.659476595260494)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[151  59]\n",
      " [ 27 436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78       210\n",
      "           1       0.88      0.94      0.91       463\n",
      "\n",
      "    accuracy                           0.87       673\n",
      "   macro avg       0.86      0.83      0.84       673\n",
      "weighted avg       0.87      0.87      0.87       673\n",
      "\n",
      "MCC                  0.694085656717507)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[142  68]\n",
      " [ 35 428]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.68      0.73       210\n",
      "           1       0.86      0.92      0.89       463\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.83      0.80      0.81       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6320558940891691)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[155  73]\n",
      " [ 26 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.68      0.76       228\n",
      "           1       0.85      0.94      0.89       445\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.81      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6632773367445333)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[149  79]\n",
      " [ 33 412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.73       228\n",
      "           1       0.84      0.93      0.88       445\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6173239140502462)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157  71]\n",
      " [ 27 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76       228\n",
      "           1       0.85      0.94      0.90       445\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.81      0.83       673\n",
      "weighted avg       0.85      0.85      0.85       673\n",
      "\n",
      "MCC                  0.6667914435889607)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  70]\n",
      " [ 35 410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75       228\n",
      "           1       0.85      0.92      0.89       445\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6429103608500695)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[155  73]\n",
      " [ 36 409]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74       228\n",
      "           1       0.85      0.92      0.88       445\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6287531364683179)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[155  76]\n",
      " [ 40 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.67      0.73       231\n",
      "           1       0.84      0.91      0.87       442\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6075563280198312)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[160  71]\n",
      " [ 37 405]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.69      0.75       231\n",
      "           1       0.85      0.92      0.88       442\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.80      0.82       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6354013154361122)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[148  83]\n",
      " [ 34 408]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.64      0.72       231\n",
      "           1       0.83      0.92      0.87       442\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.78      0.80       673\n",
      "weighted avg       0.82      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6026182923813109)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[155  76]\n",
      " [ 38 404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73       231\n",
      "           1       0.84      0.91      0.88       442\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6141729128107436)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[162  69]\n",
      " [ 42 400]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.74       231\n",
      "           1       0.85      0.90      0.88       442\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.82      0.80      0.81       673\n",
      "weighted avg       0.83      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6263052486253066)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[160  78]\n",
      " [ 35 400]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74       238\n",
      "           1       0.84      0.92      0.88       435\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.83      0.80      0.81       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.623711166364516)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[174  64]\n",
      " [ 29 406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79       238\n",
      "           1       0.86      0.93      0.90       435\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.86      0.83      0.84       673\n",
      "weighted avg       0.86      0.86      0.86       673\n",
      "\n",
      "MCC                  0.6921219579028006)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[154  84]\n",
      " [ 26 409]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.65      0.74       238\n",
      "           1       0.83      0.94      0.88       435\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.79      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6343443059090678)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[159  79]\n",
      " [ 28 407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.67      0.75       238\n",
      "           1       0.84      0.94      0.88       435\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.80      0.82       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6443397453071595)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[164  74]\n",
      " [ 28 407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76       238\n",
      "           1       0.85      0.94      0.89       435\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.85      0.81      0.83       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6614345748262753)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[154  68]\n",
      " [ 39 412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74       222\n",
      "           1       0.86      0.91      0.89       451\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.80      0.81       673\n",
      "weighted avg       0.84      0.84      0.84       673\n",
      "\n",
      "MCC                  0.6312639303375851)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[150  72]\n",
      " [ 42 409]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.72       222\n",
      "           1       0.85      0.91      0.88       451\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.6065607202958783)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[144  78]\n",
      " [ 35 416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.65      0.72       222\n",
      "           1       0.84      0.92      0.88       451\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.83       673\n",
      "\n",
      "MCC                  0.607636465986428)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[147  75]\n",
      " [ 42 409]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.72       222\n",
      "           1       0.85      0.91      0.87       451\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.81      0.78      0.80       673\n",
      "weighted avg       0.82      0.83      0.82       673\n",
      "\n",
      "MCC                  0.5953203760565702)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[150  72]\n",
      " [ 32 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.68      0.74       222\n",
      "           1       0.85      0.93      0.89       451\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.80      0.82       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6400947399381737)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157  70]\n",
      " [ 32 414]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75       227\n",
      "           1       0.86      0.93      0.89       446\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6521314631831789)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  69]\n",
      " [ 28 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77       227\n",
      "           1       0.86      0.94      0.90       446\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.85      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.85       673\n",
      "\n",
      "MCC                  0.6694806273458984)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[158  69]\n",
      " [ 27 419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77       227\n",
      "           1       0.86      0.94      0.90       446\n",
      "\n",
      "    accuracy                           0.86       673\n",
      "   macro avg       0.86      0.82      0.83       673\n",
      "weighted avg       0.86      0.86      0.85       673\n",
      "\n",
      "MCC                  0.6729738257638481)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[157  70]\n",
      " [ 33 413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75       227\n",
      "           1       0.86      0.93      0.89       446\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.81      0.82       673\n",
      "weighted avg       0.85      0.85      0.84       673\n",
      "\n",
      "MCC                  0.6487309981325384)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[154  73]\n",
      " [ 31 415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.68      0.75       227\n",
      "           1       0.85      0.93      0.89       446\n",
      "\n",
      "    accuracy                           0.85       673\n",
      "   macro avg       0.84      0.80      0.82       673\n",
      "weighted avg       0.84      0.85      0.84       673\n",
      "\n",
      "MCC                  0.644816012634078)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 1 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[147  77]\n",
      " [ 31 418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.73       224\n",
      "           1       0.84      0.93      0.89       449\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.84      0.79      0.81       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6273737000796845)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 2 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[143  81]\n",
      " [ 29 420]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72       224\n",
      "           1       0.84      0.94      0.88       449\n",
      "\n",
      "    accuracy                           0.84       673\n",
      "   macro avg       0.83      0.79      0.80       673\n",
      "weighted avg       0.84      0.84      0.83       673\n",
      "\n",
      "MCC                  0.6199095596140637)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 3 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[142  82]\n",
      " [ 34 415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.63      0.71       224\n",
      "           1       0.84      0.92      0.88       449\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.78      0.79       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.5985579065521708)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 4 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[148  76]\n",
      " [ 39 410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72       224\n",
      "           1       0.84      0.91      0.88       449\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.79      0.80       673\n",
      "weighted avg       0.83      0.83      0.82       673\n",
      "\n",
      "MCC                  0.6036846139481558)\n",
      "\n",
      "-----------------------------------------------------\n",
      "              ***Fold 5 Evaluation***\n",
      "\n",
      "Confusion Matrix:\n",
      " [[147  77]\n",
      " [ 39 410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72       224\n",
      "           1       0.84      0.91      0.88       449\n",
      "\n",
      "    accuracy                           0.83       673\n",
      "   macro avg       0.82      0.78      0.80       673\n",
      "weighted avg       0.82      0.83      0.82       673\n",
      "\n",
      "MCC                  0.5999793460385724)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1040x650 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.6602374250503029\n"
     ]
    }
   ],
   "source": [
    "Score_list = []\n",
    "for i in range(0,15):\n",
    "    file = \"AC_dataset.csv\"\n",
    "    Training_Set, Testing_Set                     = Train_Test_Split(file)                                 #Create training and testing sets\n",
    "    d_test, TestData, TestLabels                  = test_matrix(Testing_Set)\n",
    "    # test(inData, classData, ValData, Vallabel)                                                          #Initial evaluation\n",
    "    IT_list, LT_list, IV_list, LV_list = CV(Training_Set)                #Cross-validate training set        \n",
    "\n",
    "    K_fold_score = []\n",
    "    all_prob_matrix = []\n",
    "    for i in range(len(IT_list)):          \n",
    "        inData = IT_list[i]\n",
    "        classData = LT_list[i]\n",
    "        ValData = IV_list[i]\n",
    "        Vallabel = LV_list[i]\n",
    "\n",
    "        minClass, minSize, maxSize  = find_minority_class(classData)                            #Determines imbalance\n",
    "        BF                          = Balance_ratio(maxSize, minSize)                           #Determins number of balancing folds needed\n",
    "        Input_folds, Output_folds   = Balance_Folds(BF, inData, classData, minClass, minSize)   # balance() and balance_data() functions are called under this\n",
    "        d_train_list, d_val         = model_training_data(BF, Input_folds, Output_folds, ValData, Vallabel)\n",
    "        # BF_GBC_HP                   = hyperparameter(BF, d_train_list, d_val)\n",
    "        BF_GBC                      = BF_fitting(BF, d_train_list, d_val)\n",
    "        Prob_matrix                 = BF_validate(BF_GBC, d_test)\n",
    "        all_prob_matrix.append(Prob_matrix)\n",
    "\n",
    "        Final_vote, Sum_PD, Sum_SNP = Weighted_Vote(Prob_matrix)\n",
    "        \n",
    "        evalutation(TestLabels, Final_vote)\n",
    "        MCC = fold_MCC(Final_vote, TestLabels)\n",
    "        \n",
    "    MCC_final = final_evaluation(all_prob_matrix, TestLabels)\n",
    "    Score_list.append(MCC_final)  \n",
    "\n",
    "plot(Score_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 337.844,
   "position": {
    "height": "359.844px",
    "left": "1536px",
    "right": "20px",
    "top": "112px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e5cd67c8584618c148c6f2b57de13817422ccd98975b320089863a41752ead79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
